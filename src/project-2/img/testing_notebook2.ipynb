{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "#with open('/Users/mjdioli/Documents/STK-IN5000/ml-society-science/src/project-2/final_analysis.json') as json_file:\n",
    "    #data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'TestRecommenderMarius'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a09878b73305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mTestRecommenderMarius\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'TestRecommenderMarius'"
     ]
    }
   ],
   "source": [
    "import TestRecommenderMarius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'TestRecommenderMarius'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5aa74c10985f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTestRecommenderMarius\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfixed_treatments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_full_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_exploration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'TestRecommenderMarius'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from TestRecommenderMarius import fixed_treatments, final_full_analysis, test_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TestRecommenderMarius import test_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict_sum = {}\n",
    "new_dict_mean = {}\n",
    "for key, value in data.items():\n",
    "    new_dict_sum[key] = sum(value)\n",
    "    new_dict_mean[key] = sum(value)/len(value)\n",
    "\n",
    "sorted_sum = {k: v for k, v in sorted(new_dict_sum.items(), key=lambda item: item[1])}\n",
    "sorted_mean= {k: v for k, v in sorted(new_dict_mean.items(), key=lambda item: item[1])}\n",
    "\n",
    "print(sorted_sum)\n",
    "\n",
    "\n",
    "return_dict = fixed_treatments(n_tests=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for key, value in return_dict.items():\n",
    "    print(counter)\n",
    "    sum_val = sum(value[0])\n",
    "    mean_val  = sum(value[0])/len(value[0])\n",
    "    covars = value[1]\n",
    "    covars = covars.loc[covars[\"y\"]==1.0]\n",
    "    s = covars.sum()\n",
    "    covars = covars[s.sort_values(ascending=False).index]\n",
    "    covars.drop([\"sex\", \"smoker\", \"y\", \"symptom 1\", \"symptom 2\"], axis=1, inplace=True)\n",
    "    covars.head()\n",
    "    top5 = covars.iloc[:,:5]\n",
    "    bot5 = covars.iloc[:,-5:]\n",
    "    top5.head()\n",
    "    print(\"Action: \", key)\n",
    "    #print(\"Sum of utilities: \", sum_val )\n",
    "    if sum_val>500:\n",
    "        print(\"large utility: \", sum_val, key)\n",
    "    #print(\"Mean of utilities: \", mean_val )\n",
    "    #print(list(top5.index)+list(bot5.index))\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(11,8)\n",
    "    plt.bar(list(top5.columns)+list(bot5.columns), list(top5.sum())+list(bot5.sum()))\n",
    "    plt.title(key)\n",
    "    plt.show()\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sum = {k: sum(v[0]) for k, v in sorted(return_dict.items(), key=lambda item: item[1])}\n",
    "sorted_sum = {k: v for k, v in sorted(sorted_sum.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "for key, value in return_dict.items():\n",
    "    plt.hist([sum(resample(value[0])) for _ in range(500)], bins=15)\n",
    "    plt.xlabel(\"Utility\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Histogram of utilities for \" + key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking intersections of best three policies\n",
    "best_three = [return_dict[\"fixed_policy_1\"],\n",
    "return_dict[\"fixed_policy_2\"],\n",
    "return_dict[\"fixed_policy_11\"]]\n",
    "for name, item in zip([\"fixed_policy_1\", \"fixed_policy_2\", \"fixed_policy_11\"], best_three):\n",
    "    for name2, item2 in zip([\"fixed_policy_1\", \"fixed_policy_2\", \"fixed_policy_11\"], best_three):\n",
    "        if name==name2:\n",
    "            continue\n",
    "        else:\n",
    "            covars = item[1]\n",
    "            covars = covars.loc[covars[\"y\"]==1.0]\n",
    "            s = covars.sum()\n",
    "            covars = covars[s.sort_values(ascending=False).index]\n",
    "            covars.drop([\"sex\", \"smoker\", \"y\", \"symptom 1\", \"symptom 2\"], axis=1, inplace=True)\n",
    "            covars.head()\n",
    "            top5 = covars.iloc[:,:10]\n",
    "            bot5 = covars.iloc[:,-10:]\n",
    "\n",
    "            covars = item2[1]\n",
    "            covars = covars.loc[covars[\"y\"]==1.0]\n",
    "            s = covars.sum()\n",
    "            covars = covars[s.sort_values(ascending=False).index]\n",
    "            covars.drop([\"sex\", \"smoker\", \"y\", \"symptom 1\", \"symptom 2\"], axis=1, inplace=True)\n",
    "            covars.head()\n",
    "            top5_2 = covars.iloc[:,:10]\n",
    "            bot5_2 = covars.iloc[:,-10:]\n",
    "\n",
    "            print(\"Intersection of \" +name+ \" and \"+ name2)\n",
    "            print(\"Top 10 genes\", set(top5).intersection(top5_2))\n",
    "            print(\"Bottom 10 genes\", set(bot5).intersection(bot5_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the intersections of the worst three policies\n",
    "worst_three = [return_dict[\"fixed_policy_101\"],\n",
    "return_dict[\"fixed_policy_102\"],\n",
    "return_dict[\"fixed_policy_48\"]]\n",
    "for name, item in zip([\"fixed_policy_101\", \"fixed_policy_102\", \"fixed_policy_48\"], worst_three):\n",
    "    for name2, item2 in zip([\"fixed_policy_101\", \"fixed_policy_102\", \"fixed_policy_48\"], worst_three):\n",
    "        if name==name2:\n",
    "            continue\n",
    "        else:\n",
    "            covars = item[1]\n",
    "            covars = covars.loc[covars[\"y\"]==1.0]\n",
    "            s = covars.sum()\n",
    "            covars = covars[s.sort_values(ascending=False).index]\n",
    "            covars.drop([\"sex\", \"smoker\", \"y\", \"symptom 1\", \"symptom 2\"], axis=1, inplace=True)\n",
    "            covars.head()\n",
    "            top5 = covars.iloc[:,:10]\n",
    "            bot5 = covars.iloc[:,-10:]\n",
    "\n",
    "            covars = item2[1]\n",
    "            covars = covars.loc[covars[\"y\"]==1.0]\n",
    "            s = covars.sum()\n",
    "            covars = covars[s.sort_values(ascending=False).index]\n",
    "            covars.drop([\"sex\", \"smoker\", \"y\", \"symptom 1\", \"symptom 2\"], axis=1, inplace=True)\n",
    "            covars.head()\n",
    "            top5_2 = covars.iloc[:,:10]\n",
    "            bot5_2 = covars.iloc[:,-10:]\n",
    "\n",
    "            print(\"Intersection of \" +name+ \" and \"+ name2)\n",
    "            print(\"Top 10 genes\", set(top5).intersection(top5_2))\n",
    "            print(\"Bottom 10 genes\", set(bot5).intersection(bot5_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test exploration\n",
    "results = test_exploration(10000, epsilons = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = []\n",
    "values = []\n",
    "for key, value in results.items():\n",
    "    epsilons.append(key)\n",
    "    values.append(sum(value))\n",
    "    print(\"Epsilon: \",key, \"Utility: \", sum(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.plot(epsilons, values)\n",
    "plt.title(\"Utility of 10000 tests at various levels of exploration\")\n",
    "plt.xlabel(\"Exploration factor\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.show()\n",
    "plt.savefig(\"./exploration_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "scores = []\n",
    "for model, score in two_action_anal.items():\n",
    "    models.append(model)\n",
    "    scores.append(sum(score))\n",
    "    print(model, sum(score))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.bar(models, scores)\n",
    "plt.title(\"Utility of various models with 5000 online iterations\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.show()\n",
    "#plt.savefig(\"./exploration_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in final_anal_dict.items():\n",
    "    print(model, sum(score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}