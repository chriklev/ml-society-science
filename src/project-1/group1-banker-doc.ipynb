{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "\n",
    "\n",
    "## Policy\n",
    "\n",
    "We assume that $A = \\{a_{0}, a_{1}\\}$, we further define $a_{0}$ as \"deny credit\" and $a_{1}$ as \"offer credit\". We also know from the project text that the utility function is assumed to be linear. This implies that among $E(utility|a_{i})$ and $E(utility|a_{j})$, we will always choose action $a_{i}$ over action $a_{j}$ if $E(utility|a_{i}) > E(utility|a_{j})$ adapted from (Dimitrakakis, 2020, p. 48). We will \"blindly\" choose the action that maximizes expected utility.\n",
    "\n",
    "## Utility function\n",
    "\n",
    "There are two possible actions that we could perform: $\\{a_{0}, a_{1}\\}$. We also have the following rewards, which are defined as possible outcomes for the bank (Dimitrakakis, 2020, p. 47). In our case these rewards are $\\{-m, 0, m((1 + r)^{n} - 1)\\}$. Further there are two possible actions for the bank when it comes to deciding for each new customer if they will be granted credit.\n",
    "\n",
    "Further, we will use the definition of expected utility\n",
    "$$\n",
    "E[U|a_{t} = a] = \\sum_{r} U(r)Pr(r|a_{t} = a)\n",
    "$$\n",
    "adapted from (Dimitrakakis, 2020, p. 48). This will be used for each action to calculate its expected utility. We can further define the rewards as $r_{0} =$ \"the debtor defaults\" and $r_{1} =$ \"the debtor does not default\". If we use the assumption that the utility function is linear, we can say that $U(r)$ is proportional to $r$.\n",
    "\n",
    "### Grant credit\n",
    "\n",
    "If we decide to grant credit ($a_{t} = 1 $) we have the following expected utility considering the rewards above:\n",
    "$$\n",
    "E[U|a_{t} = 1] = U(r = r_{0})Pr(r = r_{0}|a_{t} = 1) + U(r = r_{1})Pr(r = r_{1}|a_{t} = 1) \n",
    "$$\n",
    "which becomes\n",
    "$$\n",
    "E[U|a_{t} = 1] = -m \\cdot Pr(r = r_{0}|a_{t} = 1) + m((1 + r)^{n} - 1) \\cdot Pr(r = r_{1}|a_{t} = 1)\n",
    "$$\n",
    "In our code, we have defined $Pr(r = r_{1}|a_{t} = 1)$ as the variable \"p\\_c\" and $Pr(r = r_{0}|a_{t} = 1)$ as 1-\"p\\_c\".\n",
    "\n",
    "### Do not grant credit\n",
    "\n",
    "If we decide not to grant credit ($a_{t} = 0 $).\n",
    "\n",
    "$$\n",
    "E[U|a_{t} = 0] = 0 \\cdot Pr(r = r_{0}|a_{t} = 0) + 0 \\cdot Pr(r = r_{1}|a_{t} = 0) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expected_utility(self, X, action):\n",
    "    \"\"\"Calculate expected utility using the decision maker model.\n",
    "\n",
    "    Args:\n",
    "        X: New observations.\n",
    "        action: Whether or not to grant the loan.\n",
    "\n",
    "    Returns:\n",
    "        The expected utilities of the decision maker.\n",
    "    \"\"\"\n",
    "    if action == 0:\n",
    "        return np.zeros(X.shape[0])\n",
    "\n",
    "    r = self.rate\n",
    "    p_c = self.predict_proba(X)\n",
    "\n",
    "    # duration in months\n",
    "    n = X['duration']\n",
    "    # amount\n",
    "    m = X['amount']\n",
    "\n",
    "    e_x = p_c * m * ((1 + r) ** n - 1) + (1 - p_c) * (-m)\n",
    "    return e_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "\n",
    "We chose to use a logistic regression model. It predicts the probability of a binary categorical variable beeing 1. A fresh random state is also given to the model for reproducable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_model(self, X, y):\n",
    "    \"\"\"Fits the logistic model.\n",
    "\n",
    "    Args:\n",
    "        X: Covariates\n",
    "        y: Response variable\n",
    "\n",
    "    Notes:\n",
    "        Using logistic regression, adapted from\n",
    "        https://scikit-learn.org/stable/modules/generated/\n",
    "            sklearn.linear_model.LogisticRegression.html\n",
    "    \"\"\"\n",
    "    log_reg_object = LogisticRegression(random_state=1, max_iter=2000)\n",
    "    return log_reg_object.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading the data we one hot encode all the catagorical variables which means that they loose the information in the order. This could be fixed by instead giving them an integer value, but then we assume a linear relationship between the order of the categories.\n",
    "\n",
    "## Best action\n",
    "\n",
    "The best action is the action that gives the highest utility. In the event of the utilities beeing equal, we chose to not give a loan. Because of the linear utility of the investor it does not matter what we do in this situation, but we figured it is better to not accept unnecessary variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(self, X):\n",
    "    \"\"\"Gets the best actions defined as the actions that maximizes utility.\n",
    "    An epsilon for utility is also set as the threshold that the expected\n",
    "    utility should exceed in order to get the best action. This utility\n",
    "    epsilon is 0 if the banker is not configured to use this functionality.\n",
    "    Otherwise it is estimated from the training data as the value that\n",
    "    provide a type 1 error below the parameter '_max_type1_error'.\n",
    "\n",
    "    Args:\n",
    "        X: New observations.\n",
    "\n",
    "    Returns:\n",
    "        Best actions based on maximizing utility.\n",
    "    \"\"\"\n",
    "    expected_utility_give_loan = self.expected_utility(X, 1)\n",
    "    expected_utility_no_loan = self.expected_utility(X, 0)\n",
    "\n",
    "    give_loan = expected_utility_give_loan > (\n",
    "        expected_utility_no_loan + self._utility_epsilon)\n",
    "    return give_loan\n",
    "\n",
    "def predict_proba(self, X):\n",
    "    \"\"\"Predicts the probability for y=1 given new observations.\n",
    "\n",
    "    Args:\n",
    "        x: New, independent observations.\n",
    "\n",
    "    Returns:\n",
    "        The predicted probabilities for y=1.\n",
    "    \"\"\"\n",
    "    return self.model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model against random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random_banker\n",
    "import group1_banker\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing decision makers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data():\n",
    "    \"\"\" Reads in raw data then maps response to 0 and 1 and parses\n",
    "    the categorical attributes to pandas.caategorical\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame with the \"raw\" data\n",
    "    \"\"\"\n",
    "    features = ['checking account balance', 'duration', 'credit history',\n",
    "                'purpose', 'amount', 'savings', 'employment', 'installment',\n",
    "                'marital status', 'other debtors', 'residence time',\n",
    "                'property', 'age', 'other installments', 'housing', 'credits',\n",
    "                'job', 'persons', 'phone', 'foreign', 'repaid']\n",
    "\n",
    "    data_raw = pd.read_csv(\"../../data/credit/german.data\",\n",
    "                           delim_whitespace=True, names=features)\n",
    "\n",
    "    # Mapping the response to 0 and 1\n",
    "    data_raw.loc[:, \"repaid\"] = data_raw[\"repaid\"].map({1: 1, 2: 0})\n",
    "\n",
    "    categorical_columns = ['checking account balance', 'credit history',\n",
    "                           'purpose', 'savings', 'employment', 'marital status',\n",
    "                           'other debtors', 'property', 'other installments',\n",
    "                           'housing', 'job', 'phone', 'foreign', 'repaid']\n",
    "    data_raw.loc[:, categorical_columns] = data_raw[categorical_columns].apply(\n",
    "        lambda x: x.astype('category'))\n",
    "\n",
    "    return data_raw\n",
    "\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    \"\"\" One hot encodes specified columns.\n",
    "\n",
    "    Args:\n",
    "        data: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the categorical attributes one hot encoded\n",
    "    \"\"\"\n",
    "    columns = ['checking account balance', 'credit history',\n",
    "               'purpose', 'savings', 'employment', 'marital status',\n",
    "               'other debtors', 'property', 'other installments',\n",
    "               'housing', 'job', 'phone', 'foreign']\n",
    "    dummies = pd.get_dummies(data[columns], drop_first=True)\n",
    "    data = data.drop(columns, axis=1)\n",
    "\n",
    "    return data.join(dummies)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\" Gets the data and applies one hot encoding\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the usable data\n",
    "    \"\"\"\n",
    "    data = get_raw_data()\n",
    "    data = one_hot_encode(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_from_obs(predicted_decision, true_decision, amount, duration, interest_rate):\n",
    "    \"\"\"Calculates utility for predicted decisions\n",
    "\n",
    "    Args:\n",
    "        predicted_decision: the model's best actions\n",
    "        true_decision: if the observations repaid or not\n",
    "        amount: the lending amounts\n",
    "        duration: the number of periods\n",
    "        interest_rate: the interest rate of the loan\n",
    "\n",
    "    Returns:\n",
    "        numpy array with the utilities for each decision.\n",
    "    \"\"\"\n",
    "    utility = np.zeros_like(true_decision)\n",
    "\n",
    "    predicted_decision_bool = predicted_decision == 1\n",
    "    ind1 = np.logical_and(predicted_decision_bool, true_decision == 1)\n",
    "    ind2 = np.logical_and(predicted_decision_bool, true_decision == 0)\n",
    "\n",
    "    utility[ind1] = amount[ind1]*((1 + interest_rate)**duration[ind1] - 1)\n",
    "    utility[ind2] = -amount[ind2]\n",
    "\n",
    "    return utility\n",
    "\n",
    "\n",
    "def utility_from_test_set(X, y, decision_maker, interest_rate):\n",
    "    \"\"\"Calculates total utility from a given test set.\n",
    "\n",
    "    Args:\n",
    "        X: the covariates of the test set\n",
    "        y: the response variable of the test set\n",
    "        decision_maker: the decision maker to use in order to calculate utility\n",
    "        interest_rate: the interest rate to use when calculating utility\n",
    "\n",
    "    Returns:\n",
    "        The sum of utility from the test set and the sum of utility divided by\n",
    "        total amount.\n",
    "    \"\"\"\n",
    "    predicted_decision = decision_maker.get_best_action(X)\n",
    "\n",
    "    amount = X['amount']\n",
    "    duration = X['duration']\n",
    "\n",
    "    utility = utility_from_obs(\n",
    "        predicted_decision, y, amount, duration, interest_rate)\n",
    "\n",
    "    return np.sum(utility), np.sum(utility)/np.sum(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_cross_validation_utility(X, y, bankers, interest_rate, n_repeats=20, n_folds=5):\n",
    "    \"\"\" Preforms repeated cross validation to find estimates for average utility\n",
    "    for different bankers.\n",
    "\n",
    "    Args:\n",
    "        X: pandas data frame with covariates\n",
    "        y: pandas series with the response\n",
    "        bankers: iterable with bankers implementing the fit() and get_best_action() methods.\n",
    "        interest_rate: float interest rate by month\n",
    "        n_repeats: number of repeats in repeated cross validation\n",
    "        n_folds: number of folds in k-fold cross validation\n",
    "\n",
    "    Returns:\n",
    "        numpy ndarray with shape (number of bankers, n_repeats, n_folds)\n",
    "        containing the utilities\n",
    "    \"\"\"\n",
    "    results = np.empty(shape=(len(bankers), n_repeats, n_folds))\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "        j = 0\n",
    "        for train_indices, test_indices in kf.split(X):\n",
    "            X_train = X.iloc[train_indices, :]\n",
    "            X_test = X.iloc[test_indices, :]\n",
    "            y_train = y[train_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            for b, banker in enumerate(bankers):\n",
    "                banker.fit(X_train, y_train)\n",
    "\n",
    "                util, _ = utility_from_test_set(\n",
    "                    X_test, y_test, banker, interest_rate)\n",
    "                results[b, i, j] = util\n",
    "            j += 1\n",
    "    return results\n",
    "\n",
    "\n",
    "def compare_with_random(n_repeats, n_folds, response, interest_rate):\n",
    "    \"\"\" Tests the random banker against our group1 banker.\n",
    "\n",
    "    Args:\n",
    "        n_repeats: the number of repeated cv's\n",
    "        n_folds: number of folds in k-fold cv\n",
    "        response: the name of the response variable\n",
    "        interest_rate: float interest rate by month\n",
    "\n",
    "    Returns:\n",
    "        numpy ndarray with shape (number of bankers, n_repeats, n_folds)\n",
    "        containing the utilities\n",
    "    \"\"\"\n",
    "\n",
    "    ## decision makers ##\n",
    "    # random banker\n",
    "    r_banker = random_banker.RandomBanker()\n",
    "    r_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # group1 banker\n",
    "    g_banker = group1_banker.Group1Banker()\n",
    "    g_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # get data\n",
    "    data = get_data()\n",
    "    # pop removes and returns the given column, \"response\" is no longer in data\n",
    "    y = data.pop(response)\n",
    "\n",
    "    return repeated_cross_validation_utility(\n",
    "        X=data, y=y,\n",
    "        bankers=[r_banker, g_banker],\n",
    "        interest_rate=interest_rate,\n",
    "        n_repeats=n_repeats, n_folds=n_folds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 1.12 s, total: 1min 55s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = compare_with_random(\n",
    "    n_repeats=100, n_folds=5, response='repaid', interest_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average utilities\n",
      "-----------------\n",
      " Random banker: 586948.126\n",
      " Our banker:    1158849.104\n"
     ]
    }
   ],
   "source": [
    "print(\"Average utilities\\n-----------------\\n\",\n",
    "    f\"Random banker: {results[0].mean()}\\n\",\n",
    "    f\"Our banker:    {results[1].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Density')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gc1bn48e/ZVe/VlqxiuTfc5W6DMc0BAwZMwASMIQkdbsjNJbnhJkCSXwqQhJgSSkI3YAgl1AAGjDG4d7nbkmzJVu+97J7fH7MSspCstbSr2fJ+nmcfjXZnZ97Z2d13z5lTlNYaIYQQ/stidgBCCCHMJYlACCH8nCQCIYTwc5IIhBDCz0kiEEIIPyeJQAgh/JxXJgKl1LNKqWKlVJaLtpeulPpEKbVPKbVXKZXhiu0KIYQ38MpEADwPLHTh9l4EHtJajwGmA8Uu3LYQQng0r0wEWuu1QHnH+5RSw5RS/1FKbVVKfaWUGu3MtpRSY4EArfWnjm3Xaq3rXR+1EEJ4Jq9MBN14GrhTaz0V+BnwhJPPGwlUKqXeUkptV0o9pJSyui1KIYTwMAFmB+AKSqkIYDbwhlKq7e5gx2OXA7/p4mnHtdYXYLwG84DJwDFgFbAc+Kd7oxZCCM/gE4kAo2RTqbWe1PkBrfVbwFuneG4+sF1rnQ2glHoHmIkkAiGEn/CJqiGtdTWQo5S6EkAZJjr59M1ArFIq0fH/AmCvG8IUQgiP5JWJQCn1KrAeGKWUyldK/RD4AfBDpdROYA9wqTPb0lrbMK4pfKaU2g0o4Bn3RC6EEJ5HyTDUQgjh37yyRCCEEMJ1vO5icUJCgs7IyDA7DCGE8Cpbt24t1VondvWY1yWCjIwMtmzZYnYYQgjhVZRSR7t7TKqGhBDCz0kiEEIIPyeJQAgh/JzXXSMQQrhHS0sL+fn5NDY2mh2K6IOQkBBSU1MJDAx0+jmSCIQQAOTn5xMZGUlGRgYdxuwSXkRrTVlZGfn5+QwZMsTp50nVkBACgMbGRuLj4yUJeDGlFPHx8addqpNEIIRoJ0nA+/XmHEoiEEIIPyfXCIQQXXpl4zGXbu+aGek9rmO1Whk/fjytra0MGTKEl156iZiYmD7v+/nnn2fLli089thjfd5WR20dXBMSEvq0ndzcXBYtWkRWlkumYT9tkgi8kDMfUGc+dEJ4mtDQUHbs2AHA9ddfz+OPP869995rclSerbW1lYCAvn2VS9WQEMIjzZo1i+PHjwOwadMmZs+ezeTJk5k9ezYHDhwAjF/6l19+OQsXLmTEiBHcc8897c9/7rnnGDlyJGeddRZff/11+/1Hjx7lnHPOYcKECZxzzjkcO2b8sFq+fDm33norZ599NkOHDuXLL7/kxhtvZMyYMSxfvrzbOB966CGmT5/O9OnTOXz4MADvvfceM2bMYPLkyZx77rkUFRUBcP/993PjjTcyf/58hg4dyooVK76zvezsbCZPnszmzZs5cuQICxcuZOrUqcybN4/9+/e3x/rTn/6Us88+m5///Od9eJUNkgiEEB7HZrPx2WefcckllwAwevRo1q5dy/bt2/nNb37DL3/5y/Z1d+zYwapVq9i9ezerVq0iLy+PgoIC7rvvPr7++ms+/fRT9u79dq6pO+64g2XLlrFr1y5+8IMfcNddd7U/VlFRweeff85f//pXLr74Yu6++2727NnD7t2720sqnUVFRbFp0ybuuOMOfvKTnwAwd+5cNmzYwPbt27n66qt58MEH29ffv38/H3/8MZs2beKBBx6gpaWl/bEDBw5wxRVX8NxzzzFt2jRuuukmHn30UbZu3crDDz/Mbbfd1r7uwYMHWb16NX/+85/7+GpL1ZAQwoM0NDQwadIkcnNzmTp1Kueddx4AVVVVXH/99Rw6dAil1Elfnueccw7R0dEAjB07lqNHj1JaWsr8+fNJTDQG27zqqqs4ePAgAOvXr+ett4zZa6+77rqTShEXX3wxSinGjx/PwIEDGT9+PADjxo0jNzeXSZO+MxsuS5cubf979913A0afjKuuuoqCggKam5tPatN/0UUXERwcTHBwMAMGDGgvLZSUlHDppZfy5ptvMm7cOGpra/nmm2+48sor25/b1NTUvnzllVditVp79Tp3JiUCIYTHaLtGcPToUZqbm3n88ccB+NWvfsXZZ59NVlYW77333knt5IODg9uXrVYrra2tgPPNKDuu17Yti8Vy0nYtFkv7dk/1/LblO++8kzvuuIPdu3fz1FNPORVvdHQ0aWlp7dVYdrudmJgYduzY0X7bt29f+3PDw8OdOj5nSCIQQnic6OhoVqxYwcMPP0xLSwtVVVWkpKQAxnWBnsyYMYM1a9ZQVlZGS0sLb7zxRvtjs2fP5rXXXgNg5cqVzJ07t0+xrlq1qv3vrFmzAE6K94UXXnBqO0FBQbzzzju8+OKLvPLKK0RFRTFkyJD22LXW7Ny5s0+xdkeqhoQQXTK75dnkyZOZOHEir732Gvfccw/XX389f/nLX1iwYEGPz01OTub+++9n1qxZJCcnM2XKFGw2GwArVqzgxhtv5KGHHiIxMZHnnnuuT3E2NTUxY8YM7HY7r776KmBcFL7yyitJSUlh5syZ5OTkOLWt8PBw3n//fc477zzCw8NZuXIlt956K7/73e9oaWnh6quvZuLEiX2KtyteN2dxZmam9veJaaT5qHCHffv2MWbMGLPDEC7Q1blUSm3VWmd2tb5UDQkhhJ+TRCCEEH5OEoEQQvg5SQRCCOHnJBEIIYSfk0QghBB+TvoRCCG6tqVv7eu/I/OGHlcpKiri7rvvZsOGDcTGxhIUFMQ999zDZZdd5tpYOnnsscd45JFHOHLkCCUlJV0OK+3KoayXL1/OokWLWLJkSZ+35QpSIhBCeAStNYsXL+bMM88kOzubrVu38tprr5Gfn/+ddbsb7qG35syZw+rVqxk8eLBLt+tqWmvsdrvLtyuJQAjhET7//HOCgoK45ZZb2u8bPHgwd955J2D8Ir/yyiu5+OKLOf/88ykvL2fx4sVMmDCBmTNnsmvXLsDo1fvwww+3b+OMM84gNzeX3NxcRo8ezfXXX8+ECRNYsmQJ9fX1gNGLOSMjo8cY8/LyWLhwIaNGjeKBBx5ov3/x4sVMnTqVcePG8fTTT7ffHxERwb333svEiROZOXNm+wBzHf3qV79i+fLl2O12HnroIaZNm8aECRO47777AGPSmjFjxnDbbbcxZcoU8vLyTuNVdY7bEoFSKk0p9YVSap9Sao9S6r+6WEcppVYopQ4rpXYppaa4Kx4hhGfbs2cPU6ac+itg/fr1vPDCC3z++efcd999TJ48mV27dvH73/+eZcuW9biPAwcOcNNNN7Fr1y6ioqJ44oknTivGTZs2sXLlSnbs2MEbb7xB2ygHzz77LFu3bmXLli2sWLGCsrIyAOrq6pg5cyY7d+7kzDPP5Jlnnjlpe/fccw/FxcU899xzrF69mkOHDrFp0yZ27NjB1q1bWbt2bXvcy5YtY/v27W4ptbizRNAK/LfWegwwE7hdKTW20zrfA0Y4bjcBf3djPEIIL3L77bczceJEpk2b1n7feeedR1xcHADr1q3juuuuA2DBggWUlZVRVVV1ym2mpaUxZ84cAK699lrWrVt3WjGdd955xMfHExoayuWXX97+/BUrVrT/6s/Ly+PQoUOAMZDcokWLAJg6dSq5ubnt2/rtb39LZWUlTz31FEopPvnkEz755BMmT57MlClT2L9/f/t2Bg8ezMyZM08r1tPhtovFWusCoMCxXKOU2gekAHs7rHYp8KI2BjzaoJSKUUolO54rhPAj48aN480332z///HHH6e0tJTMzG+Hx+k49HJX46QppQgICDipHr3jENCdh6Z2dqjqUz1/zZo1rF69mvXr1xMWFsb8+fPb9xkYGNj+nI5DTgNMmzaNrVu3Ul5eTlxcHFpr/vd//5ebb775pH3k5ua6dMjprvTLNQKlVAYwGdjY6aEUoGOFV77jPiGEn1mwYAGNjY38/e/fVgy01eF35cwzz2TlypUArFmzhoSEBKKiosjIyGDbtm0AbNu27aSRP48dO8b69esBePXVV097COpPP/2U8vJyGhoaeOedd5gzZw5VVVXExsYSFhbG/v372bBhg1PbWrhwIb/4xS+46KKLqKmp4YILLuDZZ5+ltrYWgOPHj1NcXHxa8fWW25uPKqUigDeBn2itqzs/3MVTvpPmlVI3YVQdkZ4uo2oK0S+caO7pSkop3nnnHe6++24efPBBEhMTCQ8P509/+lOX699///3ccMMNTJgwgbCwsPZx/6+44gpefPFFJk2axLRp0xg5cmT7c8aMGcMLL7zAzTffzIgRI7j11lsBo2rnwQcfpLCwkAkTJnDhhRfyj3/84zv7nDt3Ltdddx2HDx/mmmuuITMzk/Hjx/Pkk08yYcIERo0adVpVOFdeeSU1NTVccsklfPjhh1xzzTXtcxpERETw8ssvu2wWslNx6zDUSqlA4H3gY631X7p4/Clgjdb6Vcf/B4D5p6oakmGoZRhq4R6+Pgx1bm4uixYtIisry+xQ3M5jhqFWRsXYP4F9XSUBh3eBZY7WQzOBKrk+IIQQ/cudVUNzgOuA3UqpHY77fgmkA2itnwQ+BC4EDgP1QP+WRYUQfiMjI8MvSgO94c5WQ+vo+hpAx3U0cLu7YhBCnB6t9Wm3pBGepTfV/dKzWAgBQEhICGVlZb36IhGeQWtNWVkZISEhp/U8GXROCAFAamoq+fn5lJSUmB2K6IOQkBBSU1NP6zmSCIQQgNH5aciQIWaHIUwgicBHNbbYKKpuJMBqYVB0iNT7CiG6JYnAx2it2ZlfxSOrD1Jc0wTAxNRo7lwwgnPHDjQ5OiGEJ5KLxT5mfXYZr2/JIyk6hAevmMC9F46hurGVH724hV//O4umVpvZIQohPIyUCHxIfkU9H+0uZHRSJG/fNgerxagOWj4ngwf/s59nvsoht6yep66dSmiQ+7utCyG8g5QIfIRda/61NZ/IkACWTE1tTwIAgVYL9140lgevmMC6QyUsf24TjS1SMhBCGKRE4CMOFNZQXNPE9zPTCAsK6HY8oiunpvH6ljzueGUbT147lQCr/BYQwt/Jt4CPWHuohJiwQManRJ9yvYlpMVw8cRCr9xXz8zd3Y7dL5yEh/J2UCHxAXnk9R8vqWTQh+aQqoe7MHBrPsMQI/rr6IHHhgdx7UeeJ44QQ/kQSgQ/YmV9JgEUxJT3W6efcdc5wyuuaeOarHIYmRrB0ugxbLYS/kqohL6e1Zs+JaoYPiCAk0PmWQEopfrVoLGeOTORX72SxMbvMjVEKITyZJAIvl1/RQFVDC2f0cG2gKwFWC48unUx6fBi3rtxGXnn30wIKIXyXVA15uT0nqrAoGJMU1avnR4cG8s/rp3HpY+v48YtbePu2Oe19DGQmNCH8g5QIvNzeghqGJUb0qYPYkIRwHr1mCvsLa/jtB3tdGJ0QwhtIIvBiVQ0tlNY2MWJARJ+3ddbIRG4+ayivbDzGR7tltlAh/IkkAi+WU1oHwJDEvicCgJ+dP4rxKdH86t9ZVNQ1u2SbQgjPJ4nAi+WU1hISaCE5+vRmI+pOoNXCn66YQGV9i1QRCeFH5GKxF8suqSMjPhxLL+YaONWF4LnDE3hr23ESwoPJSAjvS4hCCC8gJQIvVdXQQlldM0Pd8EU9f9QAokIC+DCrALvMXyuEz5NE4KVy264PJLjm+kBHQQEWzh+XRH5FA7vyq1y+fSGEZ5FE4KXyK+oJtCqSXHR9oLNJaTEkR4fw+f4iKRUI4eMkEXip/IoGkqNDnRpkrjcsSnH2qAGU1jaTdVxKBUL4MkkEXshm15yoaiA1NtSt+xk7KIrEyGC+OFAspQIhfJgkAi9UUtNEi02TEuPeRGBRirNGJlJU3cSR4lq37ksIYR5JBF4ov8IYHC41Nszt+5qQEk14cAAbZHRSIXyWJAIvlF/ZQHCAhfiIILfvK8BqYVpGLPsLa6S3sRA+ShKBFzpe0UBKbGivOpL1xvSMOJSCjTnl/bI/IUT/kkTgZVptdgqrG0mJdu/1gY5iwoIYNTCS7XkV2GSOYyF8jiQCL5NTWofNrt3Wf6A7k9NjqWls5UiJXDQWwtfIWENeZn9hDUC/J4LRSZGEBlrZdqyCkQMj+3XfHmHLc86tl3mDe+MQwg2kROBl9hdWY1GQGBHcr/sNsFqYmBbN3hPVNLbY+nXfQgj3kkTgZfYX1JAYGUyAtf9P3aS0WFrtmn0F1f2+byGE+0gi8DL7C2sYGNW/1UJtUmNDiQoJYM8JSQRC+BJJBF6kurGF45UNJJuUCCxKMW5QNAeLamhqleohIXyFXCz2IgdMulDc0biUKNZnl3GwqJbxKdGmxdFvDn4Me/8NhVmggLSZkDga+qkPhxD9QRKBF2lrMWRW1RBARnw44cEBZB2v8u1EUHEUProHDv4HwuLBEggt9VCwE2IGw4SrISrZ7CiFcAm3JQKl1LPAIqBYa31GF4/PB/4N5Djuektr/Rt3xeMLDhfVEBEcQHRooGkxWJRibHIUO/MrabHZTYvDZbpqFlpfDl8/Aq2NMOYSGHImWALA3gp5m+DgR7DhMZh5O0QN6v+YhXAxd14jeB5Y2MM6X2mtJzlukgR6cLiklmEDIlAmV0ucMSiK5lY7h31xRNLmOtj0JNhbYO7dMGyBkQTA+Dt4Nsy6C1QAbHgcqgvMjVcIF3BbItBarwVkcBoXOlRUy/BE109NebqGJkYQGmj1vQlrtB22PAv1ZZD5I4jspuonIhFm3QHKClv+Ca1N/RunEC5mdquhWUqpnUqpj5RS47pbSSl1k1Jqi1JqS0lJSX/G5zGqG1sormlixEDzE4HVohiTHMm+wmqaW32geqhNzldQfgQmXAXxw069bkQiTFlmJI19/+6f+IRwEzMTwTZgsNZ6IvAo8E53K2qtn9ZaZ2qtMxMTE/stQE/SVg3jCSUCgHGDomlssbMxx0fmKWiogAMfQuIYSJnm3HPih8PQ+XD0Gyje687ohHAr0xKB1rpaa13rWP4QCFRKJZgVj6c7XORIBAM8IxEMHxBBoFXx2b5is0PpO60h601Aw/glp9c0dNSFRhXSrlVSRSS8lmmJQCmVpBxXPZVS0x2x+MjPS9c7XFJLUICFtDj3z0rmjECrhWGJEazeV4T29vmMS/ZDURaMXGg0FT0d1kAYfyU0VkHOl+6JTwg3c1siUEq9CqwHRiml8pVSP1RK3aKUusWxyhIgSym1E1gBXK29/hvFfQ4X1zI0IRyrxXM6Mo1OiiK/ooFD3tx6SGs48BGExhrNRHsjbigkTYDDn0GtD5SQhN9xWz8CrfXSHh5/DHjMXfv3NYeKa5iYGmN2GCcZnWQMR716X5H3Dk1dvAeqjhkdxCx9+DiMXmSUKtb8ERb9xXXxCdEPzG41JJzQ2GIjv6KBYR5yobhNVGgg41Oivfc6gd1ulAbCEiDVyQvE3YkYAIPnwNbnoTzbJeEJ0V8kEXiBY+X1aA1DE8PNDuU7FowewLZjFZTVeuGF0gMfQPVxGHkBWKx9397w84xSxbpH+r4tIfqRJAIvkF1SB8CQBM9LBOeOGYjW8MUBL+vfobXxhR0WD4OmuGabIVEw5TrY8QpUn3DNNoXoB5IIvEBOqZEIMjwwEZyREsXAqGA+319kdiinJ28jHN9i9ANwRWmgzey7jB7K3zzqum0K4WaSCLxATmktCRHBRIWYN9hcd5RSLBg9kLUHS72rl/E3jxothVKnu3a7sYNhwveNawV1pa7dthBuIonAC+SU1jHUA0sDbc4dM4Daplbv6WVcehj2fwDTfgQBbpj7ec5PjCGrtzzr+m0L4QaSCLxATmmdR14faDN7WALBARbvaT204QmjI9j0m9yz/QGjjVFLtzwLthb37EMIF5JE4OGqGloorW1miAe2GGoTGmRl7vAE7+hl3FAJO181egNHDHDffqbfDDUFsO9d9+1DCBeRRODhcks9t8VQR+eMGegdvYy3v2xU28y42b37GXEexGbApmfcux8hXMCpRKCUelMpdZFSShJHP2trMeTJ1wgAzhlj/Lpevc+DWw/ZbbD5GWPe4eSJ7t2XxWpcgzi2Hgp2uXdfQvSRs1/sfweuAQ4ppf6olBrtxphEB9mldSgF6fGeMdhcdwZGhXh+L+NDn0JFLsxw07WBziZfC4FhsOmp/tmfEL3k1OAqWuvVwGqlVDSwFPhUKZUHPAO8rLWWK2JuklNaR2psKMEBLmzr7iYLRg9gxeeHKKttIj7CDa1x+mrTU8aQ0WMucd8+Os+BnDwRdq4y5jkI6lCqy7zBfTEIcZqcrupRSsUDy4EfAduBvwFTgE/dEpkAjGsEQxI8a4yh7nh0L+PSQ3Dkc8i80Wgx1F8y5hnzHx/b0H/7FOI0OXuN4C3gKyAMuFhrfYnWepXW+k7AO76lvJDW2uP7EHTk0b2MNz0N1iCYurx/9xs1yJjJ7Og6o8exEB7I2XF3/+GYRaydUipYa92ktc50Q1wCKKltorap1aNbDL2y8dhJ/6fHhfPZvmJeXJ9LgMXCNTPSzQmso8ZqY/yfcZe7t8lodzLmwdbnjGGqkyb0//6F6IGzVUO/6+K+9a4MRHxXjgcPNted0UmRNLXa22P3CDtfheba/rtI3NnAMyAkBnLXmbN/IXpwyhKBUioJSAFClVKTgbbpsaIwqomEG+V4SR+CjoYPiCAowELWiWpGmDVZTccLttoOax+CmMFGM04zmnJarDB4Nhz40JjBzIxSiRCn0FPV0AUYF4hTgY7TLtUAv3RTTH6vrbrlo6wCAiyKLw+WYDmdCdVNFGi1MDopkj0nqrhk4iCzw4Hi/VBXApOuNTeOtBlw8D9Gv4Kxl5obixCdnDIRaK1fAF5QSl2htX6zn2ISDqW1zcSFB3lNEmgzPiWaXflV7SUaU+WsgZBoGDTZ3DhCoiFpvDH89agLzY1FiE56qhq6Vmv9MpChlPpp58e11jI5qxuV1jaR6Int8XswcmAkQQEWdh+vMjeQqnwoPQijL3btnAO9NXgOFOw0bkJ4kJ6qhtoqp6WJaD+za015bTNjkrxvUviO1UOtNjsBVpNGJsn50mgymj7LnP13Fj8cwhPh2DdmRyLESXqqGnrK8feB/glHtKmsb8GmNQleWCKAb6uHNmSXM3dEQv8H0FgFx7cZv8KDPKRdg7IYSWnfu1C0FwaONTsiIQDnO5Q9qJSKUkoFKqU+U0qVKqVMvvrm20odk8F75FANTmirHvpgd4E5AeR+ZbQYGnKmOfvvTtp0o5pq63M9rytEP3G2zH6+1roaWATkAyOB/3FbVKI9ESREBJkcSe+0VQ99vKeQVls/96htbYKj3xidt8JNKI2cSlAEJE+Cna9BswdcTBcC5xNB2+AsFwKvaq3L3RSPcCitbSI4wEJEsLOdvz3P+JRoyuuaWZ/dz1NY5m8y5hwYOr9/9+uswXOgqRqypCGe8AzOJoL3lFL7gUzgM6VUItDovrBEaW0zCRHBKC9rOtrRyIGRRAYH8Pb24/23U7sNsr80OpDFDem//Z6O2CGQOPq7I5UKYRKnEoHW+hfALCDTMeR0HSC9YtyotLbJa6uF2gRaLSyamMx/sgqpa2rtn50e+BDqS2Ho2f2zv95QyhgF9cQ2OLHd7GiEOK2pKscAVymllgFLgPPdE5Josdmpqm/x2hZDHS2Zmkp9s40P++Oisdbw1Z8hLN7ovOXJJlwFAaFSKhAewdlWQy8BDwNzgWmOm4w66iZldc1o8IlEMCU9liEJ4fxra777d3Z4tfELe/i5ntGB7FRCY2D8FbD7X0ZTVyFM5OyVyExgrNZauzMYYSitaWsx5P2JQCnFFVNSePiTg+SV15MW14c2/af69aw1fP0IhMZC6rTe76M/Zd4I21+GXa/D9B+bHY3wY85WDWUBSe4MRHyrrK4ZgHgvv0bQ5rIpqSgFb25zY6mgZD9UHnWUBrykpdWgKUYT1y3PGYlMCJM4mwgSgL1KqY+VUu+23dwZmD8rrWkiMjiAkEAPr95wUkpMKLOHxfPmtnzsdjd84WkNhz42xvxPm+H67btL20Xj4j2Qv9nsaIQfczYR3A8sBn4P/LnDTbhBSW0TCZHeXy3U0RVTUskrb2Bzrhu6oJQehIpc7yoNtBm/BIIiYcuzZkci/JizzUe/BHKBQMfyZmCbG+Pya0bTUd9KBAvPSCIiOIDXt7i4eqi9NBANaTNdu+3+EBwJE74PWW9BvfTTFOZwttXQj4F/AU857koB3nFXUP6soq6Z+mYbiT5yfaBNWFAAF08cxAe7T1Dd2OK6DZcdhvJsGHYuWL2sNNAm8wawNRlTagphAmerhm4H5gDVAFrrQ4DMt+cG2aW1AD5XNQSwdHoajS123t1xwnUbPfgfCI6GdC8sDbRJGm+0dJKLxsIkziaCJq11c9s/SqkAQN6xbnDEMem7N05I05PxKdGMSY5i1eY812yw7DCUH4HhC8Aa2PP6nizzRig7JBPcC1M4mwi+VEr9EmMS+/OAN4D3TvUEpdSzSqlipVRWN48rpdQKpdRhpdQupdSU0wvdN2WX1GFVipgw36oaAqNPwdXT0th9vIosV8xedvBjCI7ynIln+mLcZcZ1ji3/NDsS4YecrVT9BfBDYDdwM/Ah8I8envM88BjwYjePfw8Y4bjNAP7u+OvXsktqiYsIwmrx3sHmOnpl47GT/m+1aQIsit99sJdLJqYAcM2M9NPfcNkR4xf02MXGLGTeLjAUJl8HG5+E6gKISjY7IuFHnG01ZMe4OHyb1nqJ1vqZnnoZa63XAqdqBnEp8KI2bABilFJ+/+7PLq3zyWqhNqFBVs5IiWZHXiUtfZmn4NDHxtj+g2e7LjizTfuhMXqqNCUV/aynyesVcB9wB6Acd9mAR7XWv+njvlOAjpXF+Y77TJrSynytNjtHy+qYNdTDJlNxsczBsezIqyTreBWT02NPfwMVOUbfgTGXeG9poLvhMgaMgQ1PQPiAb1tBZd7Qf3EJv9RTieAnGK2Fpmmt47XWcRjVN3OUUnf3cd9d1X10WcpQSt2klNqilNpSUlLSx916rvyKBlps2uuHn+7JkCP8vzAAACAASURBVIRw4sOD2Jxb0bsNHPoUAsONCV58TcY8aK6Fgh1mRyL8SE+JYBmwVGud03aH1jobuNbxWF/kA2kd/k8FumxXqLV+WmudqbXOTExM7ONuPVdb09FEH2w62pFSisyMOHLL6toH2HNaVR4U7zVmHwvwwdcpcRSEJxpzLgvRT3pKBIFa69LOd2qtS/h2+sreehdY5mg9NBOo0lr7bbUQGC2GwDdGHe3JlPQYLAq2HD3N3rSHPoWAEMiY657AzKYsxrFVHoXKYz2vL4QL9JQImnv5GEqpV4H1wCilVL5S6odKqVuUUrc4VvkQyAYOA88AtzkZs886UlJHTFgg4V48T7GzIkMCGZ0UxdZjp3HRuKYACnfBkDONVja+KnUGWIOlVCD6TU/fOBOVUtVd3K+AkFM9UWu9tIfHNUaPZeGQXVLL0IRws8PoN1MHx7K3oJqvDpWwYPTAnp9weLVxcXjIWe4PzkyBIUZP47z1MEZmhBXud8oSgdbaqrWO6uIWqbX28q6cnie7tI6hiRFmh9FvRgyMICzIytvbnRhyouwIHN8Gg+dCkB8ky4y5RlPSY+vNjkT4gdOZs1i4UU1jCyU1TQxN9IMvOYcAi4XxKdF8sqeQmp4Golv3V2OI6aHz+yM080UmQcJIOPo12FrNjkb4OEkEHqLtQvHQBP8pEQBMTo+lqdXOf7IKu1+pMs8YmTN9JoRE9V9wZss4ExorYZ/MASXcy/evSnqJtqajwxLDKa875XV4n5IWG0pceBB///IILbauO6tfU/YYoGDYgv4NzmwDx0JYgtHB7IzLzY5G+DApEXiI7JI6LArS4/swubsXUkoxKS2GnJI6qhq+Wz0U2FIF218yJm8J7UUvZG+mLDD0LGMay7xNZkcjfJgkAg9xpKSW9LgwggN8Y57i0zE5LQYN7Myr/M5jw/LehpZ6mHlr/wfmCVKnG6OSrn/c7EiED5NE4CEOFNYwcmCk2WGYIj4imLTYUHZ0SgTK3sqoo68Ywy4kjTcpOpMFBMPUG4zrBBVHzY5G+ChJBB6gqdVGblm93yYCgEnpsRRWN1JY3dh+X2rR54Q3FsBMP+9rOP0mo5po09NmRyJ8lCQCD5BTWofNrhkx0L9aDHV0xqAoFJw0Yc2ooy9TE5YGIy8wLzBPEJ1iTFyz9QVo7Kp/pxB9I4nAAxworAFgVJL/lggiQwLJSAhntyMRxFVmMaBiOwcG/wAs/nfd5Dtm3gbNNbD9ZbMjET5Imo96gENFtVgtiiF+NLxEV85Iiea9nScoqm5kdu5LNAdEkJ26mEyzAzNb29wFcUNh7UPGdQPVxW84mbdA9JKUCDzAgaIahiSE+2WLoY7aqofyjh4hvfATslMvozXAv5PjSYbMh4ZyKNxtdiTCx0gi8ACHimoY6cfXB9pEhgQyOD6c8SdeB23nwOBrzA7JsySdAWHxkL3G7EiEj5FEYLLGFhtHy+sZMcB/rw90NGVQMJfaPuFI3JnUhaWaHY5nURZjCO6KHKjINTsa4UMkEZjscHEtWvv3heKOLrWsI07V8lbQJWaH4pnSZhgT8+R8aXYkwodIIjDZwSKjxZBUDQFaM/H4qxy0DOXN0nSzo/FMASGQPgsKdkJDL+d8FqITSQQmO1BUQ6BVMTheLoomla0npvYIGwd8n+LaZoo6dC4THQw50/ibs9bcOITPkERgskNFtQxLjCDQKqdiVO7LNATF0zByMQrYc6Kqx+f4pdBYSJ5oTFrT0mB2NMIHyLePyQ4W1TDCj4eWaBNZm0NKyVccSr+KiPBw0uPDyDouvWi7NewcaG00Jq4Roo8kEZiorqmV/IoGRsn1AUYdXYlNBXIo/fsAnDEomsLqRkprmkyOzENFp0LiaOOisc1/5q8Q7iGJwESHio3JaPy9RBDYUsXQ4++SO+gimoLjARg3yJiJLEuqh7o3/FxoqpG5CkSfyRATJjpY2NZiyL8TwYzd9xNga6A+ZADDjr3Rfv+I8MEczDkKW6QnbZfihkHMYMj+wmhJJEQvSYnARAeLaggOsJAe51+zknWk7K0MLN9EVXgG9SFJJz02I7aG3IYQjtb699Ab3VLKKBXUl0HBDrOjEV5MEoGJDhTVMGJgBFaLMjsU06QWfUZwSzWFcTO+89iMGKPE9NHx4P4Oy3sMHAcRSXB4Neiu53wWoieSCEyitWbPiWrGJkeZHYqpRue+TGNQLJWRI77z2IDgFoaFNfBRviSCbikLDF8ANQVw6BOzoxFeShKBSYqqmyiva2bcoGizQzFNfOVuEit3UBg3vethlTGqh3ZWBJJfJ2/Vbg2aavQtWPdXsyMRXko+XSbZW2C0hhk7yH9LBKNyX6Y5IIKSmEndrjMj1qge+o9UD3XPYoWhZxsdzI5+Y3Y0wgtJIjDJHkdnqTF+WjUU2ljUPueA3dr9l3xScAvjYlr4MD+kH6PzQukzIXwArPmD2ZEILySJwCR7C6rJiA8jItg/W/COOLbK6TkHLkxpYlt5IAX18nbtljUI5t5tjD+U85XZ0QgvI58sk+wtqPbb6wPW1npGHHud4wPPdmrOge+lGr2LpXqoB5k3GC2I1vxBWhCJ0+KfP0dNVt3YwtGyer6fmWZ2KG7VsXNYRwPLNhPcUkV1WHq363Q0NNLG6OhW3ssL4YYRMshatwJDYd5/w0f/Yww9MXS+2REJLyElAhPsPWFcH/DLpqPaTlLZBmpCU6kNcz4RXprWyLbyQI7Vylv2lKYsg6hUWP2AlAqE0+RTZYLd+UaLoQmp/lc1FFe9n5CWCgoSZp/W8y5NN+YmeOeYXDQ+pcAQOPuXcGIb7Hnb7GiEl5BEYIKd+ZWkxIQSH+Fndd5ak1z2DY1BcVREjjytpw4KszMzsZm3j4XID92eTLwaBoyDzx6AVhmZVPRMEoEJduVX+WVpILL+GBENJyiIn9ltB7JTuSy9kZzaALaXy6WtU7JY4bwHjAnutzxrdjTCC0gi6GeV9c0cK69nQmqM2aH0u+Sy9bRYwyiNmdir51+Y2kSoVfN6bqiLI/NBw881prRc8weoKzM7GuHhJBH0s11+en0gpKmU2JqDFMVlYrcE9mobkYGaRWmNvHssmNoW/x2ozylKwfceNOYr+Ox+s6MRHk4SQT/bfdxIBGek+FciSC5dj10FUBQ3rU/buXpIA/U2C+/LQHQ9GzAGZt4K216C/K1mRyM8mFsTgVJqoVLqgFLqsFLqF108Pl8pVaWU2uG4/dqd8XiCnXmVDEkIJzq0d7+KvVFAay0JVbsoiZlIa0B4n7Y1Ja6VkVGtrMwOlYvGzjjr5xAxED74KdhazY5GeCi3XXVTSlmBx4HzgHxgs1LqXa313k6rfqW1XuSuODyJ1pptxyqZNyLB7FD6VXLZBpS2URg/s8/bUgquG9bAr7ZHsq0sgKkJ8uXWbstzXd8/8gLY9gK8sRyGn2P0QBaiA3c2v5gOHNZaZwMopV4DLgU6JwK/kV/RQGltEza75pWNx8wOp19YWxsYWL6FsqhxNDrmI+6rKwY38FBWOM8eDmNqQrVLtunTkidB0nY4+JExkY0QnbizaigFyOvwf77jvs5mKaV2KqU+Ukp1+S5VSt2klNqilNpSUlLijlj7xdajFQB+NTVlUvlGrPZmTiTOddk2wwJg6RBjwhqZp8AJSsH4K8EaDDtfkSoi8R3u/BR11ayjc63uNmCw1noi8CjwTlcb0lo/rbXO1FpnJiYmujjM/rPtWAVBARYGRvlH71irrYmksk2UR46iIWSgS7e9bHgDFgVPH/SfpNonwZEw/gqoPAZf/snsaISHcWciyAc6DiaTCpzouILWulprXetY/hAIVEr5bAX61qMVpMaG+s0cxQPKNxNgb+RE4jyXbzslzM6SjEZeywmlsEFKBU4ZNAVSp8PahyB7jdnRCA/izk/QZmCEUmqIUioIuBp4t+MKSqkkpZRyLE93xOOTvV/qm1vZX1jjN9VCVlsDyWUbqIwYRl3oILfs4/bRddg0PHnAP15TlzjjCkgYAW/+GGqKzI5GeAi3JQKtdStwB/AxsA94XWu9Ryl1i1LqFsdqS4AspdROYAVwtda+2ShwR14lNrtmsJ8kguF5bxJoq+d4gutLA23Swu1cMbiRV7JDyZNrBc4JCIYrnzc6mr1+HbQ2mR2R8ABu/fRorT/UWo/UWg/TWv8/x31Paq2fdCw/prUep7WeqLWeqbX22QlXN2aXY1EwOL5v7ei9gcXWzJjs56gOG0xteLpb9/XTcXVYFDyYFeHW/fiUgeNg8ROQtxHe+y8ZrlpIz+L+sjGnjLGDoggJtJoditsNPf4OYU3FHHdhS6HuJIXauWlkPe/lhbC1TAajc9oZl8P8/4Wdr8LXj5gdjTCZfHL6QVOrje3HKrl25mCzQ3E7i62Zsdn/pDR6PNXhQ/tlnzePquf13BDu3RbJe+dUECg/b06treNZ+AAYNNmYxKYyD5LGn7yedDzzG/KR6Qc786poarUzY0ic2aG43bD8t4hoOMGuEXcY7df7QXiA5v5JNeyvCuTZQ/5xDcYllIKJSyE6Dba/BNXHzY5ImEQSQT/YmF2GUjDdxxOB1dbIuCNPUxw7hcKEWf267wsGNXNuchN/2RPOoWrfr35zGWsQTPuhMd/xpmegscrsiIQJpGqoH2zIKWN0UhQxYUFmh+JWI46tIqyphK8nPejS0sDGnPIe15kxJI7fT61h4Sdx3LUxincWVBAs+cA5IdEw7cfwzQrY/A+YdYfRukj4DSkRuFlji43NuRXMGeaacXY8VUBrPWOP/JOC+FmUxGWaEsOAEDsPZlazryqQh6UV0emJTjUmvq/KN6qJtN3siEQ/khKBm23KKae51c68kd47NIYzRh5dSUhLBbtG3mHK/ttKDZHAeYmaZw7FMoBSJkTVt6/jD9do+mTgGTBusTHp/b53jSoj4RekROBmXx0qIchqYXqG734JBbZUMzb7OfIHzKcsZoLZ4XBdajEpIU08njOIyhapHzotQ86CjHnGEBSb/2F2NKKfSCJws68OlTJtSCyhQb77hTQ650WCWmvYNeJ2s0MBINii+a8hJ6i3WXgkO4VW6S91esYuhgFj4cN74NBqs6MR/UASgRsVVzeyv7CGucN9t1oouKmc0bkvcTTpfCqjRpsdTrvBYU3cNLiQfbVhvJI/wOxwvIvFClOuh4FjjclsCrPMjki4mSQCN/ryoDF3gi/PSDb+8BNY7U3s9pDSQEfz4qu5ILGCD4rjWF8eaXY43iUgGJauguAIeOX7UF1gdkTCjSQRuNHqfUUkRYUwblCU2aG4RVTNEYbn/YvDaVdSHdE/vYhP17LUIkaG1/P3o8nSv+B0RafANaugoRJeuwZaGsyOSLiJJAI3aWyxsfZgKeeOHYDqpx62/W3KgYdptYaxe8RtZofSrQAL3D30BCEWOzevj6amxTfPhdskT4TLn4YT2+DdO2WAOh8licBN1meX0dBi49wxrp2Zy1Mkl3zNoJJ1ZA2/maagWLPDOaW4oFZ+MvQ4R2ut3L0pCpt8l52eMYtgwf/B7jdkgDofJYnATVbvLSIsyMrMob7XkUzZW5m8/2FqwtI4mL7U7HCcMjaygV9PrGV1QTAP7vb9ocBdbt7PjEltVj8ABz4yOxrhYpII3MBm13y6t4gzRyT65LDTw/LfIqb2MNtH/RS71XuGzVg2rIFrh9bz1MFw3sj1j3mjXUYpuOQxo6rozR9B8T6zIxIuJD2L3WBTTjnFNU1cNCHZ7FBcbmTOy0w89CjVYekEN5Uz7NgbZofkNKXgvkm15NQG8MutkQwOtzE9scXssLxHUBhc/Qo8cza8ejX8+AsI892Okv5EEoELvbLxGADv7DhOoFVRVtvcfp+vGFTyFYG2evYnnd9vw0y7UqAFnphZxWWfx/Kjb6JZdVYFY2JsZoflPaJT4KqV8PxF8PoyuO5tsAaaHZXoI0kELmaza7KOVzE6KYqgAN+qeYuuOUhS2QaKYyZR76YJ6ftDdJDmxXmVLFkTy7J1Mbx2ViXDIiUZfEfbBDZdGb8EdqyEFxcbyzKJjVfzrW8qD3CkpJb6ZhsTU6PNDsW1tJ3pWb/BZg0hb+C5ZkfTZ6nhdl6aV4nWiqvWxHCgyveu5bhV6jQYugCOroOjX5sdjegjKRG42NajFYQGWhkx0Ld6sg7Le5PEyp0cSbmU1gDvnAWsq3kN/ndYFb87lMZln8fw1Oxq5g089TWDnuZG8KsRTscsgtpCyHrTGJJiyDyzIxK9JCUCF6pvamVvQTWT0mMItPrOSxvWUMjkA3+lKG4apdHmjy7qSqmhzfx21FHiA1tYvi6GFXvDaJWh+J2jLDD5OghPhNevg/JssyMSveQ731YeYHteJTa7JnOwZ3ewOi1aMyPrPiy6lY1nPOCVF4h7khjcym9HH2NRahN/2RvB5V/Esq1MCstOCQyFaT8yll++AmpLzI1H9IokAhfRWrM5t5zU2FCSo0PNDsdlhue9QXLpN2wb9d/UhqeZHY7bhFrt/G1GNStmVFHYYOHyL+JYvi6ab4oDZVSFnoQnwjWvGwPTrVwCTTVmRyROkyQCF1l3uJTimiafqiOOrM1h8v6HKYifxeH075sdTr+4JK2Jzy8o57/H1ZJVEcg1a2O55PNY3j4aTJM0LOpe2nS48nko3A2vLoXm+h6fIjyHJAIXeearHCKDA5iYGmN2KC5htTUwd8d/Y7MEs2H8b3yySqg7EYGaO8fUs+7CUn4/pZq6FsXdm6OZ82ECq44nUN0qLYy6NGohLP475K6D15bKaKVeRBKBCxworGHtwRJmDosnwEcuEk/d+0diaw6xfuIfaAhNMjscU4RY4Zqhjay+oJwX51YyMa6FtwvjuWv3UN4siKfR5j/J0WkTr4LFT0D2l8bQ1c11ZkcknCBXxFxgxeeHCAuyMsOL5yXuOFREYvk2hha8z/GEuYQ1FHjVMBLuYFFwZlIzZyY18+beWl47kcjrJxL5uDiW69OKmB1b408Fpq517nw28WrY+Ro8MQum3wRBjoH+pOOZR/KNn68myjpexQe7CvjR3CGEBXt/Xo2qPcKQgg+ojBhG/oD5ZofjcVJDm/nZsOP8dlQuicEtrMhJ4ZGcQVJd1FnaDJh6A1Qfh29WQF2p2RGJU5BE0Adaax78+AAxYYH86EzPnKHrdIQ2FjMi7180BCdyOHWJ0U5cdGlkRCO/HXWUpSnFbK6M5Gd7hrCjSoa3PknyBJh+MzRVw7q/QOlBsyMS3fD+n7Am+nhPEWsPlvB/F40hKsS7B94KaSpl9NGXsFsCOZC+FJs12OyQ+l1PvYY7syhYnFTOpKg6HstJ5g+H06gOqOPusXX42DBTvZcwAub+FLb8Ezb8HULjYO7dYJWvHk8ib9deqmls4f539zAmOYrrZ2eYHU6fRNbmMCb3RZSGfRnX0RzkY+MkuVlGWBP/b8xRFiRU8vj+cK5ZG0NRg3y02oUnwpyfwKDJ8MXv4LnvQdkRs6MSHci7tRe01tz/7l6Kahr5w+XjvXo4iYSK7Zy34XqU1uzLWEZjcKLZIXmlYIvm5sGF/HVaFVkVAVy4Oo61hd4zaY/bBYTAlGVw+T+g5AA8MRM++420KvIQ3vsNZqJVm/N4c1s+dy0YwaQ07+03kHH8Pc7Z+EOaA6PYO2Q5DSGSBPrqssFNvHtOBQnBdq5fF83DWeEydlFHE66E2zfCuMvgqz/D3ybB13+T3sgmk0Rwmr46VMKv/72HeSMSuOucEWaH0yuBLVXM2vkLZu/6JaWxk/hk1koag31vbmWzDI+y8c6Ccr6f0chj+8O54otY9lVKq6J2Uclw+dNw4ycwcCx8+mv4yzh47yeQtwnskjn7m1yxOQ3rj5Rx04tbGZoYzqNLJ2O1eFfjcaVtDD7xIZMOPEJIcxm7h99K1rAfoy3efaHbE4UGwJ8ya5g7sJn7d0Sy6LM4rh7SwH+NqWdAqHzRAZA+A5b9G/K3wsYnjX4HW58zrikMWwDps2DQJEgcA4Eyx7Q7SSJwgtaa1zbn8et/Z5EeF8ZLP5xBTJj31P9abY2kFX7K2Oxniak9THnUGNZOXUF59DizQ/N5F6c1MXdAM4/sDWdldihv5IayOL2RxemNzEhswepdvyX6rrtZzwbPhkFToGg3FO+H/e/DrlXfPh4cBWHxRqujsDjjb2gMTPshRKVAcET/xO+jlPayoRUzMzP1li1b+m1/x8rquf+9PXy+v5h5IxJ47JopRId2/Qvak+YnDmquZGDZRgaVfk1a4WqCWmuoCs9g94jbOZZ0/nf6CPh772FXOdWgg8dqLTxzKIx/5YbSYFMkBNs5b1AT0xJamBDbwtBIG15WyHQfraG+DKryobYIGsqgvsK4r7ESdKdSVWgsRKdCzGCIGwrxw4y/ccMgMhksUguulNqqtc7s6jG3lgiUUguBvwFW4B9a6z92elw5Hr8QqAeWa623uTMmZ9jsmg3ZZbyxJY/3dhUQZLXwfxeNYfnsDFPHElLaRkBrLUEttQS21hDUUkNQazWBLTUEt1QR3lBARH0+MTUHCW8sAKA5IJITifM4nLaE4rhMvxo8zgw99UVYFAPnjlfsqI5gQ0Ukbx8N59UcY9jyEIuNpOAWBgY3M2mAlfQIG2lhdpJCbSSF2YkM0P5z+pSC8ATj1pndZnRSa6iA5IlQlWckjKp8KDsMhz4FW9O36weEOpKDIzHEDzP+xqRDSDQERfh9onBbiUApZQUOAucB+cBmYKnWem+HdS4E7sRIBDOAv2mtZ5xqu30pEWitabbZaWq109Rip6nVRmV9CyU1TRTXNHKsvJ69J6rZkltBTVMrEcEBXDUtjR/PG0pSdM91lK9sPAbajtI2lNYobCjH/1Z7M1ZbIwG2RsffBqz2RgJaGwhsrSWotYbAlhqCHF/wgV38H9Rae8r92yxBNAXGUB8ygPqQgdSEpVEbmio9hD2YXcPxxiCO1IWSUx9MUVMQRU2BlLYE0Ww/+Vs/zGonKcxOcqidgaE2kkLsxIfYiQnSxATaiQmyExmoCbZCkEUTZNUEWRzLFj/6DaDt0FAJdSXf3upLwdYC5Tlg7zwdqYKQKKP6SVkcLZgc34taf7vcWaCjJ7k1wFgOartFdFgOh+BI477gCMffTv9bg8ASANZAsFjBEvjt/8p1J86sEsF04LDWOtsRxGvApcDeDutcCryojWy0QSkVo5RK1loXuDqYD3YVcPsrpy5sBFgUQxPDWTRxEPNGJLBg9ABCAnto7fHipXD0G7DbuEb3bcB6jaIlIILmwCiaAyJpCYykNizVuC8gipbASJoDImkOjCS+cjc2azCtlhBs1hBaraHYLMF+9Gn3DRYFaaHNpIU2M7/D/ZkZcRQ1WMivs1LYaKGowUJBvZXCBguFDVY2FAdR1GjBpk/vfCs0CnjlrEpmJp56fmavpSzGdYSwOEgc9e39mTcYpYmqPKNDW1W+UbJorIbGKmNZ243HlAIUKIy/dPE6JzhaDdpaoKXO6BPRXAf15dBc67jVQUsf52awBH77uZ59F5zzq75trwvuLBEsARZqrX/k+P86YIbW+o4O67wP/FFrvc7x/2fAz7XWWzpt6ybgJse/o4ADLgozAfC30bDkmP2HPx63HHP3Bmutu+ws5M4SQVc/VTpnHWfWQWv9NPC0K4I6aedKbemuqOSr5Jj9hz8etxxz77iz8jgf6DjJbSpwohfrCCGEcCN3JoLNwAil1BClVBBwNfBup3XeBZYpw0ygyh3XB4QQQnTPbVVDWutWpdQdwMcYzUef1VrvUUrd4nj8SeBDjBZDhzGaj/b39EUur27yAnLM/sMfj1uOuRe8rkOZEEII15IG5kII4eckEQghhJ/z+USglFqolDqglDqslPpFF48rpdQKx+O7lFJTzIjT1Zw47vlKqSql1A7H7ddmxOlKSqlnlVLFSqmsbh73uXPtxDH74nlOU0p9oZTap5Tao5T6ry7W8alz7eQx9/5ca6199oZxkfoIMBQIAnYCYzutcyHwEUafhpnARrPj7qfjng+8b3asLj7uM4EpQFY3j/viue7pmH3xPCcDUxzLkRhD2fj059rJY+71ufb1EkH7MBda62agbZiLjtqHudBabwBilFLJ/R2oizlz3D5Ha70WONWobz53rp04Zp+jtS7QjsEptdY1wD4gpdNqPnWunTzmXvP1RJAC5HX4P5/vvnjOrONtnD2mWUqpnUqpj5RS/jA5gS+ea2f47HlWSmUAk4GNnR7y2XN9imOGXp5rX5+YxmXDXHgZZ45pG8bYI7WOUWDfAbxz7k3n+eK57onPnmelVATwJvATrXV154e7eIrXn+sejrnX59rXSwT+OsxFj8ekta7WWtc6lj8EApVSXQz+7lN88Vyfkq+eZ6VUIMYX4kqt9VtdrOJz57qnY+7Lufb1ROCvw1z0eNxKqSTHxEAopaZjvBfK+j3S/uWL5/qUfPE8O47nn8A+rfVfulnNp861M8fcl3Pt01VD2juGuXA5J497CXCrUqoVaACu1o6mB95KKfUqRsuJBKVUPnAfEAi+e66dOGafO8/AHOA6YLdSaofjvl8C6eCz59qZY+71uZYhJoQQws/5etWQEEKIHkgiEEIIPyeJQAgh/JwkAiGE8HOSCIQQwoP1NLBgF+t/Xym11zE43SvOPEcSQR8ppS5TSmml1GizY+ktpdRipdTYDv//Ril1rmN5jVIq07H8oVIqxnG7zax4naWUWq6UesyxfItSapljebRjdMbtSqlhSqm7HKM6rnRzPL905/Y77av9vLlwmxlKqWt6+dxvnFxvqVLqXsdImrN7uS+n41RKPa+UWtKb/fSj54GFzqyolBoB/C8wR2s9DviJM8+TRNB3S4F1GJ22+kwpZXXFdk7TYqA9EWitf621Xt15Ja31hVrrSiAGMD0RnM5rpbV+Umv9ouPfxcC/tdaTtdZHMI7lQq31jJN27wAACQdJREFUD5zcb2/73ziVCEx6DzgjA+jyC7an10Rr7eyX+kLgPxh9I3qVCDhFnM7ypHPQ1cCCjh8w/1FKbVVKfdXhh+iPgce11hWO5xY7uxO59X5o2AjgODAS2O+473vA6x3WmQ+851g+H1iPMSbIG0CE4/5c4Nd8m1B+jNE7eCdGl/Iwx3rDgA2Ox34D1HbYz/847t8FPNBNvB3XX4LxS2O2402WA+xw7ON5YIljvTVAZoc4EzBGM21wrP8Q8BJwaYdtrwQu6bRv5Vg3C9gNXOW4fxXGl3Dbes8DV2B0hHuowzHd3OH1/AJ4BdjbxTHegDFE75fAM8BjjvvvB36G0cmo0HHevgCeBJodMd0NhAPPOva7ve24gOWOc/Ye8HkP672F8WV2CHjQcf8fAZvjNVvZ1blxnNONwFzH+2Gz4/V6mm/7/KwB/gRschznPMf9oY7zssvxmm7scN6WOo4vC/hTp33+CdgKrMYYtXYNkN35/DnW3wBUOY7h7i5ekwjgM4z39+5O74naDudvDfAvYD/Ge0V1eI/sBIZ0OEc7gHlAIsZnYbPjNsfxnLMc6+xwnIfIznF28T58DNgLfIDR8aztvZ5LD59DjPdltmM7MYAdONPx/K+A4V3F5ILvmgw6DDXueJ1HOJZnAJ87lt8BHgS+drwOC53avtlfpt58A64F/ulY/gZjXPgA4BgQ7rj/7471EoC1He7/OfDrDm/AezpsN77D8u+AOx3L7wNLHcu3dPhwnY/jywKjlPd+25uzU7zfSQSO5efbPgyd/6frRND5TXkW8I5jORojqQR02vcVwKeOD9JAx2uUDFwGvOBYJwhjxMhQ4Cbg/xz3BwNbML4g5gN1wJAuji/Zsd1Ex7a+plMi6Lzc8bgcy78HrnUsx2B82YZjfOnlA3FOrJfteB1CgKNAWufXv4vYNfD9Dv/HdVh+Cbi4w/n4s2P5QmC1Y/mnGD3IASYArUAmMKjDaxKA8YW9uMM+v+dYfhv4BKNX8kRgRxcxzqfDePddvCYBQJRjOQGjV6/qeOyObVRhjP1jwfhhNNfx2BSMoaO7OkevdFgvHWOoBTCSUFtSiHDEcFKcnY7hcr59Hw4CKjk5ETjzOfwPMA5YhJEo7sV4j+Z0F5MLvmsycHzmHNts+yHWdmt7Pd53nMtAjM9LPhDT0/alaqhvlmL8CsPxd6nWuhXjjXKxo7h8EfBvjMkxxgJfO7qIXw8M7rCtVR2Wz3AU93b///bOLkTLIorjv78RiWVdWIF9CoVZWFkmEtWWUeZtlOgmRGhQUYoJSl0EUdAHgVdRVFZChUZFX0b4UehKuLuFtbsZeWWQVGZFJqG2rv8uzjzs4+vzfuxGmu38YNmX55l35sy8Z2bOOTPMAPMIpQO4mrDAIDpGwcz09yVhjU3iKJ4waXsTcKGkM4k2eSe1Q5lrgVW2B2zvIiz2acTlITdKOonwpjps7yPqc2dqqy5gHIN16ra9o0KU6cBG27sd9zC8WZGmGTOBh1K5G4nB/Lz0br3t31pI94ntPbb3E5Zn+XeuxwBhdRbMkNSVdOBGBnUAwuOAsOQnpM9twOsAtnsJzwCijYs2OUhY4G3p3V+ErkJY8Jts96fPRb7NKLeJgCck9RIextnEpF9Lt+2dtg8Rg1hR1ixCH6q4CXg2tfcHwKmSxhKT/XJJi4gBr1bvamljUA9/ICbGMq30w80pnzbgSUK3pxGTAsOQaaiMAn63PaX0d3F6t5MIe/anPrKdFsaC//VZQ/8mksYRHXSyJBMWhiUtI5TpfiLk8rntvekwqPW22+tk+Wfp80rCauuRdBdh4TQUB3jS9gtN0pXPExndJO1QeY3oLHOB+RXvq44FxvZ+SRuBW4A5wKpS+oW21x6WiXQDh7fVEVkOSepqOW+zvb2m3Ok15TZKd6D0aIDW+tl+2wMpj9HAc4Qn9r2kRzn89yryr827qu6V7Z7odzIjiRDHAQDbh4awDlJuk3mE5zHVdr+k76jWs3rtM5PwHKsYBVydjIQyT0n6iPCOOotNDk1opCOt9MPNhEd+FhFKWpredQDYPkIm29+2IFdL2P5D0g5Js22/lcaWy2z3EKGhdmCl4uTRiYSH2pDsEQyf2wk39nzbE2yfS4REriUsxCuJGGNhYXQC10i6EEDSGEkT6+Q9FvhRcexseQGzk8GOUl6cXgvMV5xVjqSzk3Veyy5JF0saRYRkCvamMlulKv1K0g4F29sqvtMBzJF0gqQzCGuqO71bTcT2r0t1Kep0X2oDJE2UdHITubqAGySNS9+bPYQ6FawFFqbOhaQr/mG6Mv1FfZpQDJ6/pN+0lV0tHSRdkTSZCA9BtMn1kk5PC6DthDc2HJrpyWnAz2kSmEFrnhBJ5tOIEEpxWmZtWeuAB0rpp6T/F9jus/00ET6c1ETODmBu0sPxwIwGYtXrh13E2tqh5PV9BdxDTBD1ZBo2ioMFtwAXSdopaUGSZ4GkHmAbgzcQrgV+lfQNsQa2tNSmdckTwfBpJ2JxZd4B7kiW3Roi1LEGwPZuIqa6KrnOndRXkEcIZVtPLKgVLAaWSOom4uF7Ut7riFDRluTGvk11R3goyfMpUD6SdzWwtNhO2aziSbE+k/S1pGfSs13E9Xmv1vnau0S4oieVv8z2T+ndOmJi2JBCOgAriLDKVsX+6RdoYlk7jhl+lOg0G4gw2VB5nIiv9qZyH/+H6cq8mNI33Kbq2Jn1EhGieY/BkEMjngdOSbq1jDTJpjZ5mBgUeoCttt9vIb8qeoGDihuwHqx4/wZwlaQviIFqKFbwzcRvVvAhcKtim+91wKKUd28a5O5N6RYnPewh4uYfN5HzXWIRv49os0aTYmU/tH2AWMvqTI82E/2tr4FMw8Z2u+3xtk+0fY7tl23vsD3L9uW2L7H9WEpr20vSs0ttr26WP+TTR48rJI0B9tm2pLnEmsR/4i7iJFsfccH2nmMtT+b4QtIKYIXjfuHMUSavERxfTCUWzETsdqiKxR91Ulz2FWB5ngQyw8H23cdahpFM9ggymUxmhJPXCDKZTGaEkyeCTCaTGeHkiSCTyWRGOHkiyGQymRFOnggymUxmhPM3TbtC4b+eapIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results[0, :, :].flatten(), label=\"Random banker\")\n",
    "sns.distplot(results[1, :, :].flatten(), label=\"Group1 banker\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Average utility over different random train/test draws\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Based on 100 repeats of 5-fold cv, our model using logistic regression is considerably better than the random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: reproducibility, reliability and privacy\n",
    "\n",
    "### Is it possible to ensure that the policy maximises revenue?\n",
    "\n",
    "We cannot ensure that the policy maximises revenue. This is due to the fact that the model is not perfect and we are maximising the expected utility. There is an uncertainty in the estimated probability of a new individual being credit-worthy. If there were no uncertainty in this and we knew in advance which of the new individuals were going to pay back, we could ensure that a policy would maximise revenue by only lending to the credit-worthy individuals.\n",
    "\n",
    "### How can we take into account the uncertainty due to limited/biased data?\n",
    "\n",
    "In an ideal world we would have an independent replication of our study and check whether or not new, independent data would develop the same type of policy that we obtained with the current data set. Another option is simulation of data in order to validate our policy based on constructed data (Dimitrakakis, 2020, pp. 35-36). When it comes to the current policy, there are several ways of taking this uncertainty into account when considering our objective of maximising expected utility.\n",
    "\n",
    "### What are the consequences if the model is wrong?\n",
    "\n",
    "There will always be a possibility that the model performs a lot worse in practice. For example our data set could be a bad representation of the population because of some change in the population properties after it was collected. Therefore it is important not to put too much trust into new models. Simple interpretable models have a clear advantage in this regard. If the model is simple enough you might spot errors before the model is tested in practice, and if you find a model to be wrong, it will be easier to understand why.\n",
    "\n",
    "For the bank, one of the major consequences of the model being wrong is the loss of profit. If the model is granting credit too easily, the bank could incur losses due to the fact that they are granting credit and then loosing the entire investement $m$. If the model is too strict about granting credit, the bank is missing potential profit from the individuals that were declined credit, this would be $-m((1+r)^n - 1)$. The missed potential income could also cause the individuals that were wrongfully declined credit to apply for credit elsewhere. In that case, a hard-to-intepret model would also increase the difficulty in troubleshooting the reasons for the wrongfully decline of credit.\n",
    "\n",
    "### How can we take into account the risk of the model being wrong?\n",
    "\n",
    "It is possible to consider the two types of error the model can generate: \n",
    "\n",
    "1. classify new individuals as credit-worthy when they are in fact not ($a_{10}$)\n",
    "2. classify new individuals as not being credit-worthy when they in fact are ($a_{01}$)\n",
    "\n",
    "We can indicate the class of actual credit-worthy individuals as 'positive' ($a_{1}$) and the class of individuals not being credit-worthy as 'negatives' ($a_{0}$). Then our error (1) can be called a false positive and the other type of error (2) as a false negative. This corresponds to type 1 and type 2 erros, where the probability of type 1 errors is equivalent to the probability of false positive and type 2 error is equivalent to the probability of false negative. These probabilities can be estimated by looking at the fraction $\\frac{a_{10}}{\\# a_{1}}$. Similarily for the false negatives $\\frac{a_{01}}{\\# a_{0}}$. Adapted from (Azzalini & Scarpa, 2012, p. 139). For our example, if a new individual is classified as credit-worthy and this is a false positive, it implies the loss $-m$ (the lost investment). While if a new individual is classified as not being credit-worthy and this is a false negative, it implies the loss of $-m[(1+r)^{n} - 1]$ (the \"lost\" return on investment). \n",
    "\n",
    "The different actions are weighted by their reward values, so the decision maker grants credit based on the reward-weighted utility, not only whether or not the probability of repayment is above a threshold, such as $>0.5$. These weights are shown below:\n",
    "\n",
    "|   |           |            | True              |         |\n",
    "|---|-----------|------------|-------------------|---------|\n",
    "|   |           |            | No default        | Default |\n",
    "|   | Predicted | No default | $-m((1+r)^n - 1)$ | $-m$    |\n",
    "|   |           | Default    | 0                 | 0       |\n",
    "\n",
    "\n",
    "We could take into account the risk of the model being wrong by trying to control the type 1 error (false positive), we want to minimize false positives because this causes us to lose $-m$. We could enfore a higher threshold than 0 for the expected utility and then we could check this by demanding that the probability for type 1 errors (false positive) should be within an accepted range, e.g. maximum 5 %. We could attempt to find this threshold for type 1 erros by looking at the training data and check the probability for type 1 errors on a holdout set of the training data. Currently, we are attempting to control this by increasing the threshold for which to grant credit. When increasing the threshold for the expected utility, the model becomes more conservative. This would be equivalent to saying that we need to be for example $\\ge$ 75 % sure that the loan is going to be repaid rather than just $\\ge$ 50 % sure that the loan is going to be repaid in a situation where we only looked at the probability of repayment.\n",
    "\n",
    "We would want to have the percentage of false positives to be below a limit, e.g. $max\\_alpha = Pr(\\text{false positive}) = 0.05$ \n",
    "\n",
    "An outline of the algorithm:\n",
    "\n",
    "1. initialize $\\epsilon = 0$, $alpha\\_value = 1$ and $\\Delta \\epsilon = 1000$\n",
    "2. while $alpha\\_value \\ge max\\_alpha$:\n",
    "    * false_positives = 0\n",
    "    * predicted_actions = get_actions(validation_data, $\\epsilon$)\n",
    "    * false_positives += \n",
    "    * get_number_of_false_positives(predicted_actions, validation_data)\n",
    "    * $alpha\\_value$ = false_positives/len(validation_data)\n",
    "    * $\\epsilon = \\epsilon + \\Delta \\epsilon$\n",
    "3. alter policy so that $E(U(\\cdot)) > \\epsilon$ in order to grant credit to an individual \n",
    "\n",
    "\n",
    "\n",
    "### Does the existence of the database raise any privacy concerns?\n",
    "\n",
    "The database is anonymized because there are no directly identifying attributes about the individuals (Dimitrakakis, 2020, p. 74). However, there is very specific information about the individuals in the database, such as age, personal status, sex and information about the employement situation of the individuals. There is also information about the housing and property situation of the different individuals.\n",
    "\n",
    "There seems to be a high probability of inferring personal information about the individuals in the database by using for example record linkage. When considering differential privacy, it could be useful to assume that the adversary has potentially infinite side information (Dimitrakakis, 2020, p. 76). Where side information could be defined as information that an adversary has about all, except one observation of a dataset (A). We can call these datasets A and Aâ€™. The idea of differential privacy is then that even in the extreme case that the adversary has all this information, they should not be able to infer information about the missing observation based on differential private queries on A and Aâ€™ (Zhu, 2017, pp. 7-8). Unlimited access to this database could therefore be a large privacy concern. Both because adversaries could use side information to infer information from this database and/or because adversaries could use this database as side information to infer information from other databases. \n",
    "\n",
    "If we have the datasets A and Aâ€™ as above, an algorithm called ALG and define f(ALG(*)) as the probability distribution of the result. Then differential privacy could be defined as\n",
    "\n",
    "$$\n",
    "f(ALG(A)) < e^{\\epsilon}f(ALG(Aâ€™)) + \\delta\n",
    "$$\n",
    "\n",
    "where $\\delta = 0$ for $\\epsilon$-DP. The parameter $\\epsilon$ here controls the degree of equality between the distributions, adapted from (Le Ny, 2020, pp. 5-6). Based on this definition it would seem that by decreasing $\\epsilon$, the two distributions for the different algorithms would be more similar.\n",
    "\n",
    "### How would secret database and public credit decisions affect privacy?\n",
    "\n",
    "It would obviously be better to have the database secret instead of the database also being public. It could however be possible to infer a lot of information from the secret database by knowing the public credit decision. \n",
    "\n",
    "Because the bank is publishing the actual credit decisions, differential privacy is not possible. If, for example, an adversary with information about all but one attribute for a specific row, the adversary could infer the information of the missing attribute by using the public credit decisions. If the credit decisions were to be made public, the bank would have to consider the fact that adversaries could query the public â€œdatabaseâ€ containing the credit decisions. This information could then be used as side information or together with additional side information to infer information about the individuals. \n",
    "\n",
    "One way to ensure privacy of the credit decision would be the â€œrandomised response mechanismâ€. In this response mechanism, the true credit decision would be returned with probability p0 = 0.5 and with probability, p0â€™ = 1 â€“ p0, the response mechanism would return 1 with probability 0.5 and 0 with probability 0.5. This calculation of the response could then be independent for each query (Dimitrakakis, 2020, p. 77). To ensure differential privacy for the public credit decisions, this algorithm could be implemented when potential adversaries queries the public â€œdatabaseâ€.\n",
    "\n",
    "### How can we protect the data of the people in the training set?\n",
    "\n",
    "We could use differential privacy to obscure the information in the public credit decisions that have been made by the bank.\n",
    "\n",
    "* if the database is secret, but the credit decisions are public (we assume that the identities of the individuals also are public): we would have a randomised response mechanism for the credit decision. This randomised response mechanism will ensure that the public responses are correct with a probability $\\le 1$ (Dimitrakakis, 2020, p. 77). This would make it harder to infer information about the individuals from the public information. Even if the database is not public, there is a risk of dishonest employees and/or digital attacks on the bank.\n",
    "\n",
    "The training data contains several columns of attributes. We could implement a mechanism where each of the attributes would be transformed independently and then the entire observation (with all attributes) could be returned (Dimitrakakis, 2020, p. 82). For categorical columns of the training data, it would be possible to implement a randomised response mechanism as above. For the numerical values one could use a Laplace mechanism in order to transform the response by adding Laplace-distributed noise to the returned value. This could also be done by adding Laplace-distributed noise to each variable before computing a response, which would be a local privacy model (Dimitrakakis, 2020, p. 83). In order to protect the training data w.r.t. privacy the following outline of an algorithm could be implemented\n",
    "\n",
    "1.\tAdd Laplace-noise to numerical attributes\n",
    "2.\tAdd randomized response mechanism to categorical attributes\n",
    "\n",
    "* if the database is public and the credit decisions are public: for categorical attributes, we could use a randomised response mechanism. For the numerical attributes, we can apply a Laplace mechanism in order to make the information differentially private. In this scenario as well, the bank is still vulnerable to dishonest employees and digital attacks as the original (true) data is still available inside the bank.\n",
    "\n",
    "One could also have performed randomized response mechanism for the credit decision of the training data if this was the only data that would be public (and would have needed protection). In that case one would have a situation more similar to a centralized privacy model when adversaries query the data. Because one could for example calculate the true number of accepted credit applications and then add noise before returning the response (Dimitrakakis, 2020, p. 83). This would protect the data of the people in the training set because an adversary would lose the ability to infer information with the credit decision as side-information.\n",
    "\n",
    "### How can we protect the data of the people that apply for loans?\n",
    "\n",
    "We assume that the data for a new individual could potentially be leaked and considered non-secret. In that case we could apply the same techniques as for people in the training set. We would then apply a random mechanism to the input data for the new applicant. This could be done in the same manner as for the training data. There would be two possible scenarios:\n",
    "\n",
    "1.\tProtect the data by adding Laplace-noise to numerical attributes and using the randomized response mechanism for the categorical attributes\n",
    "2.\tProtect the data by adding noise to the response variable after the policy has made the decision on the true data of the new test data. This would be a type of centralized privacy model as mentioned above where the noise is added after the calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a private decision making mechanism for people that apply for new loans\n",
    "\n",
    "We decided to implement local privacy with laplace noise for the quantitative attributes and randomized response mechanism for the categorical attributes. We then need to find values for the parameters of the noise. More specificly the scale $\\lambda$ for the laplace noise and the probability of changing a value $p$ for the randomised response mechanism. From (Dimitrakakis 2020, p. 84) we have that for a function $f$ with sensitivity $\\mathbb{L}(f)$:\n",
    "$$\n",
    "    \\epsilon \\ge \\mathbb{L}(f)/\\lambda\n",
    "$$\n",
    "Here the sensitivity is defined as $\\mathbb{L}(f) \\triangleq \\sup_{xNx'} |f(x) - f(x')|$, and can be estimated by the range of the attribute.\n",
    "\n",
    "From (Dimitrakakis 2020, p. 80) we have that for a randomized response mechanism with $p \\le 1/2$:\n",
    "$$\n",
    "    \\epsilon \\ge \\ln \\left( \\frac{1-p}{p} \\right)\n",
    "$$\n",
    "With $k$ as the number of attributes, to achieve $\\epsilon$-DP in total, each attribute needs to be $(\\epsilon/k)$-DP (Dimitrakakis 2020, p. 82). Using this and the equations above, we can find the noise parameters as a function of the total privacy guarantee $\\epsilon$:\n",
    "$$\n",
    "    \\lambda = \\frac{\\mathbb{L}(f) k}{\\epsilon}, \\quad p = \\frac{1}{e^{\\epsilon/k} + 1}\n",
    "$$\n",
    "\n",
    "To simulate people applying for new loans, we split the data into training and test sets, and only apply the noise to the covariates in the test set. The utility is estimated by 5-fold CV for a more stable result. The implementation is listed in the apendix under the file privacy_guarantee.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_guarantee import utility_epsilons\n",
    "epsilon_sequence = np.linspace(1, 400, 200)\n",
    "utility = utility_epsilons(epsilon_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total utility')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(epsilon_sequence/24, utility)\n",
    "plt.xlabel(\"epsilon/k\")\n",
    "plt.ylabel(\"Total utility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the cross validated total utility over different values of $\\epsilon/k$. The number of attributes $k$ is 24, so to get the total privacy guarantee one would have to multiply by 24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the amount of loss in utility as we change the privacy guarantee\n",
    "\n",
    "The amount of loss in utility is related to privacy. More privacy in general indicates less expected utility as more information is â€œlostâ€ when the policy is deciding the best action. In order to estimate the loss in utility one can base the estimation of (alpha, beta) usefulness for an algorithm A, an algorithm with more privacy as A_hat and the (test) data set TD that is defined through Pr(|A(TD) â€“ A_hat(TD)| <= alpha) > 1 â€“ beta. A small difference between the algorithm and the privacy modified algorithm would imply a small loss in utility (Zhu, 2017, pp. 15-16). This would be one possible estimate of the loss in utility, while the absolute difference |U(TD) â€“ U_hat(TD)| itself could be another estimate of loss in utility where U is the normal utility and U_hat is the utility with increased privacy.\n",
    "\n",
    "### How will the interest rate affect the decision maker(s)?\n",
    "\n",
    "The interest rate $r$ affects the action of the decision maker through the expected utility. The expected utility given that the credit application is granted, $a_{t}=1$ is defined as:\n",
    "\n",
    "$$\n",
    "E[U|a_{t} = 1] = -m \\cdot Pr(r = r_{0}|a_{t} = 1) + m((1 + r)^{n} - 1) \\cdot Pr(r = r_{1}|a_{t} = 1)\n",
    "$$\n",
    "\n",
    "This further implies that the interest rate only affects the reward where the debtor does not default. This reward defines the utility:\n",
    "\n",
    "$$\n",
    "m((1 + r)^{n} - 1)\n",
    "$$\n",
    "\n",
    "From this we see that increasing interest rate when investment $m$ and the number of periods $n \\ge 1$ are held constant will monotonically increase the expected utility with increasing interest rate. For the decision maker this would mean that the probability for repayment of the credit: $Pr(r = r_{1}|a_{t} = 1)$ could be lower and the decision maker would still accept the credit application.\n",
    "\n",
    "### How will the number of periods affect the decision maker(s)?\n",
    "\n",
    "For the number of periods, the situation is the same as above, the expected utility will increase monotonically with increasing $n$ as long as $r > 0$. This is also logical because the bank would increase its profit with the number of interest rate accruals from the loan.\n",
    "\n",
    "### What are two main ways to perturbate the data in order to protect the individuals of the data set?\n",
    "\n",
    "There seems to be two possible mechanism to use in order to protect the individuals of the datasets. These are input perturbation and output perturbation. The input perturbation would add differently distributed types of noise to the columns of the data in order to protect the private information. Output perturbation would use â€œsecretâ€ data in the algorithm and then add noise to the output of that algorithm (Le Ny, 2020, pp. 18-22). These ways correspond to adding noise directly to the columns of the data sets before predicting the best action as an input perturbation. If we would calculate the best action based on the private data and then obtain our â€œtrueâ€ credit decision we could add noise to this output we would have a mechanism closer to the output perturbation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: fairness\n",
    "\n",
    "In order to simplify notation, we define the following variables in the same manner as in (Dimitrakakis, 2020, pp. 103-104): \n",
    "* y: {1: the credit was repaid, 0: the credit was not repaid (default)}\n",
    "* a: {1: the application was accepted, 0: the application was rejected}\n",
    "* x: covariates\n",
    "* z: sensitive covariates\n",
    "* U(a, y): the decision makerâ€™s utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guiding questions\n",
    "\n",
    "### Identify sensitive variables\n",
    "\n",
    "There are several variables in the data set that could potentially be considered sensitive. Variables such as the 9th covariate â€œPersonal status and sexâ€ could be considered sensitive. Because ceteris paribus we would ideally have that the chance of being offered credit should be the same whether the applicant is e.g. a married male or a single female. \n",
    "Covariate 11 â€œpresent residence sinceâ€ could also be considered sensitive, since we generally do not want to discriminate w.r.t. this because we cannot determine the reason for the change of residency.\n",
    "\n",
    "Covariate 13 â€œageâ€ could also potentially be considered sensitive because, as with gender and personal status, we do not want to discriminate the credit decision upon age. Although we could argue that age must be considered when considering the credit decision w.r.t. repayment.\n",
    "\n",
    "Covariate 20 â€œforeign workerâ€ ceteris paribus could also be discussed to be a sensitive variable. Whether or not the worker is foreign or not should ideally not affect the credit decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the original features already imply some bias in data collection?\n",
    "\n",
    "We can think of bias in the data collection as either what covariates where selected to be measured (bias in selecting the columns of the training set) and as what type of individuals were selected to be measured (bias in selecting the rows of the training set). As the covariates seem to cover all the usefull information that one can collect within reason, we are not interested in looking at the bias in covariate selection. However when it comes to bias in the population sample, there are some problems that should be adressed. It is unclear who they chose to include in the data set. The response variable \"repaid\" implies that all the induviduals in the data set were given a loan, how else would they know wether they repiad or not. If the data only consists of people who were given a loan, then there are two posibilities for how the data was gathered:\n",
    "\n",
    "1. They gave out loans as normal trying to maximise profit.\n",
    "2. They gave out loans to everyone who applied for the sake of the experiment.\n",
    "\n",
    "If point 2. is the case, then that is ideal. Most likely point 1. is the case and then this should be accounted for.\n",
    "It is also worth pointing out that there are no single females in the data set. This could be because of the aforementioned bias. Maybe it was hard to get a loan as a single female when this data was collected.\n",
    "\n",
    "### Analysis of decision function\n",
    "\n",
    "It is important that the decision function does not discriminate against gender. To investigate how fair our model is with respect to gender, we plotted the amount of males/females that are classified as \"did repay\"/\"didnot repay\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAGQCAYAAAAdqIDwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXyM5/7/8XcyEkJCSUJRRy1NiIhElCbi5OippUXb0M2uWrpYq5ZIKSoltlJrHFRRrX1pj5469e1py6EoQrSCCELTkkQrSirb/fvDz5xOkSY3mUnk9Xw8PB6Z677u+/5cM67MO/c99z1OhmEYAgAAAArJ2dEFAAAAoGQiSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAHdYZGSkXn31Vevjnj176u2337Z7Hbt375avr68yMjLsvm+UDgRJ4DbMmTNHTzzxhKPLAFDMzZkzR0OGDClQX8IfShKCJJSVleXoEu562dnZji4BdwHmqn3dyef7nnvukbu7+x3bHlBcECRLoZ49e+qtt97S22+/rRYtWuiFF16QJB07dkwvvviigoKCFBoaqhEjRujChQvW9T777DN16tRJAQEBatGihfr06aMrV65I+t9pnLlz5+qhhx5S06ZN9eabb9r8Is7KylJ0dLRCQkLUuHFjde3aVYcOHbIuv/5X+K5du9S5c2c1adJEzz33nJKSkqx9EhIS1LNnTwUFBalp06bq3Lmz4uPjrcu//fZbdevWTQEBAQoPD1d0dLS1xjttw4YNmjt3rhISEuTr6ytfX19t2LBBkuTr66sPP/xQL7/8sgIDAxUbG6sNGzaoWbNmNtvYtm2bfH19b2iLiIhQ48aN9fe//11z585VTk5OkYwBxRtz9c65fvZg1apVCg8PV5MmTTRkyBBdunTJ2uf6c7NgwQKFhYWpffv2kqQff/xRQ4YMUbNmzdS8eXO98sorOnv2rHW93NxcTZ48Wc2aNVOLFi00depUGYZhs/8/ntrOysrStGnTFB4eLn9/f7Vp00Zr167V2bNn1atXL0nSgw8+KF9fX0VGRkqS8vLytHDhQj388MMKCAjQ448/rs8++8xmP1999ZXatWungIAA9ezZUz/88MOdfSKBPzJQ6vTo0cMIDAw0pkyZYpw4ccI4ceKEcfHiReOhhx4yZsyYYSQmJhrfffed8fzzzxs9e/Y0DMMwzp07Z/j5+RlLly41zpw5YyQkJBgffPCB8euvvxqGYRijRo0yAgMDjaFDhxrHjh0z/vOf/xgPPfSQ8c4771j3O3HiRCMsLMz48ssvjePHjxujRo0yHnzwQePnn382DMMwvvnmG8PHx8d4+umnjd27dxvHjx83unXrZjz77LPWbXTo0MEYPny4kZiYaJw8edL49NNPjSNHjhiGYRinT582AgMDjaVLlxonT5409u3bZzz55JNGZGTkLZ+LvXv3GoGBgfn+27x5803XzczMNGJiYowOHToY58+fN86fP29kZmYahmEYPj4+RkhIiLFu3TojOTnZ+OGHH4z169cbwcHBNtv4/PPPDR8fH5t6mjZtamzYsMFITk42duzYYbRu3dqYM2dOgV9f3D2Yq/9zO3PVMAxj9uzZRmBgoNGrVy/j+++/N/bs2WO0adPGGDZsmLXP9edmxIgRxrFjx4xjx44ZWVlZxqOPPmqMHj3aSEhIMBITE41hw4YZ7dq1M65evWoYhmH84x//MB588EFj69atRmJiohEVFWUEBQUZr7zyis1rGR0dbX08ZMgQIzw83Pj3v/9tJCcnGzt37jS2bNli5OTkGFu3bjV8fHyMpKQk4/z580ZGRoZhGIYxf/58o3379sbXX39tJCcnG+vXrzf8/f2N3bt3G4ZhGCkpKYa/v78xefJk48SJE8bmzZuN0NBQw8fHx7h48WJ+/9UA0wiSpVCPHj2MJ5980qZt3rx5Rt++fW3afvzxR+svs8OHDxs+Pj7G2bNnb7rNUaNGGc2bNzeuXLlibfvwww+NwMBAIzc317h8+bLRqFEj4+OPP7Yuz8rKMsLCwoxFixYZhvG/N6edO3da+3z55ZeGj4+P8dtvvxmGYRhBQUHGhg0bblpDVFSUMXbsWJu2vXv3Gg0aNLCu/0eZmZnGqVOn8v136dKlm65rGNfenB5//PEb2n18fIy3337bpq0gQbJ3795GbGysTZ9NmzYZLVu2vGUNuHsxV//nTszVhg0bGj/99JO17auvvjIaNGhgnD9/3vrchIaGWgOiYVybf+3atTPy8vKsbVevXjUCAgKM7du3G4ZhGC1btrQ+N4ZhGNnZ2cZf//rXWwbJpKQkw8fHx/jvf/9701qvP7+/D39Xr141mjRpYuzfv9+mb1RUlDUMz5gxw3jsscdslk+bNo0giSJVxtFHROEYjRo1snmckJCg3bt3Kygo6Ia+ycnJCgsLU0hIiDp16qSwsDCFhYWpXbt2qlSpkrWfr6+v3NzcrI+DgoJ05coV/fjjj7p06ZKys7PVtGlT63IXFxcFBAToxIkTNvv7/aleb29vSVJ6erpq1Kih559/XmPGjNHmzZsVGhqq9u3b6y9/+Yt1DEePHtUnn3xiXd8wDOXl5ens2bOqV6/eDWMrV66cateuXaDnrLD8/f0LvU5CQoL279+v2NhYa1tubq6uXr2qzMxMm+cXpQNz9Zo7MVerV6+uatWq2Yw7Ly9PJ0+etNbv4+MjV1dXa5+EhAQlJyfbPB+SdPXqVSUnJ+vSpUtKTU1VkyZNrMvKlCkjf3//G05vX3fkyBFZLBY9+OCDBa799OnTyszMVN++fW3as7Oz1bBhQ0nSiRMnFBAQYLM8MDCwwPsAzCBIllJ/DCRXrlxR69atNXz48Bv6ent7y2KxaOnSpdq/f7/++9//asWKFZo5c6bWrFmjWrVq3dHaypT5339LJycnSdc+GyRJgwYNUseOHfXVV1/p66+/1uzZszVz5ky1adNGV65c0XPPPaeePXvesM3q1avfdF/ffvut+vXrl289EyZM0OOPP17ocZQvX97msbOz8w1vLH+8COfKlSsaNGiQ2rZte8P2ypYtW+gaUPIxV68pyrn6ezd7vhs1aqTp06ff0LdKlSqm9lGuXLlCr3P986MLFy60CcOSbIIvYG8ESUi6dtRj69atqlmzps2bw+85OTkpODhYwcHBGjBggFq3bq1t27bp+eeflyQdPXpUv/32m/WXZFxcnMqXL6/q1aurcuXKcnFx0f79+1WzZk1J10JUfHy8evfuXaha69Spozp16qhPnz4aNmyY1q9frzZt2sjPz0+JiYmFOmrh7++vTZs25dvH09PzlstcXFysb5x/pnLlyrp8+bKuXLliDZkJCQk2ffz8/HTy5MkiO0qKko+5emv5zVXp2kUz586dswaxuLg4OTs7q06dOrdcp1GjRvrXv/4lT0/PW1517e3trYMHD1qPMObk5Oi7776Tn5/fTfv7+PgoLy9Pe/fuVWho6A3LXVxcJF07G3FdvXr15OrqqpSUFDVv3vym261Xr56++OILm7aDBw/ecmzAncBV25AkdevWTRcvXtSwYcN06NAhJScna/v27Ro9erRyc3N18OBBxcbGKj4+XikpKfr3v/+tCxcuqG7dutZtZGVl6Y033lBiYqK++uorzZkzRz169JCzs7PKly+vrl27aurUqfr666+VmJiosWPH6rffftNTTz1VoBp/++03vfXWW9q9e7d++OEH7du3T/Hx8dbTYP369dOBAwf01ltv6ciRIzp16pS2bdumt95665bbvH66LL9/+d2yo2bNmjp79qyOHDmiCxcu5Hu7kCZNmsjNzU3vvPOOkpOT9cknn1iv8r5uwIAB2rx5s+bOnavjx4/rxIkT2rJli2bOnFmg5wh3P+aqubkqXTuqHxkZqYSEBH377beKjo7Wo48+aj2tfTOdOnVS5cqV9corr+jbb7/VmTNntHv3bkVHR+unn36SJPXq1UuLFi3Stm3bdOLECU2YMCHfe0Ded999ioiIUFRUlLZt22bd5qeffirp2u8VJycnffnll7pw4YIuX74sd3d39e3bV5MnT9bGjRuVnJys7777TitWrNDGjRslSc8995xOnTqlKVOmKCkpSZ988ol1GVBUOCIJSVK1atX00Ucfafr06XrhhReUlZWlGjVqqFWrVnJ2dpa7u7v27t2rZcuW6ddff1WNGjUUGRmp8PBw6zZCQkJUu3Ztde/eXVlZWerYsaMGDRpkXT58+HAZhqGRI0fq8uXL8vf31+LFi20+u5UfZ2dn/fLLLxo1apTS0tJUuXJltW3bVoMHD5YkNWjQQCtWrNCsWbPUrVs3SVKtWrX02GOP3cFnyla7du30+eefq1evXsrIyNDkyZPVuXPnm/a95557NG3aNE2dOlVr165VSEiIBg0apLFjx1r7tGrVSrGxsZo3b54WLVqkMmXKqG7dunr66aeLbAwoWZir5v3lL39RmzZt1K9fP128eFF/+9vfNG7cuHzXcXNz0wcffKDp06dr4MCBunz5sqpVq6aQkBBrcO3bt69SU1M1atQoOTs7q0uXLmrTpo3NrYX+aPz48XrnnXc0fvx4/fLLL6pRo4ZeeuklSdde40GDBmnGjBkaPXq0nnzyScXExGjo0KGqUqWKFi5cqLNnz8rDw0N+fn56+eWXJUk1atTQnDlzNHnyZH3wwQcKCAjQa6+9pqioqDv0DAI3cjJu9WlgoBAiIyOVkZGh+fPnO7oUAPkorXN1zpw52rZtmzZv3uzoUoC7Cqe2AQAAYApBEgAAAKZwahsAAACmcEQSAAAAphAkAQAAYApBEgAAAKaUqiBpGIZyc3Nv+f2nAO4+zHsAKDqlKkjm5eUpLi6uwF9pB6DkY94DQNEpVUESAAAAdw5BEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAHgD3Lz8hxdwm0p6fUDKDnKOLoAAChuLM7OGvPhdp08f9HRpRRanaqVFN2tlaPLAFBKECQB4CZOnr+ohB8uOLoMACjWOLUNAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAU+wWJM+dO6fhw4erRYsWCggIUKdOnRQfH29dbhiG3n33XYWFhSkgIEB9+vTRqVOnbLbxyy+/6PXXX1fTpk3VrFkzRUVF6fLly/YaAgAAAH7HLkHy4sWL6tq1q1xcXLRo0SJt2bJFo0aNUqVKlax9Fi1apBUrVmj8+PFas2aN3Nzc9MILL+jq1avWPsOHD1diYqKWLl2q2NhYffvtt3rzzTftMQQAAAD8gV2+2WbRokW69957NXnyZGtbrVq1rD8bhqHly5frlVde0SOPPCJJmjp1qkJDQ7Vt2zZ16NBBJ06c0Pbt27Vu3To1btxYkjRmzBj1799fI0eOVLVq1ewxFAAAAPx/djki+cUXX8jf31+DBw9WSEiInnzySa1Zs8a6/OzZs0pNTVVoaKi1zcPDQ02aNNGBAwckSQcOHFDFihWtIVKSQkND5ezsrEOHDtljGAAAAPgduxyRPHPmjD766CM9//zzevnllxUfH6/o6Gi5uLgoIiJCqampkiRPT0+b9Tw9PZWWliZJSktLU5UqVWyLL1NGlSpVsq5fULm5ubcxGgCOYLFYbmv9wsz7291XccDvOdwN7oa5eLezS5A0DEP+/v4aNmyYJMnPz0/Hjx/XqlWrFBERYY8SbPz+Ih8AJUNwcPBtrV/Qee/m5iY/P7/b2ldxcPToUWVmZjq6DOC23O68R9GzS5D09vZWvXr1bNrq1q2rrVu3WpdLUnp6uqpWrWrtk56ergYNGkiSvLy8dOHCBZtt5OTk6OLFi9b1C6px48b8lQOUMqVt3vv6+jq6BAClgF2CZNOmTXXy5EmbtlOnTqlmzZqSpPvuu0/e3t7atWuXGjZsKEn69ddfdfDgQXXt2lWSFBQUpIyMDB0+fFj+/v6SpG+++UZ5eXkKCAgoVD0Wi6VUvaEAKH3zvjSNFYDj2OVim969e+vgwYOKjY3V6dOn9cknn2jNmjXq1q2bJMnJyUm9evXSggUL9H//9386evSoRo4cqapVq1qv4q5Xr55atWqlsWPH6tChQ9q3b58mTpyoDh06cMU2AACAA9jliGRAQIDmzp2rd955R/PmzdN9992nqKgoPf7449Y+/fr1U2Zmpt58801lZGQoODhYixcvVtmyZa19pk+frokTJ6p3795ydnZW27ZtNWbMGHsMAQAAAH/gZBiG4egi7CU3N1dxcXEKDAzktA9QSpid991n/VMJP1z4847FTIOaVbRyaEdHlwGglOC7tgEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKbYJUjOmTNHvr6+Nv/at29vXX716lVNmDBBLVq0UFBQkAYNGqS0tDSbbaSkpKh///5q0qSJQkJCNGXKFOXk5NijfAAAANxEGXvt6IEHHtDSpUutjy0Wi/XnSZMm6auvvtKsWbPk4eGhiRMnauDAgVq1apUkKTc3Vy+99JK8vLy0atUqnT9/XqNGjZKLi4uGDRtmryEAAADgd+x2attiscjb29v6r0qVKpKkS5cuaf369YqMjFRISIj8/f01adIkHThwQHFxcZKkHTt2KDExUdOmTVPDhg0VHh6uIUOGaOXKlcrKyrLXEAAAAPA7djsiefr0aYWFhals2bIKDAzU66+/rho1aujw4cPKzs5WaGiotW+9evVUo0YNxcXFKTAwUHFxcfLx8ZGXl5e1T1hYmMaPH6/ExET5+fkVqpbc3Nw7Ni4A9vH7sxhmFGbe3+6+igN+z+FucDfMxbudXYJkQECAJk+erDp16ig1NVXz5s1T9+7d9cknnygtLU0uLi6qWLGizTqenp5KTU2VJKWlpdmESEnWx9f7FEZ8fHyB+7q4uKhMGbvl7TsuJydH2dnZji4DuG3BwcG3tX5B572bm1uh/zgtjo4eParMzExHlwHcltud9yh6dklI4eHh1p8bNGigJk2aqHXr1vrXv/6lcuXK2aMEG40bNy74XzlOTrI4l9yL23Pz8iTDcHQZgMMVat7fBXx9fR1dAoBSwCGH2ipWrKj7779fycnJCg0NVXZ2tjIyMmyOSqanp8vb21vStaOPhw4dstnG9au6r/cpDIvFUqg3lDEfbtfJ8xcLvR9Hq1O1kqK7tXJ0GUCxUNh5X9KVprECcByHBMnLly/rzJkz8vb2lr+/v1xcXLRr1y61a9dOkpSUlKSUlBQFBgZKkgIDAxUbG6v09HR5enpKknbu3Cl3d3fVr1+/yOs9ef6iEn64UOT7AQAAKEnsEiSnTJmi1q1bq0aNGjp//rzmzJkjZ2dndezYUR4eHurSpYtiYmJUqVIlubu7Kzo6WkFBQdYgGRYWpvr162vkyJEaMWKEUlNTNWvWLHXv3l2urq72GAIAAAD+wC5B8qefftKwYcP0yy+/qEqVKgoODtaaNWustwCKioqSs7OzBg8erKysLIWFhWncuHHW9S0Wi2JjYzV+/Hg9++yzcnNzU0REhAYPHmyP8gEAAHATdgmSM2fOzHd52bJlNW7cOJvw+Ec1a9bUokWL7nRpAAAAMKnkXo4MAAAAhyJIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMcUiQ/Mc//iFfX1+9/fbb1rarV69qwoQJatGihYKCgjRo0CClpaXZrJeSkqL+/furSZMmCgkJ0ZQpU5STk2Pv8gEAACAHBMlDhw5p1apV8vX1tWmfNGmS/vOf/2jWrFlasWKFzp8/r4EDB1qX5+bm6qWXXlJ2drZWrVqlmJgYbdy4UbNnz7b3EAAAACA7B8nLly9rxIgRio6OVqVKlaztly5d0vr16xUZGamQkBD5+/tr0qRJOnDggOLi4iRJO3bsUGJioqZNm6aGDRsqPDxcQ4YM0cqVK5WVlWXPYQAAAEBSGXvu7K233lJ4eLhCQ0O1YMECa/vhw4eVnZ2t0NBQa1u9evVUo0YNxcXFKTAwUHFxcfLx8ZGXl5e1T1hYmMaPH6/ExET5+fkVuI7c3NwC97VYLAXuW1wVZrxAcXW7c5F5D5Q8d8NcvNvZLUhu2bJF33//vdatW3fDsrS0NLm4uKhixYo27Z6enkpNTbX2+X2IlGR9fL1PQcXHxxeon5ubW6ECanF19OhRZWZmOroM4LYEBwff1vrMe6Dkud15j6JnlyD5448/6u2339Z7772nsmXL2mOX+WrcuHGp+ivnj59HBUoj5j0A3Hl2CZLfffed0tPT1blzZ2tbbm6u9u7dq5UrV2rJkiXKzs5WRkaGzVHJ9PR0eXt7S7p29PHQoUM2271+Vff1PgVlsVhK1RtKaRorcCvMewC48+wSJB966CF98sknNm2jR49W3bp11a9fP1WvXl0uLi7atWuX2rVrJ0lKSkpSSkqKAgMDJUmBgYGKjY1Venq6PD09JUk7d+6Uu7u76tevb49hAAAA4HfsEiTd3d3l4+Nj01a+fHndc8891vYuXbooJiZGlSpVkru7u6KjoxUUFGQNkmFhYapfv75GjhypESNGKDU1VbNmzVL37t3l6upqj2EAAADgd+x61XZ+oqKi5OzsrMGDBysrK0thYWEaN26cdbnFYlFsbKzGjx+vZ599Vm5uboqIiNDgwYMdWDUAAEDp5bAguWLFCpvHZcuW1bhx42zC4x/VrFlTixYtKurSAAAAUAB81zYAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAlHyDZK9evZSRkXFD+6+//qpevXoVWVEAAAAo/vINknv27FF2dvYN7VevXtW+ffuKrCgAAAAUfzf9isSEhATrz4mJiUpNTbU+zsvL0/bt21WtWrWirw4AAADF1k2D5JNPPiknJyc5OTmpd+/eNywvV66cxowZU+TFAQAAoPi6aZD8v//7PxmGoUceeURr165VlSpVrMtcXFzk6ekpi8VityIBAACKk88++0zz5s3T6dOn5ebmpoYNG2r+/PkqX7681q5dq/fee09nz55VzZo11bNnT3Xv3l2SNHr0aB0+fFjr16+Xq6ursrKy9Mwzz8jHx0dTp0518KgK76ZBsmbNmpJsT3EDAABAOn/+vF5//XWNGDFCjzzyiC5fvqxvv/1WhmHo448/1rvvvqs333xTDRs21JEjRzR27FiVL19eERERGjNmjJ544glNnz5dUVFRmjlzpjIyMvTmm286elim3DRI/t6pU6e0e/dupaenKy8vz2bZwIEDi6wwAACA4ig1NVU5OTlq06aN9eCbr6+vJGnOnDmKjIxU27ZtJUm1atVSYmKiVq9erYiICFWoUEHTpk1Tz549VaFCBS1fvlzLli2Tu7u7w8ZzO/INkmvWrNH48eNVuXJleXl5ycnJybrMycmJIAkAAEqdBg0aKCQkRJ06dVJYWJjCwsLUrl07ubi4KDk5WW+88YbGjh1r7Z+TkyMPDw/r46CgIPXt21fz589Xv3791KxZM0cM447IN0guWLBAQ4cOVf/+/e1VDwAAQLFmsVi0dOlS7d+/X//973+1YsUKzZw5U7GxsZKkiRMnqkmTJjbrODv/746LeXl52r9/vywWi5KTk+1a+52W730kL168qEcffdRetQAAAJQITk5OCg4O1uDBg7Vp0ya5uLho//79qlq1qs6cOaPatWvb/KtVq5Z13cWLFyspKUkrVqzQ9u3btX79egeO5Pbke0Syffv22rFjh7p27WqvegAAAIq1gwcPateuXWrZsqU8PT118OBBXbhwQXXr1tXgwYMVHR0tDw8PtWrVSllZWTp8+LAyMjL0/PPP6/vvv9fs2bM1e/ZsBQcHKzIyUm+//baaN29uEzZLinyDZO3atfXuu+/q4MGD8vHxUZkytt35mkQAAFDauLu7a+/evVq2bJl+/fVX1ahRQ5GRkQoPD5d07X7bS5Ys0dSpU1W+fHn5+Piod+/eunr1qkaMGKHOnTvr4YcfliQ9++yz+vLLLzVixAitXLmyxN1eMd8guXr1apUvX1579uzRnj17bJY5OTkRJAEAQKlTr149LVmy5JbLO3XqpE6dOt102ZYtW25oW7BgwR2rzd7yDZJffPGFveoAAABACZPvxTYAAADAreR7RHL06NH5rjx58uQ7WgwAAABKjnyDZEZGhs3jnJwcHT9+XBkZGXrooYeKtDAAAAAUb/kGyXnz5t3QlpeXp/Hjx5fIS9QBAABw5xT6M5LOzs7q06ePli1bVhT1AAAAoIQwdbHNmTNnlJOTc6drAQAAQAmS76ntP15MYxiGUlNT9eWXXyoiIqJICwMAAEDxlm+Q/P77720eOzs7q0qVKoqMjFSXLl2KtDAAAAAUb/kGyRUrVtirDgAAANxCZGSkMjIyNH/+fEeXYiPfIHndhQsXlJSUJMTRrqAAACAASURBVEmqW7euqlSpUqRFAQAA3EpuXp4szvb5ThV77qskyjdIXrlyRRMnTtTmzZuVl5cnSbJYLHriiSc0duxYubm52aVIAACA6yzOzhrz4XadPH+xSPdTp2olRXdrVaT7KOnyDZIxMTHau3evFixYoODgYEnSvn37FB0drZiYGE2YMMEuRQIAAPzeyfMXlfDDBUeXcVM9e/aUj4+PnJ2dtWnTJrm4uGjo0KHq2LGjJk6cqM8++0xeXl4aM2aMwsPDlZubq7Fjx+qbb75RWlqaqlevrm7duql379633EdeXp4WLVqk1atXKy0tTffff79effVVtW/f3o4j/ZPb/2zdulVvv/22wsPD5e7uLnd3d4WHh2vixInaunWrvWoEAAAoUTZu3KjKlStr7dq16tGjh8aPH68hQ4YoKChIGzduVMuWLTVy5EhlZmYqLy9P9957r959911t2bJFAwYM0MyZM/Xpp5/ecvsLFy7Upk2bNGHCBG3ZskV9+vTRiBEjtGfPHjuO8k+C5G+//SYvL68b2j09PfXbb78VeCcffvihOnXqpKZNm6pp06Z69tln9dVXX1mXX716VRMmTFCLFi0UFBSkQYMGKS0tzWYbKSkp6t+/v5o0aaKQkBBNmTKFe1kCAIBiqUGDBnr11Vd1//3366WXXlLZsmVVuXJlPfPMM7r//vs1YMAA/fLLLzp69KhcXFw0ePBgNW7cWLVq1dLjjz+uzp0767PPPrvptrOysrRw4UJNmjRJrVq1Uq1atdS5c2c9/vjjWr16tV3Hme+p7cDAQM2ePVtTp05V2bJlJV0Ll3PnzlVgYGCBd3Lvvfdq+PDhql27tgzD0KZNmzRgwABt3LhRDzzwgCZNmqSvvvpKs2bNkoeHhyZOnKiBAwdq1apVkqTc3Fy99NJL8vLy0qpVq3T+/HmNGjVKLi4uGjZs2G0MHwAA4M7z9fW1/myxWHTPPffIx8fH2nb9QF16erokaeXKlVq/fr1SUlJ09epVZWdnq0GDBjfd9unTp5WZmam+ffvatGdnZ6thw4Z3eij5yjdIRkVF6cUXX9Rf//pX62ASEhLk6uqq9957r8A7efjhh20ev/baa/roo48UFxene++9V+vXr9f06dMVEhIiSZo0aZIee+wxxcXFKTAwUDt27FBiYqKWLl0qLy8vNWzYUEOGDNH06dM1cOBAubq6FnbcAAAARaZMGduI5eTkZNPm5OQk6dqXvWzZskVTpkzRqFGjFBQUpAoVKmjJkiU6ePDgTbd95coVSddOb1erVs1mmb0zUb5B0tfXV//+97/1ySefWG//07FjR3Xq1EnlypUztcPc3Fx99tlnunLlioKCgnT48GFlZ2crNDTU2qdevXqqUaOGNUjGxcXJx8fH5jR7WFiYxo8fr8TERPn5+ZmqBQAAwNH279+voKAgde/e3dqWnJx8y/716tWTq6urUlJS1Lx5c3uUeEv5BsmFCxfK09NTzzzzjE37unXrdOHCBfXv37/AOzp69Kiee+45Xb16VeXLl9e8efNUv359HTlyRC4uLqpYsaJNf09PT6WmpkqS0tLSbvis5vXH1/sURm5uboH7WiyWQm+/uCnMeIHi6nbnIvMeKHnuhrlYELVr19amTZu0fft23Xfffdq8ebPi4+N133333bS/u7u7+vbtq8mTJ8swDAUHB+vSpUvav3+/3N3d7fo11vkGydWrV2v69Ok3tD/wwAN67bXXChUk69Spo02bNunSpUvaunWrRo0apQ8++KDwFd8B8fHxBern5uZ2VxztPHr0qDIzMx1dBnBbrt+CzCzmPVDy5Dfv61StVOT7t8c+JOm5557TkSNH9Nprr8nJyUkdOnRQt27d9PXXX99ynaFDh6pKlSpauHChzp49Kw8PD/n5+enll1+2S83X5RskU1NT5e3tfUN7lSpVCn0k0NXVVbVr15Yk+fv7Kz4+XsuXL9ejjz6q7OxsZWRk2ByVTE9Pt+7by8tLhw4dstne9au6b1bfn2ncuHGp+StHsv3AL1BaMe+Bu0duXp7dbhRu5pttbvYV01988cUNbUePHrX+PHnyZE2ePNlm+euvv279OSYmxmaZk5OTevfune+9Ju0h3yBZvXp17d+/X7Vq1bJp37dvn6pWrXpbO87Ly1NWVpb8/f3l4uKiXbt2qV27dpKkpKQkpaSkWK8MDwwMVGxsrNLT0+Xp6SlJ2rlzp9zd3VW/fv1C79tisZSqN5TSNFbgVpj3wN3Dnl9ZyNcj5i/fIPn0009r0qRJysnJ0UMPPSRJ2rVrl6ZNm3bDJef5mTFjhv7617+qevXqunz5sv75z39qz549WrJkiTw8PNSlSxfFxMSoUqVKcnd3V3R0tIKCgqxBMiwsTPXr19fIkSM1YsQIpaamatasWerevTtXbAMAADhIvkHyxRdf1C+//KIJEyYoOztbklS2bFm9+OKLeumllwq8k/T0dI0aNUrnz5+Xh4eHfH19tWTJErVs2VLStdsMOTs7a/DgwcrKylJYWJjGjRtnXd9isSg2Nlbjx4/Xs88+Kzc3N0VERGjw4MFmxgwAAIA7wMkwDOPPOl2+fFknTpxQuXLldP/995fYo4C5ubnWWwoV5rRP91n/LLbf55mfBjWraOXQjo4uA3Ao5j0AFJ18j0heV6FCBQUEBBR1LQAAAChB+AQpAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAMAdZBiGxo4dq+bNm8vX11dHjhxxSB1nz54t8v0X6KptAACA4sLIy5WTs32+vcnMvr7++mtt3LhRy5cvV61atVS5cuUiqs7xCJIAAKBEcXK2KG1DpLLTkop0Py5edeXVOebPO/7BmTNn5O3traZNmxZBVcULQRIAAJQ42WlJyv7JMaeM8xMZGamNGzdKknx9fVWzZk1t27ZNixYt0urVq5WWlqb7779fr776qtq3by9J2r17t3r16qXFixdrxowZSkpKUmBgoGbOnKnDhw8rJiZG586dU+vWrRUdHS03NzdJ1458LliwQMePH5fFYlFgYKDeeOMN/eUvf7llfceOHdPUqVO1b98+ubm5qWXLlho9erSqVKliarx8RhIAAOAOeeONNzR48GDde++92rFjh9atW6eFCxdq06ZNmjBhgrZs2aI+ffpoxIgR2rNnj826c+fO1dixY7Vq1Sr99NNPGjp0qJYvX64ZM2boH//4h3bs2KEVK1ZY+2dmZur555/X+vXr9f7778vJyUkDBgxQXl7eTWvLyMhQ79695efnp3Xr1mnx4sVKT0/X0KFDTY+XI5IAAAB3iIeHhypUqCCLxSJvb29lZWVp4cKFWrp0qYKCgiRJtWrV0r59+7R69Wo1b97cuu7QoUMVHBwsSXrqqac0Y8YMbdu2TbVq1ZIktWvXTrt371b//v2tj39v0qRJCgkJUWJionx8fG6o7YMPPpCfn5+GDRtms054eLhOnjypOnXqFHq8BEkAAIAicvr0aWVmZqpv37427dnZ2WrYsKFNm6+vr/VnT09Pubm5WUOkJHl5eSk+Pt76+NSpU5o9e7YOHjyon3/+WYZhSJJ+/PHHmwbJhIQE7d692xpofy85OZkgCQAAUJxcuXJFkrRw4UJVq1bNZpmrq6vN4zJl/hfLnJycbB5fb/v9aeuXX35ZNWvWVHR0tKpWraq8vDx17NhR2dnZt6yldevWGj58+A3LvL29Czew6zWbWgsAAAB/ql69enJ1dVVKSorNaezb9fPPP+vkyZOKjo5Ws2bNJEnffvttvus0atRIW7duVc2aNW8IqWYRJAEAAIqIu7u7+vbtq8mTJ8swDAUHB+vSpUvav3+/3N3dFRERYWq7lSpV0j333KPVq1fL29tbKSkpmjFjRr7rdOvWTWvWrNGwYcP04osv6p577tHp06f16aefKjo6WhZL4e/NSZAEAAAljotX3RKzj6FDh6pKlSpauHChzp49Kw8PD/n5+enll182vU1nZ2fNnDlT0dHR6tixo+rUqaMxY8aoZ8+et1ynWrVq+uijjzR9+nS98MILysrKUo0aNdSqVSs5O5u7kY+Tcf2TmaVAbm6u4uLiFBgYWKjU3X3WP5Xww4UirKxoNKhZRSuHdnR0GYBDMe+Bu09x/2ab0oT7SAIAgBLFnsGOEJk/giQA3EU8PcrJyMt1dBm3paTXD5QmfEYSAO4iHuVc7fY9xEXB7HcbA3AMgiQA3IWK6/cQA7i7cGobAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRIAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKbYJUguXLhQXbp0UVBQkEJCQvTqq68qKSnJps/Vq1c1YcIEtWjRQkFBQRo0aJDS0tJs+qSkpKh///5q0qSJQkJCNGXKFOXk5NhjCAAAAPgDuwTJPXv2qHv37lqzZo2WLl2qnJwcvfDCC7py5Yq1z6RJk/Sf//xHs2bN0ooVK3T+/HkNHDjQujw3N1cvvfSSsrOztWrVKsXExGjjxo2aPXu2PYYAAACAP7BLkFyyZIk6d+6sBx54QA0aNFBMTIxSUlL03XffSZIuXbqk9evXKzIyUiEhIfL399ekSZN04MABxcXFSZJ27NihxMRETZs2TQ0bNlR4eLiGDBmilStXKisryx7DAAAAwO+UccROL126JEmqVKmSJOnw4cPKzs5WaGiotU+9evVUo0YNxcXFKTAwUHFxcfLx8ZGXl5e1T1hYmMaPH6/ExET5+fkVeP+5ubkF7muxWArct7gqzHiB4up252Jpm/clHb+3IDEXSwK7B8m8vDxNmjRJTZs2lY+PjyQpLS1NLi4uqlixok1fT09PpaamWvv8PkRKsj6+3qeg4uPjC9TPzc2tUAG1uPH0KCcjL7dET8S83Bwd/u57ZWdnO7oUOFhwcPBtrV9a5v3d4ujRo8rMzHR0GXCw2533KHp2D5ITJkzQ8ePH9eGHH9p711aNGzcu0eGqoDzKucrJ2aK0DZHKTkv68xWKGRevuvLqHKNGjRo5uhTcBUrLvL9b+Pr6OroEAAVg1yD51ltv6csvv9QHH3yge++919ru5eWl7OxsZWRk2ByVTE9Pl7e3t7XPoUOHbLZ3/aru630KymKxlKo3lOy0JGX/dMTRZZhWml4rFJ3SNu9LOl4roGSwy8U2hmHorbfe0ueff65ly5apVq1aNsv9/f3l4uKiXbt2WduSkpKUkpKiwMBASVJgYKCOHTum9PR0a5+dO3fK3d1d9evXt8cwAAAA8Dt2OSI5YcIE/fOf/9T8+fNVoUIF62caPTw8VK5cOXl4eKhLly6KiYlRpUqV5O7urujoaAUFBVmDZFhYmOrXr6+RI0dqxIgRSk1N1axZs9S9e3e5urraYxi4C+Xm5cniXDLvy1+SawcA3B3sEiQ/+ugjSVLPnj1t2idPnqzOnTtLkqKiouTs7KzBgwcrKytLYWFhGjdunLWvxWJRbGysxo8fr2effVZubm6KiIjQ4MGD7TEE3KUszs4a8+F2nTx/0dGlFEqdqpUU3a2Vo8sAAJRydgmSR48e/dM+ZcuW1bhx42zC4x/VrFlTixYtupOlATp5/qISfrjg6DIAAChxOC8GAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABT7BYk9+7dq5dffllhYWHy9fXVtm3bbJYbhqF3331XYWFhCggIUJ8+fXTq1CmbPr/88otef/11NW3aVM2aNVNUVJQuX75sryEAxYanRzkZebmOLuO2lPT6AQBSGXvt6MqVK/L19VWXLl00cODAG5YvWrRIK1asUExMjO677z69++67euGFF/Tpp5+qbNmykqThw4crNTVVS5cuVXZ2tqKiovTmm29qxowZ9hoGUCx4lHOVk7NFaRsilZ2W5OhyCs3Fq668Osc4ugwAwG2yW5AMDw9XeHj4TZcZhqHly5frlVde0SOPPCJJmjp1qkJDQ7Vt2zZ16NBBJ06c0Pbt27Vu3To1btxYkjRmzBj1799fI0eOVLVq1ew1FKDYyE5LUvZPRxxdBgCglLJbkMzP2bNnlZqaqtDQUGubh4eHmjRpogMHDqhDhw46cOCAKlasaA2RkhQaGipnZ2cdOnRIbdq0KfD+cnMLfkrNYrEUuC+KRmFer8Li9XUse85F5n3JUpTzHiUHc7H4KxZBMjU1VZLk6elp0+7p6am0tDRJUlpamqpUqWKzvEyZMqpUqZJ1/YKKj48vUD83Nzf5+fkVatu4844eParMzMw7vl1eX8crzGsbHBx8W/ti3pcsRTXvUbLc7rxH0SsWQdLeGjduzF85JYivr6+jS0ARsedry7wvWZj3QMlQLIKkt7e3JCk9PV1Vq1a1tqenp6tBgwaSJC8vL124cMFmvZycHF28eNG6fkFZLBbeUEoQXqu7lz1fW+Z9ycJrBZQMxeI+kvfdd5+8vb21a9cua9uvv/6qgwcPKigoSJIUFBSkjIwMHT582Nrnm2++UV5engICAuxeMwAAQGlntyOSly9fVnJysvXx2bNndeTIEVWqVEk1atRQr169tGDBAtWuXdt6+5+qVatar+KuV6+eWrVqpbFjx2rChAnKzs7WxIkT1aFDB67YBgAAcAC7BcnDhw+rV69e1seTJ0+WJEVERCgmJkb9+vVTZmam3nzzTWVkZCg4OFiLFy+23kNSkqZPn66JEyeqd+/ecnZ2Vtu2bTVmzBh7DQEAAAC/Y7cg2aJFCx09evSWy52cnDRkyBANGTLkln3uuecebj4OAABQTBSLz0gCAACg5CFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAADAFIIkAAAATCFIAgAAwBSCJAAAAEwhSAIAAMAUgiQAAABMIUgCAFCCGHm5ji7BtJJcO26ujKMLAAAABefkbFHahkhlpyU5upRCcfGqK6/OMY4uA3cYQRIAUKrk5uXJ4lyyT8hlpyUp+6cjji4DIEgCAEoXi7Ozxny4XSfPX3R0KYUW6ltDAx5t6ugyACuCJACg1Dl5/qISfrjg6DIK7X7vio4uAbBRso/tAwAAwGEIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFMIkgAAADCFIAkAAABTCJIAAAAwhSAJAAAAUwiSAAAAMIUgCQAAAFNKXJBcuXKlHn74YTVu3FhPP/20Dh065OiSAAAASqUSFSQ//fRTTZ48WQMGDNDGjRvVoEEDvfDCC0pPT3d0aQAAAKVOiQqSS5cu1TPPPKMuXbqofv36mjBhgsqVK6f169c7ujQAAIBSp8QEyaysLH333XcKDQ21tjk7Oys0NFQHDhxwYGUAAAClUxlHF1BQP//8s3Jzc+Xp6WnT7unpqaSkpAJtwzAMSddCqcViKdA6FotFD9xbSa4Wp8IVXAzU8qyg3NxcWbx9lOfs6uhyCs3ieb9yc3OVm5tbdPsooa9vaXxtLRaLnJ2d5eRUuNeKeV+yMO/zV5JfX3vOe9iPk3H9t2wxd+7cOf31r3/VqlWrFBQUZG2fOnWq9u7dq7Vr1/7pNrKyshQfH1+UZQIoQoGBgQUOg9cx74GSzcy8h/2UmCOSlStXlsViueHCmvT0dHl5eRVoG2XKlFHjxo356wYooZydC/9pHOY9ULKZmfewnxITJF1dXdWoUSPt2rVLjzzyiCQpLy9Pu3btUo8ePQq0DWdnZ7m6lqxTAQBuD/MeAIpOiQmSkvT8889r1KhR8vf3V0BAgJYtW6bMzEx17tzZ0aUBAACUOiUqSD722GO6cOGCZs+erdTUVDVs2FCLFy8u8KltAAAA3Dkl5mIbAAAAFC98ghUAAACmECQBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQbKE2bRpk1q0aKGsrCyb9ldffVUjRoyQJG3btk0RERFq3Lix/v73v2vu3LnKycmRJBmGoTlz5uhvf/ub/P39FRYWpujoaLuPAwXTs2dPRUdHa+rUqWrevLlatmypOXPmWJenpKTolVdeUVBQkJo2baohQ4YoLS3NgRWjqDD3Sw/mPUoUAyVKZmamERwcbHz66afWtrS0NMPPz8/YtWuXsXfvXqNp06bGhg0bjOTkZGPHjh1G69atjTlz5hiGYRj/+te/jKZNmxpffvml8cMPPxgHDx40Vq9e7ajh4E/06NHDaNq0qTFnzhzj5MmTxsaNGw1fX19jx44dRm5urvHEE08YXbt2NeLj4424uDgjIiLC6NGjh6PLRhFg7pcezHuUJATJEmjcuHHGiy++aH383nvvGX//+9+NvLw8o3fv3kZsbKxN/02bNhktW7a09m3btq2RlZVl15phTo8ePYyuXbvatHXp0sWYNm2asWPHDqNhw4ZGSkqKddnx48cNHx8f4+DBg/YuFXbA3C8dmPcoSUrUVyTimmeeeUZPPfWUzp07p2rVqmnDhg2KiIiQk5OTEhIStH//fsXGxlr75+bm6urVq8rMzFT79u21bNkyPfLII2rVqpXCw8PVunVrlSnDf4XiytfX1+axt7e30tPTdeLECd17772qXr26dVn9+vVVsWJFJSUlKSAgwN6loogx90sP5j1KCn6DlEB+fn5q0KCBNm3apJYtWyoxMVGdO3eWJF25ckWDBg1S27Ztb1ivbNmyql69uj777DPt3LlTO3fu1IQJE7RkyRKtWLFCLi4u9h4KCuCPb/ROTk4y+GbTUom5X3ow71FSECRLqKeeekrLli3TuXPnFBoaav3r1M/PTydPnlTt2rVvuW65cuX08MMP6+GHH1a3bt306KOP6tixY2rUqJG9yscdUK9ePf3000/68ccfra9/YmKiMjIyVK9ePQdXh6LC3C/dmPcobrhqu4Tq1KmTzp07pzVr1qhLly7W9gEDBmjz5s2aO3eujh8/rhMnTmjLli2aOXOmJGnDhg1au3atjh07pjNnzujjjz9WuXLlVKNGDUcNBSaFhobKx8dHw4cP13fffadDhw5p5MiRat68uRo3buzo8lBEmPulG/MexQ1BsoTy8PBQ27ZtVaFCBT3yyCPW9latWik2NlY7duzQU089pWeeeUbvv/++atasKUmqWLGi1q5dq65du+rxxx/Xrl27FBsbq8qVKztqKDDJyclJ8+fPV8WKFdWjRw/16dNHtWrVsgYH3J2Y+6Ub8x7FjZPBhy5KrN69e+uBBx7QmDFjHF0KADti7gMoLjgiWQJdvHhRn3/+ufbs2aNu3bo5uhwAdsLcB1DccLFNCRQREaGLFy9q+PDhqlu3rqPLAWAnzH0AxQ2ntgEAAGAKp7YBAABgCkESAAAAphAkAQAAYApBEgAAAKYQJAEAAGAKQRKlzu7du+Xr66uMjIxb9tmwYYOaNWtmx6oAFCXmPVA0CJIodYKCgrRjxw55eHg4uhQAdsK8B4oGQRLFRlZWll324+rqKm9vbzk5OdllfwBujXkPlGx8sw0cpmfPnnrggQdksVj08ccfy8fHR2PHjtXUqVO1b98+ubm5qWXLlho9erSqVKlis44kbd68WWXKlFHXrl01ZMgQ6xvEpk2btHz5cp08eVLly5fXQw89pKioKHl6ekq6doqrV69e2rt3rypWrCjp2imt2bNn6+eff1ZYWJiCg4Md8IwAdz/mPXB34YgkHGrjxo1ycXHRRx99pOHDh6t3797y8/PTunXrtHjxYqWnp2vo0KE3rGOxWLR27Vq98cYbev/997V27Vrr8pycHA0ZMkQff/yx5s2bpx9++EGRkZG3rOHgwYN644031L17d23atEktWrTQggULimzMQGnHvAfuHhyRhEPdf//9GjlypCRp/vz58vPz07Bhw6zLJ02apPDwcJ08eVJ16tSRJFWvXl1RUVFycnJS3bp1dezYMb3//vt65plnJElPPfWUdf1atWrpjTfe0FNPPaXLly+rQoUKN9SwfPlytWrVSv369ZMk1alTRwcOHND27duLbNxAaca8B+4eBEk4VKNGjaw/JyQkaPfu3QoKCrqhX3Jy8v9r745ZUgvjOI7/btbg4KAQkg4NOgQNnhfgEjgFYUsIgi5nchUhxK0gGxylRSQooTfQUIOTvQHFoSURBc/aWUQI6w6XvEj3xuXhVhrfz3TO4eF5zoHz5/lxznM4swklFovNrXOyLEvn5+eaTqfyeDzqdruqVqu6v7+X67p6/Z284ziKRqNv+n54eFAikZg7ZlkWEwrwQah74PsgSOJLeb3e2fZ4PNbOzo4KhcKbduvr6//U33g8lm3bisfjqlQq8vv9chxHtm3r6enpv503AHPUPfB9ECSxMLa3t3V7e6twOKzV1b/fmp1OZ26/3W5rc3NTHo9HvV5Pj4+PKhQK2tjYkCR1u913x41EIn/sE8DHo+6B5cbHNlgY6XRarusqn8+r0+loMBio1WqpWCxqOp3O2o1GI5XLZfV6PV1fX6vRaCibzUqSQqGQ1tbWdHl5qeFwqGazqbOzs3fHzWQyarVaqtfr6vf7ajQavN4CPgl1Dyw3giQWRjAY1NXVlZ6fn2Xbtvb29nRyciKfz6eVld+36v7+viaTiQ4ODnR0dKRsNqtUKiVJCgQCOj091c3NjXZ3atbntQAAALRJREFUd1Wr1XR4ePjuuJZl6fj4WBcXF0omk7q7u1Mul/vQawXwC3UPLLcfL68rkoElkMlktLW1pVKp9NWnAuCTUPfA4uKJJAAAAIwQJAEAAGCEV9sAAAAwwhNJAAAAGCFIAgAAwAhBEgAAAEYIkgAAADBCkAQAAIARgiQAAACMECQBAABghCAJAAAAIwRJAAAAGCFIAgAAwAhBEgAAAEYIkgAAADBCkAQAAIARgiQAAACM/ARyLq9p/G9qbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image(filename=\"img/gender_compare.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The first thing that is apparent in the plot is that our model overestimates how many that end up paying back. This is a problem, but it is not relevant to fairness.\n",
    "What is relevant to fairness is the proportions of males/females that are predicted to repay. In the true data the proportions of men and women seems aproximately equal within those who repaied and those who did not. This sugests that gender should not be very relevant in predicting wether someone repayes. That is however not the case in our predicted response. Our model greatly favors males even though the true data tells us that it shouldn't.\n",
    "\n",
    "### Fairness: balance of genders\n",
    "\n",
    "When it comes to balance w.r.t. gender as a concept of fairness. We can look at balance as the concept: if we knew the true response ($y$), the policy would have been independent w.r.t. to the action ($a$) when considering the sensitive variable (Dimitrakakis, 2020, p. 104). In our case, that would mean that the policy should have similar distributions for women and for men given that we know whether or not the individual repaid ($y$). This also makes sense intuitively as a concept of fairness. If the loan actually was repaid and all the other covariates held equal, gender should not influence the action of the policy.\n",
    "\n",
    "Formulated as an equation, this should approximately hold if the policy is balanced w.r.t. gender\n",
    "\n",
    "$$\n",
    "P^{\\pi}(a|y, z = \\text{male}) = P^{\\pi}(a|y, z = \\text{female})\n",
    "$$\n",
    "\n",
    "this should hold for y = 0/1 and z = male/female. Adapted from (Dimitrakakis, 2020, p. 105). In order to evaluate the fairness w.r.t. gender, we need to look at the output of the policy on the test set. Because our sensitive variable is gender and we want the action to be fair (independent on gender), we should separate the policy outcomes for the sensitive variables and then look at a and y based on this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image(filename=\"img/gender_balance.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The histogram shows a graphical representation of the equation above that should hold approximately for balanced policies. The label 'predicted' in the histogram is equivalent to $a$ in the equation while 'true' corresponds to $y$. Note that this histogram has been created by using data from a random train/test split with test size = 0.25.\n",
    "\n",
    "We can compare $P^{\\pi}(a|y, z=\\text{male})$ with $P^{\\pi}(a|y, z=\\text{female})$ by looking at the proportions of $a$ for different values of $y$ and $z$. Looking at these proportions we get:   \n",
    "\n",
    "(a=1, a=0)\n",
    "\n",
    "|                 | Male (z=1)        | Female (z=0)    |\n",
    "|-----------------|-------------------|-----------------|\n",
    "| No default (y=1)| (0.9286, 0.0714)  | (0.9, 0.1)      |\n",
    "| Default (y=0)   | (0.8936, 0.1064)  | (0.6667, 0.3332)|\n",
    "\n",
    "From the table, we can see that for the different genders, the proportion of $a=1$ was approximately equal when $y=1$, but for $y=0$ it seems like the proportion for $a=1$ is lower for women than for men.  \n",
    "\n",
    "This would imply \n",
    "\n",
    "$$\n",
    "P^{\\pi}(a=1|y=0,z=\\text{male}) > P^{\\pi}(a=1|y=0, z=\\text{female})\n",
    "$$ \n",
    "\n",
    "That is, men has a higher probability of getting accepted for credit than women when we look at those who did not repay. This again would imply that the policy is not balanced based on the equation above because it does not (approximately) hold for $y=0$.\n",
    "Consider relative frequency as a simplification of the probability distribution. The probability of event X can then be estimated with $\\frac{n(X)}{n}$ where n is the total number of observation and $n(X)$ is the number of $X$ (Devore & Berk, 2012, p. 58). We can then look at the total variation distance which is defined as\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{a \\in A} |P(a|y, z=\\text{male}) - P(a|y, z=\\text{female})| \n",
    "$$\n",
    "\n",
    "adapted from (Wikipedia, 2020). We can then use the estimated relative frequencies in the table above to estimate the total variation distance, we would then have the total variation distance for the â€œprobability distributionâ€ of the decisions $a$ that were made when the individuals repaid $y=1$\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}(|P(a=0|y=1, z=\\text{male}) - P(a=0|y=1, z=\\text{female})| + \\\\ |P(a=1|y=1, z=\\text{male}) - P(a=1|y=1, z=\\text{female})|)\n",
    "$$\n",
    "\n",
    "And the total variation distance when the individuals did not repay ($y=0$)\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}(|P(a=0|y=0, z=\\text{male}) - P(a=0|y=0, z=\\text{female})| + \\\\ |P(a=1|y=0, z=\\text{male}) - P(a=1|y=0, z=\\text{female})|)\n",
    "$$\n",
    "\n",
    "thus looking at the estimated probability distribution of the decision $a$ in the cases $y=1$ and $y=0$.\n",
    "\n",
    "From these approximations to the total variation distance, we see that the total variation distance for the case $y=1$ is relatively small compared to the case when $y=0$. From this, we can see that for outcome $y=0$, the total variation distance is greater than for the outcome $y=1$. This reflect the histogram above and states that the â€œdistributionâ€ among those who did not repay ($y=0$) has more variation between the genders than the â€œdistributionâ€ among those who did repay ($y=1$).\n",
    "\n",
    "\n",
    "### What would happen if fairness also would consider the amount of loan requested?\n",
    "\n",
    "We could look at fairness when taking the amount of loan requested into account by checking the sensitive variable $z$, which in our case is gender of the individual applying for a loan. We would like to check the fairness metric \n",
    "\n",
    "$$\n",
    "F(\\theta, \\pi) = \\sum_{y, z, a} (P_{\\theta}^{\\pi}(a|z, y) - P_{\\theta}^{\\pi}(a|y))^{2}\n",
    "$$\n",
    "\n",
    "Adapted from (Dimitrakakis, 2020, p. 107). We simplify and use relative frequency for the different measures of probability in the metric above. From the metric, the unfairness in balance is 0 when the two genders have equal probability of being accepted credit $a=1$ and being denied credit $a=0$ given the different values of the true response $y$. We see from the data that the median amount in the dataset was 2319.5, we therefore make a threshold for this value and check the fairness metric for amounts larger than this and lower than this. We use 10 repeated 5-fold cross validation in order to ensure stable values that do not depend to much on randomness in the data. We see that the \n",
    "\n",
    "$$\n",
    "F(\\theta, \\pi) \\approx 0.0699\n",
    "$$\n",
    "\n",
    ", while for amounts below the median, \n",
    "\n",
    "$$ \n",
    "F(\\theta, \\pi) \\approx 0.0909\n",
    "$$ \n",
    "\n",
    "and for amounts above the median \n",
    "\n",
    "$$ \n",
    "F(\\theta, \\pi) \\approx 0.0969\n",
    "$$ \n",
    "\n",
    "This implies that the degree of unfairness has increased when taking the amount requested into account when calculating fairness.\n",
    "\n",
    "We also checked the gender ratios among the 10 % largest amounts when performing repeated cross validation. We then check the ratio of male/females being granted credit ($a=1$) among the largest amount of loans. This could give an indication of why there is more unfairness according to the metric above when it comes to the loans with the largest amounts. This is done by calculating the number of granted applications for males and females among the largest 10 % of the loan applications. This is calculated in the method â€˜calculate_balance_ratiosâ€™. When averaging the results from a repeated cross validation, this returned '(male, female) ratio = 0.624, 0.257'. We see that this points toward men being overrepresented among the top 10 % of the applicants who did apply and was granted the largest loans. So the amount of loan seem to imply that men more often is granted the loans with the largest amounts.\n",
    "\n",
    "\n",
    "### Stochastic gradient descent to find a policy that balances out fairness and utility\n",
    "\n",
    "First, looking at â€œhow muchâ€ the policy breaches the balance criterion can be defined as \n",
    "$$\n",
    "F(\\theta, \\pi) = \\sum_{a, y, z} |P_{\\theta}^{\\pi}(a|y, z) - P_{\\theta}^{\\pi}(a|y)|^{2}\n",
    "$$\n",
    "and then looking at the general utility $U(\\theta, \\pi) = P^{\\pi}_{\\theta}(y = a)$, that is, the distribution of correctly classified individuals given the $\\theta$ and the policy $\\pi$. The two are then combined in order to define the â€œvalueâ€ of a policy \n",
    "\n",
    "$$\n",
    "V(\\lambda, \\theta, \\pi) = (1-\\lambda)U(\\theta, \\pi) - \\lambda F(\\theta, \\pi)\n",
    "$$\n",
    "\n",
    "This derivation is adapted from (Dimitrakakis, 2020, pp. 107-108). From the definition above, we see that this value requires $\\theta$ and this is unknown.\n",
    "\n",
    "We can then define the expected value of the policy\n",
    "$$\n",
    "V(\\lambda, \\xi, \\pi) = \\int [(1-\\lambda)U(\\theta, \\pi) - \\lambda F(\\theta, \\pi)] d\\xi (\\theta)\n",
    "$$\n",
    "\n",
    "Adapted from from. The subjective distribution $\\xi$ could be estimated by a prior and a likelihood (Dimitrakakis, 2020, pp. 108-109). We see that this the integral that has to be solved over the different subjective beliefs in order to find the expected value of the policy $\\pi$ for a specific $\\lambda$.  \n",
    "\n",
    "#### Finding the posterior distribution of $\\theta$\n",
    "\n",
    "First, we need to define the posterior distribution for $\\theta$ so we can sample from it. Because we know that the values of the response $y \\in \\{0,1\\}$, we see that if we define $p*=\\frac{e^{\\beta_{0} + \\vec{\\beta}^{T} \\cdot \\vec{x}}}{1 + e^{\\beta_{0} + \\vec{\\beta}^{T} \\cdot \\vec{x}}}$, the probability for $y=1$ with the logistic regression, this corresponds to each $y$ being Bernoulli distributed. We also assume the $y$s are independent so that the likelihood is the product of the individual likelihoods. \n",
    "We also assume that the $y$s are independent which implies $p(y_{1}, â€¦ , y_{n}) = p(y_{1})â€¦p(y_{n})$ (Devore & Berk, 2012, p. 354). This gives the likelihood function\n",
    "$$\n",
    "p(\\vec{y} |\\vec{\\beta}) = \\prod_{i=1}^{n} p*^{y_{i}}(1-p*)^{1-y_{i}}\n",
    "$$\n",
    "Which becomes\n",
    "$$\n",
    "log(p(\\vec{y} |\\vec{\\beta})) = \\sum_{i=1}^{n} y_{i}log(p*) + (1-y_{i})log(1-p*)\n",
    "$$\n",
    "\n",
    "In our case $\\theta = \\vec{\\beta}$ because we are using a logistic regression as a model. We therefore use the Bayesian approach\n",
    "$$\n",
    "p(\\vec{\\beta}) \\propto p(\\vec{y} | \\vec{\\beta})p(\\vec{\\beta})\n",
    "$$\n",
    "adapted from (Gelman et al., 2014, p. 63). We assume that the priors are normally distributed to begin with, that is \n",
    "\n",
    "$$\n",
    "\\beta \\sim N(\\mu, \\sigma^{2})\n",
    "$$\n",
    "\n",
    "This gives that the posterior joint distribution is\n",
    "$$\n",
    "p(\\vec{\\beta}) \\propto p(\\vec{y} |\\vec{\\beta}) = \\prod_{i=1}^{n} p*^{y_{i}}(1-p*)^{1-y_{i}}\n",
    "$$\n",
    "We are then able to sample from the joint posterior distribution of $\\theta$.\n",
    "\n",
    "#### Policy $\\pi$\n",
    "\n",
    "The policy $\\pi (a|x)$ can be parametrized as a softmax policy to give \n",
    "$$\n",
    "\\pi_{\\beta} = \\frac{e^{\\beta^{T}x}}{1+ e^{\\beta^{T}x}}\n",
    "$$\n",
    "Together with another form of the expected value of the policy, we can define that the following integral should be maximized w.r.t. $\\pi_{\\beta}$\n",
    "$$\n",
    "\\int [(1-\\lambda)E_{\\theta}^{\\pi_\\beta}[U(\\theta, \\pi_{\\beta}) - \\lambda F(\\theta, \\pi_{\\beta})] d\\xi (\\theta)\n",
    "$$\n",
    "Adapted from (Dimitrakakis et al., 2017). For $\\theta$ values sampled from the $\\xi$ distribution, we would like to maximize this expected utility for the policy. Because $\\theta$ is present in the equation through $\\pi_{\\theta}$ we need the gradient of this policy. In general we could write\n",
    "$$\n",
    "\\nabla_{\\pi} V(\\lambda, \\xi, \\pi) = \\int [(1-\\lambda) \\nabla E_{\\theta}^{\\pi_\\beta}[U(\\theta, \\pi_{\\beta}) - \\lambda \\nabla F(\\theta, \\pi_{\\beta})] d\\xi (\\theta)\n",
    "$$\n",
    "This can be maximized for a given $\\lambda$ which is a parameter that balances the amount of utility versus the degree of fairness. We can also look at the gradient ascent for both the gained utility and the imbalance of fairness (cost). \n",
    "This can be summarized as \n",
    "$$\n",
    "\\sum_{x,y} \\sum_{a} \\pi_{\\theta}(a|x) U(a, y) - \\sum_{x,y} \\sum_{a} \\pi_{\\theta}(a|x) F(\\theta, \\pi_{\\beta})\n",
    "$$\n",
    "\n",
    "As the total quantity that we would like to maximize, given a $\\lambda$ (Dimitrakakis, 2020, pp. 65). When taking the gradient of the different parts in the equation above, we can split it into the utility part and the â€œdeviance from fairnessâ€ part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss in fairness, $\\nabla F(\\theta, \\pi)$\n",
    "We then get\n",
    "$$\n",
    "\\nabla \\sum_{a, y, z} (P_{\\theta}^{\\pi} (a|y, z) - P_{\\theta}^{\\pi} (a|y, zâ€™))^{2} \\\\\n",
    "\\sum_{a, y, z} \\nabla (P_{\\theta}^{\\pi} (a|y, z) - P_{\\theta}^{\\pi} (a|y, zâ€™))^{2} \\\\\n",
    "\\sum_{a, y, z} 2(P_{\\theta}^{\\pi} (a|y, z) - P_{\\theta}^{\\pi} (a|y, zâ€™))(\\nabla P - \\nabla Pâ€™)\n",
    "$$\n",
    "We also use that \n",
    "$$\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) P(x|a, z) \\\\\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) \\frac{P(a, x, z)}{P(a, z)} \\\\\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) \\frac{P(a|x, z)P(x, z)}{P(a|z)P(z)} \\\\\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) \\frac{P(a|x, z)P(x|z)P(z)}{P(a|z)P(z)} \\\\\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) \\frac{P(a|x, z)P(x|z)}{P(a|z)} \\\\\n",
    "P_{\\theta}^{\\pi} = \\sum_{x} P_{\\theta} (y|a, x, z) P(x|z) \\frac{\\pi(a|x, z)}{\\pi(a|z)} \\\\\n",
    "$$\n",
    "Adapted from (University of Oslo, 2020). And then looking at $\\nabla F(\\theta, \\pi)$\n",
    "$$\n",
    "\\nabla F(\\theta, \\pi) = \\sum_{a, y, z} 2(P_{\\theta}^{\\pi} (a|y, z) - P_{\\theta}^{\\pi} (a|y, zâ€™)) ( \\sum_{x} P_{\\theta} (y|a, x, z) P(x|z) \\nabla \\frac{\\pi(a|x, z)}{\\pi(a|z)} - \\sum_{x} Pâ€™_{\\theta} (y|a, x, z) P(x|z) \\nabla \\frac{\\pi(a|x, zâ€™)}{\\pi(a|zâ€™)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient of utility, $\\nabla U(\\theta, \\pi)$\n",
    "For the utility, this can be expressed as a gradient of the utility of all observations, if we use the simplification\n",
    "$$\n",
    "U(\\theta, \\pi) = \\sum_{x, y} \\sum_{a} U(a, x, y) \\pi_{\\beta} (a|x)\n",
    "$$\n",
    "We then have\n",
    "$$\n",
    "\\nabla U(\\theta, \\pi) = \\sum_{x, y} \\sum_{a} U(a, x, y) \\nabla \\pi_{\\beta} (a|x)\n",
    "$$\n",
    "Adapted from (Dimitrakakis, 2020, p. 65). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient of policy\n",
    "We see from the expressions above that we need the gradient of the policy in order to continue. We then look at the scenario where the data used in the model is regarded as a constant. We can then find the components of the gradient by normal partial derivatives of the policy w.r.t. the different $\\beta$ variables. In general, we then get \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\beta_{i}} \\pi_{\\beta} = \\frac{x_{i} \\cdot (e^{\\beta^{T}x} + 1) - e^{\\beta^{T}x} x_{i} e^{\\beta^{T}x}}{(e^{\\beta^{T}x} + 1)^{2}} \\\\\n",
    "= \\frac{ x_{i} e^{\\beta^{T}x}}{(e^{\\beta^{T}x} + 1)^{2}}\n",
    "$$\n",
    "The cross-entropy loss function can then be defined\n",
    "$$\n",
    "L = -(y log(\\pi_{\\beta}) + (1-y) log(1 - \\pi_{\\beta}))\n",
    "$$\n",
    "Adapted from (Hastie et al., 2016, p. 309). When using p* given the model trained on the existing data we want to use stochastic gradient descent to optimize policy $\\pi_{\\beta}$ for all the training observations by varying the $\\beta$ value sin the policy. In order to minimize the loss $L$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta_{i}}  = -(\\frac{y}{\\pi_{\\beta}} \\cdot \\frac{\\partial \\pi_{\\beta}}{\\partial \\beta_{i}} â€“ (1-y) \\frac{1}{1 - \\pi_{\\beta}} \\cdot \\frac{\\partial \\pi_{\\beta}}{\\partial \\beta_{i}}\n",
    "$$\n",
    "We could then, in theory use this loss together with the loss function and stochastic gradient descent in order to find a policy $\\pi_{\\beta}$ that maximizes the balanced value. As mentioned in (Dimitrakakis et al., 2017) this involves maximizing the value policy $\\pi_{\\beta}$ over the data using the integral shown above. When looking at the $\\lambda$ we see that setting this to 0 would yield the integral over utility and we would ignore loss in fairness $F$. In that sense we would have to fix the $\\lambda$ and then attempt to find the optimal policy $\\pi$ that adheres to the given balance between utility and loss of fairness.\n",
    "\n",
    "Note: we started implementing the stochastic gradient method in the 'stochastic_gradient' method within the file 'fairness_analysis' but did not manage to finish the implementation in time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing questions\n",
    "\n",
    "## How can we measure whether our policy is fair?\n",
    "\n",
    "Measuring fairness is a complex process when it comes to policies within machine learning. We could both look at calibration (probability distribution for outcome $y$ conditional on the action $a$ should be similar for all different values of the sensitive variable $z$) and balance (probability distribution for action $a$ should be similar conditional on outcome $y$ for all sensitive variables $z$). These measures both try to describe the fairness of the policy (Dimitrakakis, 2020, p. 105). Other ways to consider whether or not the policy is fair is by looking at confusion matrices that describe the false positive rates as discussed above.\n",
    "\n",
    "We want to calculate a confusion matrix that describes the relations between the true \n",
    "responses and the predicted class (Hastie et al., 2016, p. 301). We use a random split with 0.25 as test size in order to generate the data in the confusion matrix for the different genders. We see that the rates are quite similar for $y=1$, \n",
    "but more dissimilar when it comes to $y=0$ (default). This is also shown through the graphical representation above.\n",
    "\n",
    "male (z=1)\n",
    "\n",
    "|                 | Action a=1        |  Action a=0     |\n",
    "|-----------------|-------------------|-----------------|\n",
    "| Response y=1    | 0.9206            | 0.0793          |\n",
    "| Response y=0    | 0.8510            | 0.1489          |\n",
    "\n",
    "female (z=0)\n",
    "\n",
    "|                 | Action a=1        |  Action a=0     |\n",
    "|-----------------|-------------------|-----------------|\n",
    "| Response y=1    | 0.92              | 0.08            |\n",
    "| Response y=0    | 0.6296            | 0.3703          |\n",
    "\n",
    "\n",
    "## How does the training data affect the fairness of the policy?\n",
    "\n",
    "The training data affects the fairness of the policy through the fact that the model in the policy is fitted using the training data. The training data is also affected by the collection methods for the data. The model is then implicitly affecting the policy through the expected utility for the new observations that is considered for loans.\n",
    "We can for example not say anything detailed about how the training data was collected, both methodology for collecting the data and selection of what data to collect. The data could be biased in the sense that the bank could be collecting data only about those observations they previously have provided a loan. If this is how the data was collected, this â€œprefilteringâ€ of the data makes it biased towards the applicants that repays because the observations that the bank considered too high risk to accept the credit application have already removed from the training data. \n",
    "\n",
    "## Summarizing comments\n",
    "The policy developed is as shown in the first part able to generate a higher expected utility than a random decision policy. The policy has also been modified in accordance with a local privacy model in order to increase privacy both for the training data and the test data. As was discussed in lecture 22.10.2020, the different ways of increasing the degree of privacy in the data depends on the future purpose of the data. For data that is to be published publicly, a local privacy model can make sense, but for data that is â€œprotectedâ€ a more centralized approach to privacy can be applied. Applying privacy for example at the probability provided for $y=1$ by the model in the policy can be seen as protecting the data with regards to privacy while not distorting the data as much as a local privacy model (University of Oslo, 2020a). With regard to fairness, the balance between genders should in theory be improved if the approach with stochastic gradient descent from the last part of the report is performed. The current fairness w.r.t. balance could be seen to deviate, especially for the case when $y=0$, that is, the borrower defaulted. However, this aspect of fairness should improve after adjusting the policy with different SGD.\n",
    "\n",
    "Further, the deficiencies with the conclusions in the report are addressed in the different sections. However, the bias in data collection could be highlighted as problematic. Also, the imbalance of the different categories could be seen as problematic. There are also latent hyperpriors that could be approximated in when making these decisions, especially macroeconomic conditions that would collectively affect all borrowers in the same manner as mentioned in the lecture (University of Oslo, 2020a). The assumption that the entire loan is to be repaid to a constant interest rate is also problematic. Firstly, the interest rate often varies and secondly, borrowers often transfer the loan to other banks. When it comes to methodology, more statistical analysis should ideally be performed in order to increase the accuracy of the prediction model, such as variable selection and/or model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Azzalini, A. & Scarpa, B. (2012). Data analysis and data mining: An introduction. Oxford: Oxford University Press.\n",
    "\n",
    "Devore, J. & Berk, L. (2012). Modern Mathematical Statistics with Applications\n",
    "(Springer Texts in Statistics). New York, NY: Springer New York.\n",
    "\n",
    "Dimitrakakis, C. (2020). *Machine learning in science and society*. Unpublished. Department of Informatics, University of Oslo.\n",
    "\n",
    "Dimitrakakis, C., Liu, Y., Parkes, D., & Radanovic, G. (2017). Bayesian fairness.\n",
    "\n",
    "Gelman, A., Carlin, J., Stern, H., Dunson, D., Vehtari, A. & Rubin, D. (2014). Bayesian data analysis (3rd ed., Texts in statistical science). Boca Raton, Fl: CRC Press.\n",
    "\n",
    "Hastie, T., Tibshirani, R. & Friedman, J. (2016). The Elements of Statistical Learning. Data Mining, Inference and Prediction. New York, NY: Springer New York.\n",
    "\n",
    "Le Ny, J. (2020). Differential privacy for dynamic data (1st ed. 2020, SpringerBriefs in electrical and computer engineering). Cham, Switzerland: Springer.\n",
    "\n",
    "University of Oslo. (2020). Tutlrial 2: Decisions, Utility and Fairness. Retrieved from https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/h20/forelesningsvideoer/2-tutorial-decisions-utility-fairness.mp4?vrtx=view-as-webpage \n",
    "\n",
    "University of Oslo. (2020a). Lecture videos. Retrieved from https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/h20/forelesningsvideoer/ \n",
    "\n",
    "Wikipedia. (2020, 12. august). Total variation distance of probability measures. Retrieved from https://en.wikipedia.orgwikiTotal_variation_distance_of_probability_measures \n",
    "\n",
    "Zhu, T. (2017). Differential privacy and applications (1st ed 2017 ed., Vol. 69, Advances in information security). Cham, Switzerland: Springer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## group1_banker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Group1Banker:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"A simple constructor that initializes the decision maker class with-\n",
    "        out the utility epsilon.\n",
    "        \"\"\"\n",
    "        self._utility_epsilon_enabled = False\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits a logistic regression model.\n",
    "\n",
    "        Args:\n",
    "            X: The covariates of the data set.\n",
    "            y: The response variable from the data set.\n",
    "        \"\"\"\n",
    "        self.data = [X, y]\n",
    "\n",
    "        self.model = self._fit_model(X, y)\n",
    "\n",
    "        if self._utility_epsilon_enabled:\n",
    "            self._utility_epsilon = self._calculate_utility_epsilon(\n",
    "                max_alpha=self._max_type1_error)\n",
    "        else:\n",
    "            self._utility_epsilon = 0\n",
    "\n",
    "    def _fit_model(self, X, y):\n",
    "        \"\"\"Fits the logistic model.\n",
    "\n",
    "        Args:\n",
    "            X: Covariates\n",
    "            y: Response variable\n",
    "\n",
    "        Notes:\n",
    "            Using logistic regression, adapted from\n",
    "            https://scikit-learn.org/stable/modules/generated/\n",
    "                sklearn.linear_model.LogisticRegression.html\n",
    "        \"\"\"\n",
    "        log_reg_object = LogisticRegression(random_state=1, max_iter=2000)\n",
    "        return log_reg_object.fit(X, y)\n",
    "\n",
    "    def enable_utility_epsilon(self, max_alpha=0.05):\n",
    "        \"\"\"Enables the utility epsilon in in order to reduce the probability of\n",
    "        type 1 error.\n",
    "\n",
    "        Args:\n",
    "            max_alpha: the maximum 'allowed' probability for type 1 errors.\n",
    "        \"\"\"\n",
    "        self._utility_epsilon_enabled = True\n",
    "        self._max_type1_error = max_alpha\n",
    "\n",
    "    def _calculate_utility_epsilon(self, max_alpha=0.05):\n",
    "        \"\"\"Estimates the threshold to use in the utility calculations based on\n",
    "        the training data. The method does this by splitting the training data\n",
    "        into a training set and a validation set. The validation set is used in\n",
    "        order to estimate the tuning parameter 'epsilon' which implicitly\n",
    "        calculates the estimated probability of type 1 error 'alpha_value' that\n",
    "        should be below the threshold of 'max_alpha'.\n",
    "\n",
    "        Args:\n",
    "            max_alpha: the maximal probability for type 1 error that is allowed\n",
    "\n",
    "        Returns:\n",
    "            The estimated utility epsilon.\n",
    "        \"\"\"\n",
    "        X = self.data[0]\n",
    "        y = self.data[1]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, random_state=1, test_size=0.25)\n",
    "        temp_model = self._fit_model(X_train, y_train)\n",
    "\n",
    "        MAX_ITER = 100000\n",
    "        count_iter = 0\n",
    "        epsilon = 0\n",
    "        delta_epsilon = 300\n",
    "\n",
    "        # initial estimated alpha value\n",
    "        alpha_value = 1\n",
    "\n",
    "        while (alpha_value >= max_alpha) and count_iter < MAX_ITER:\n",
    "            alpha_value = self._calculate_false_positive_rate(\n",
    "                temp_model, X_test, y_test, epsilon)\n",
    "            epsilon += delta_epsilon\n",
    "            count_iter += 1\n",
    "\n",
    "        return epsilon\n",
    "\n",
    "    def _calculate_false_positive_rate(self, temp_model, X_test, y_test, eps):\n",
    "        \"\"\"Calculates the percentage of false positives among the results on\n",
    "        the test set from the training data.\n",
    "\n",
    "        Args:\n",
    "            temp_model: the model fitted with the training part of the training\n",
    "            data\n",
    "            X_test: the covariates in the test part of the training data\n",
    "            y_test: the test part in the test part of the training data\n",
    "            eps: the epsilon (threshold) to use when deciding the best action\n",
    "            of the policy\n",
    "        \"\"\"\n",
    "        test_action = self._calculate_actions(temp_model, X_test, eps)\n",
    "\n",
    "        false_positives = np.logical_and(y_test == 0, test_action == 1)\n",
    "\n",
    "        return false_positives.mean()\n",
    "\n",
    "    def _calculate_actions(self, model, X_test, eps=0):\n",
    "        \"\"\"Calculates the best action based on a specific epsilon (threshold).\n",
    "\n",
    "        Args:\n",
    "            model: the model to use when predicting the best action\n",
    "            x_test: the test set to use when deciding the best action\n",
    "            eps: the threshold to use when deciding the best action\n",
    "\n",
    "        Returns:\n",
    "            The best action dependent on the epsilon threshold.\n",
    "        \"\"\"\n",
    "        p_c = model.predict_proba(X_test)\n",
    "\n",
    "        r = self.rate\n",
    "        # duration in months\n",
    "        n = X_test['duration']\n",
    "        # amount\n",
    "        m = X_test['amount']\n",
    "\n",
    "        e_X = p_c * m * ((1 + r) ** n - 1) + (1 - p_c) * (-m)\n",
    "\n",
    "        if e_X > eps:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # set the interest rate\n",
    "    def set_interest_rate(self, rate):\n",
    "        \"\"\"Sets the interest rate for the decision maker.\n",
    "\n",
    "        Args:\n",
    "            rate: the interest rate to use in the calculations.\n",
    "        \"\"\"\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts the probability for y=1 given new observations.\n",
    "\n",
    "        Args:\n",
    "            x: New, independent observations.\n",
    "\n",
    "        Returns:\n",
    "            The predicted probabilities for y=1.\n",
    "        \"\"\"\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # The expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is amount_of_loan*(1 + rate)^length_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    def expected_utility(self, X, action):\n",
    "        \"\"\"Calculate expected utility using the decision maker model.\n",
    "\n",
    "        Args:\n",
    "            X: New observations.\n",
    "            action: Whether or not to grant the loan.\n",
    "\n",
    "        Returns:\n",
    "            The expected utilities of the decision maker.\n",
    "        \"\"\"\n",
    "        if action == 0:\n",
    "            return np.zeros(X.shape[0])\n",
    "\n",
    "        r = self.rate\n",
    "        p_c = self.predict_proba(X)\n",
    "\n",
    "        # duration in months\n",
    "        n = X['duration']\n",
    "        # amount\n",
    "        m = X['amount']\n",
    "\n",
    "        e_x = p_c * m * ((1 + r) ** n - 1) + (1 - p_c) * (-m)\n",
    "        return e_x\n",
    "\n",
    "    def get_best_action(self, X):\n",
    "        \"\"\"Gets the best actions defined as the actions that maximizes utility.\n",
    "        An epsilon for utility is also set as the threshold that the expected\n",
    "        utility should exceed in order to get the best action. This utility\n",
    "        epsilon is 0 if the banker is not configured to use this functionality.\n",
    "        Otherwise it is estimated from the training data as the value that\n",
    "        provide a type 1 error below the parameter '_max_type1_error'.\n",
    "\n",
    "        Args:\n",
    "            X: New observations.\n",
    "\n",
    "        Returns:\n",
    "            Best actions based on maximizing utility.\n",
    "        \"\"\"\n",
    "        expected_utility_give_loan = self.expected_utility(X, 1)\n",
    "        expected_utility_no_loan = self.expected_utility(X, 0)\n",
    "\n",
    "        give_loan = expected_utility_give_loan > (\n",
    "            expected_utility_no_loan + self._utility_epsilon)\n",
    "        return give_loan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestImplementation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random_banker\n",
    "import group1_banker\n",
    "import differential_privacy\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_raw_data():\n",
    "    \"\"\" Reads in raw data then maps response to 0 and 1 and parses\n",
    "    the categorical attributes to pandas.caategorical\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame with the \"raw\" data\n",
    "    \"\"\"\n",
    "    features = ['checking account balance', 'duration', 'credit history',\n",
    "                'purpose', 'amount', 'savings', 'employment', 'installment',\n",
    "                'marital status', 'other debtors', 'residence time',\n",
    "                'property', 'age', 'other installments', 'housing', 'credits',\n",
    "                'job', 'persons', 'phone', 'foreign', 'repaid']\n",
    "\n",
    "    data_raw = pd.read_csv(\"../../data/credit/german.data\",\n",
    "                           delim_whitespace=True, names=features)\n",
    "\n",
    "    # Mapping the response to 0 and 1\n",
    "    data_raw.loc[:, \"repaid\"] = data_raw[\"repaid\"].map({1: 1, 2: 0})\n",
    "\n",
    "    categorical_columns = ['checking account balance', 'credit history',\n",
    "                           'purpose', 'savings', 'employment', 'marital status',\n",
    "                           'other debtors', 'property', 'other installments',\n",
    "                           'housing', 'job', 'phone', 'foreign', 'repaid']\n",
    "    data_raw.loc[:, categorical_columns] = data_raw[categorical_columns].apply(\n",
    "        lambda x: x.astype('category'))\n",
    "\n",
    "    return data_raw\n",
    "\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    \"\"\" One hot encodes specified columns.\n",
    "\n",
    "    Args:\n",
    "        data: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the categorical attributes one hot encoded\n",
    "    \"\"\"\n",
    "    columns = ['checking account balance', 'credit history',\n",
    "               'purpose', 'savings', 'employment', 'marital status',\n",
    "               'other debtors', 'property', 'other installments',\n",
    "               'housing', 'job', 'phone', 'foreign']\n",
    "    dummies = pd.get_dummies(data[columns], drop_first=True)\n",
    "    data = data.drop(columns, axis=1)\n",
    "\n",
    "    return data.join(dummies)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\" Gets the data and applies one hot encoding\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the usable data\n",
    "    \"\"\"\n",
    "    data = get_raw_data()\n",
    "    data = one_hot_encode(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def utility_from_obs(predicted_decision, true_decision, amount, duration, interest_rate):\n",
    "    \"\"\"Calculates utility for predicted decisions\n",
    "\n",
    "    Args:\n",
    "        predicted_decision: the model's best actions\n",
    "        true_decision: if the observations repaid or not\n",
    "        amount: the lending amounts\n",
    "        duration: the number of periods\n",
    "        interest_rate: the interest rate of the loan\n",
    "\n",
    "    Returns:\n",
    "        numpy array with the utilities for each decision.\n",
    "    \"\"\"\n",
    "    utility = np.zeros_like(true_decision)\n",
    "\n",
    "    predicted_decision_bool = predicted_decision == 1\n",
    "    ind1 = np.logical_and(predicted_decision_bool, true_decision == 1)\n",
    "    ind2 = np.logical_and(predicted_decision_bool, true_decision == 0)\n",
    "\n",
    "    utility[ind1] = amount[ind1]*((1 + interest_rate)**duration[ind1] - 1)\n",
    "    utility[ind2] = -amount[ind2]\n",
    "\n",
    "    return utility\n",
    "\n",
    "\n",
    "def utility_from_test_set(X, y, decision_maker, interest_rate):\n",
    "    \"\"\"Calculates total utility from a given test set.\n",
    "\n",
    "    Args:\n",
    "        X: the covariates of the test set\n",
    "        y: the response variable of the test set\n",
    "        decision_maker: the decision maker to use in order to calculate utility\n",
    "        interest_rate: the interest rate to use when calculating utility\n",
    "\n",
    "    Returns:\n",
    "        The sum of utility from the test set and the sum of utility divided by\n",
    "        total amount.\n",
    "    \"\"\"\n",
    "    predicted_decision = decision_maker.get_best_action(X)\n",
    "\n",
    "    amount = X['amount']\n",
    "    duration = X['duration']\n",
    "\n",
    "    utility = utility_from_obs(\n",
    "        predicted_decision, y, amount, duration, interest_rate)\n",
    "\n",
    "    return np.sum(utility), np.sum(utility)/np.sum(amount)\n",
    "\n",
    "\n",
    "def repeated_cross_validation_utility(X, y, bankers, interest_rate, n_repeats=20, n_folds=5):\n",
    "    \"\"\" Preforms repeated cross validation to find estimates for average utility\n",
    "    for different bankers.\n",
    "\n",
    "    Args:\n",
    "        X: pandas data frame with covariates\n",
    "        y: pandas series with the response\n",
    "        bankers: iterable with bankers implementing the fit() and get_best_action() methods.\n",
    "        interest_rate: float interest rate by month\n",
    "        n_repeats: number of repeats in repeated cross validation\n",
    "        n_folds: number of folds in k-fold cross validation\n",
    "\n",
    "    Returns:\n",
    "        numpy ndarray with shape (number of bankers, n_repeats, n_folds)\n",
    "        containing the utilities\n",
    "    \"\"\"\n",
    "    results = np.empty(shape=(len(bankers), n_repeats, n_folds))\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "        j = 0\n",
    "        for train_indices, test_indices in kf.split(X):\n",
    "            X_train = X.iloc[train_indices, :]\n",
    "            X_test = X.iloc[test_indices, :]\n",
    "            y_train = y[train_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            for b, banker in enumerate(bankers):\n",
    "                banker.fit(X_train, y_train)\n",
    "\n",
    "                util, _ = utility_from_test_set(\n",
    "                    X_test, y_test, banker, interest_rate)\n",
    "                results[b, i, j] = util\n",
    "            j += 1\n",
    "    return results\n",
    "\n",
    "\n",
    "def compare_with_random(n_repeats, n_folds, response, interest_rate):\n",
    "    \"\"\" Tests the random banker against our group1 banker.\n",
    "\n",
    "    Args:\n",
    "        n_repeats: the number of repeated cv's\n",
    "        n_folds: number of folds in k-fold cv\n",
    "        response: the name of the response variable\n",
    "        interest_rate: float interest rate by month\n",
    "\n",
    "    Returns:\n",
    "        numpy ndarray with shape (number of bankers, n_repeats, n_folds)\n",
    "        containing the utilities\n",
    "    \"\"\"\n",
    "\n",
    "    ## decision makers ##\n",
    "    # random banker\n",
    "    r_banker = random_banker.RandomBanker()\n",
    "    r_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # group1 banker\n",
    "    g_banker = group1_banker.Group1Banker()\n",
    "    g_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # get data\n",
    "    data = get_data()\n",
    "    # pop removes and returns the given column, \"response\" is no longer in data\n",
    "    y = data.pop(response)\n",
    "\n",
    "    return repeated_cross_validation_utility(\n",
    "        X=data, y=y,\n",
    "        bankers=[r_banker, g_banker],\n",
    "        interest_rate=interest_rate,\n",
    "        n_repeats=n_repeats, n_folds=n_folds\n",
    "    )\n",
    "\n",
    "\n",
    "def compare_decision_makers(n_repeats, n_folds, response, interest_rate):\n",
    "    \"\"\"Tests the random banker against our group1 banker.\n",
    "\n",
    "    Args:\n",
    "        num_of_repeats: the number of tests to run\n",
    "        response: the name of the response variable\n",
    "        interest_rate: the interest rate to use when calculating utility\n",
    "    \"\"\"\n",
    "\n",
    "    ## decision makers ##\n",
    "    # random banker\n",
    "    r_banker = random_banker.RandomBanker()\n",
    "    r_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # group1 banker\n",
    "    g_banker = group1_banker.Group1Banker()\n",
    "    g_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # conservative group1 banker\n",
    "    c_banker = group1_banker.Group1Banker()\n",
    "    c_banker.enable_utility_epsilon(max_alpha=0.1)\n",
    "    c_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    # get data\n",
    "    data = get_data()\n",
    "    # pop removes and returns the given column, \"response\" is no longer in data\n",
    "    y = data.pop(response)\n",
    "\n",
    "    return repeated_cross_validation_utility(\n",
    "        X=data, y=y,\n",
    "        bankers=[r_banker, g_banker, c_banker],\n",
    "        interest_rate=interest_rate,\n",
    "        n_repeats=n_repeats, n_folds=n_folds\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_priors(model):\n",
    "    \"\"\"Genereates a normally distributed prior for each of the regression\n",
    "    coefficients with mean = the estimated regression coefficients.\n",
    "\n",
    "    Args:\n",
    "        model: the logistic regression model\n",
    "    Returns:\n",
    "        The priors\n",
    "    \"\"\"\n",
    "    priors = tfp.distributions.Normal(\n",
    "        loc=[[i for i in model.coef_[0]]], scale=1)\n",
    "\n",
    "    return priors\n",
    "\n",
    "\n",
    "def _get_likelihood(model, X, y_values):\n",
    "    \"\"\"Gets the log-likelihood for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model: the probability model used\n",
    "        X: the covariates\n",
    "        y_values: the response values\n",
    "    Returns:\n",
    "        The log-likelihood\n",
    "    \"\"\"\n",
    "    log_probs = model.predict_log_proba(X)[:, 0]\n",
    "    log_lik = 0\n",
    "\n",
    "    for i in range(len(y_values)):\n",
    "        log_lik += y_values[i]*log_probs[i] + (1-y_values[i])*(1-log_probs[i])\n",
    "\n",
    "    return log_lik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## differential_privacy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Module for making data diferrentially private\n",
    "\n",
    "# TODO: Figure out what to do with discrete numerical attributes\n",
    "    Round them off after adding noise?\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "\n",
    "def transform_categorical(data, p):\n",
    "    \"\"\" Transform a column of categorical data data with a randomised response mechanism\n",
    "\n",
    "    Args:\n",
    "        data: Array with data from a categorical attribute.\n",
    "        p: The probablity of changing a datapoint.\n",
    "\n",
    "    Returns:\n",
    "        Array of the same length as the input data, containing the transformed data.\n",
    "    \"\"\"\n",
    "    transform_indexing = rnd.choice([True, False], size=data.size, p=[p, 1-p])\n",
    "    new_values = rnd.choice(np.unique(data), size=transform_indexing.sum())\n",
    "    new_data = data.copy()\n",
    "    new_data.loc[transform_indexing] = new_values\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def transform_quantitative(data, b, scale_noise=False):\n",
    "    \"\"\" Transform a column of quantitative data with laplace noise\n",
    "\n",
    "    Args:\n",
    "        data: Array with the data from a quantitative attribute.\n",
    "        b: Positive float used as the second parameter of the laplace distribution,\n",
    "            referred to as the scale or the diversity of the distribution.\n",
    "        scale_noise: If true, scale the laplace noise by the standard deviation of the data.\n",
    "            This allows the same value for b to be used on differently scaled data\n",
    "\n",
    "    Returns:\n",
    "        Array of the same length as the input data, containing the transformed data.\n",
    "    \"\"\"\n",
    "    noise = rnd.laplace(0, b, size=data.size)\n",
    "    if scale_noise:\n",
    "        noise *= data.std()\n",
    "    return data + noise\n",
    "\n",
    "\n",
    "def apply_random_mechanism_to_data(data_frame, quantitative_names, categorical_names, laplace_delta, p):\n",
    "    \"\"\" Aplies a random mechanism to certain columns of a data frame\n",
    "\n",
    "    Args:\n",
    "        data_frame: A pandas data frame\n",
    "        quantitative_names: An iterable with the column names of the quantitative attributes\n",
    "            you wish to add laplace noise to.\n",
    "        categorical_names: An iterable with the column names of the categorical attributes you\n",
    "            wish to transform.\n",
    "        laplace_delta: The delta parameter to supply to the laplace noise\n",
    "        p: The probability to suppÃ¸y to the random noise for categorical data.\n",
    "\n",
    "    Returns:\n",
    "        Pandas data frame of the same dimentions as the one supplied, but with differentially private data.\n",
    "    \"\"\"\n",
    "    dp_data = data_frame.copy()\n",
    "\n",
    "    for column_name in quantitative_names:\n",
    "        dp_data[column_name] = transform_quantitative(\n",
    "            data_frame[column_name], b=laplace_delta, scale_noise=True)\n",
    "\n",
    "    for column_name in categorical_names:\n",
    "        dp_data[column_name] = transform_categorical(\n",
    "            data_frame[column_name], p)\n",
    "\n",
    "    return dp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## privacy_guarantee.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TestImplementation\n",
    "import group1_banker\n",
    "import differential_privacy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def apply_epsilon_DP_noise(data, epsilon):\n",
    "    \"\"\" Applies noise to data to make it epsilon-DP\n",
    "\n",
    "    Args:\n",
    "        data: pandas DataFrame containing all the data\n",
    "        epsilon: float value for epsilon\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame with epsilon-DP version of data\n",
    "    \"\"\"\n",
    "    dp_data = data.copy()\n",
    "    numeric_variables = [\n",
    "        'duration', 'age', 'residence time', 'installment',\n",
    "        'amount', 'persons', 'credits'\n",
    "    ]\n",
    "    n_columns = len(dp_data.columns)\n",
    "    col_epsilon = epsilon/n_columns\n",
    "\n",
    "    for column in dp_data:\n",
    "        if column in numeric_variables:\n",
    "            val_range = dp_data[column].max() - dp_data[column].min()\n",
    "            laplace_lambda = val_range/col_epsilon\n",
    "            dp_data.loc[:, column] = differential_privacy.transform_quantitative(\n",
    "                data=dp_data[column], b=laplace_lambda\n",
    "            )\n",
    "        else:\n",
    "            rrm_p = 1/(np.exp(col_epsilon) + 1)\n",
    "            dp_data.loc[:, column] = differential_privacy.transform_categorical(\n",
    "                data=dp_data[column], p=rrm_p\n",
    "            )\n",
    "\n",
    "    return dp_data\n",
    "\n",
    "\n",
    "def utility_epsilons(epsilon_sequence, verbose=False):\n",
    "    \"\"\" Finds total utility of the group1_banker with epsilon-DF data for different values of epsilon\n",
    "    with 5-fold cv.\n",
    "\n",
    "    Args:\n",
    "        epsilon_sequence: iterable with the values for epsilon\n",
    "        verbose: If True tells you when it starts on a new fold.\n",
    "            Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np array with the utility values averaged over the cv folds\n",
    "    \"\"\"\n",
    "    banker = group1_banker.Group1Banker()\n",
    "    banker.set_interest_rate(0.05)\n",
    "\n",
    "    data = TestImplementation.get_raw_data()\n",
    "\n",
    "    utilities = np.zeros_like(epsilon_sequence)\n",
    "    n_folds = 5\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    i_fold = 0\n",
    "    for train, test in kf.split(data):\n",
    "        if verbose:\n",
    "            i_fold += 1\n",
    "            print(f\"Started on fold {i_fold}/{n_folds}\")\n",
    "\n",
    "        X_train = data.iloc[train, :]\n",
    "        X_train = TestImplementation.one_hot_encode(X_train)\n",
    "        y_train = X_train.pop('repaid')\n",
    "\n",
    "        for i, epsilon in enumerate(epsilon_sequence):\n",
    "            X_test = data.iloc[test, :]\n",
    "            y_test = X_test.pop('repaid').to_numpy()\n",
    "\n",
    "            # We need to use original amount and durantions for calculating utility\n",
    "            amount = X_test[\"amount\"]\n",
    "            duration = X_test[\"duration\"]\n",
    "\n",
    "            X_test = apply_epsilon_DP_noise(X_test, epsilon)\n",
    "            X_test = TestImplementation.one_hot_encode(X_test)\n",
    "\n",
    "            banker.fit(X_train, y_train)\n",
    "            pred_decision = banker.get_best_action(X_test)\n",
    "            utility = TestImplementation.utility_from_obs(\n",
    "                pred_decision, y_test, amount, duration, 0.05)\n",
    "            utilities[i] += np.sum(utility)/n_folds\n",
    "\n",
    "    return utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fairness_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447977\n",
      "         Iterations 7\n",
      "                               Results: Logit\n",
      "============================================================================\n",
      "Model:                   Logit               Pseudo R-squared:    0.267     \n",
      "Dependent Variable:      repaid              AIC:                 991.9540  \n",
      "Date:                    2020-10-23 12:35    BIC:                 1227.5263 \n",
      "No. Observations:        1000                Log-Likelihood:      -447.98   \n",
      "Df Model:                47                  LL-Null:             -610.86   \n",
      "Df Residuals:            952                 LLR p-value:         2.2973e-43\n",
      "Converged:               1.0000              Scale:               1.0000    \n",
      "No. Iterations:          7.0000                                             \n",
      "----------------------------------------------------------------------------\n",
      "                              Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "duration                     -0.0281   0.0093 -3.0215 0.0025 -0.0463 -0.0099\n",
      "amount                       -0.0001   0.0000 -2.9451 0.0032 -0.0002 -0.0000\n",
      "installment                  -0.3356   0.0871 -3.8551 0.0001 -0.5062 -0.1650\n",
      "residence time               -0.0092   0.0855 -0.1077 0.9142 -0.1769  0.1585\n",
      "age                           0.0135   0.0088  1.5387 0.1239 -0.0037  0.0307\n",
      "credits                      -0.2942   0.1797 -1.6369 0.1016 -0.6465  0.0581\n",
      "persons                      -0.2857   0.2423 -1.1789 0.2384 -0.7607  0.1893\n",
      "checking account balance_A12  0.3628   0.2154  1.6844 0.0921 -0.0593  0.7849\n",
      "checking account balance_A13  0.9487   0.3660  2.5923 0.0095  0.2314  1.6660\n",
      "checking account balance_A14  1.7103   0.2322  7.3653 0.0000  1.2552  2.1654\n",
      "credit history_A31           -0.2200   0.5075 -0.4335 0.6647 -1.2147  0.7747\n",
      "credit history_A32            0.5167   0.3866  1.3365 0.1814 -0.2410  1.2744\n",
      "credit history_A33            0.8034   0.4512  1.7806 0.0750 -0.0809  1.6878\n",
      "credit history_A34            1.3834   0.4157  3.3283 0.0009  0.5688  2.1981\n",
      "purpose_A41                   1.6637   0.3748  4.4389 0.0000  0.9291  2.3983\n",
      "purpose_A410                  1.4668   0.7758  1.8907 0.0587 -0.0537  2.9873\n",
      "purpose_A42                   0.7765   0.2577  3.0128 0.0026  0.2713  1.2816\n",
      "purpose_A43                   0.8860   0.2465  3.5938 0.0003  0.4028  1.3692\n",
      "purpose_A44                   0.5087   0.7603  0.6691 0.5034 -0.9814  1.9989\n",
      "purpose_A45                   0.2046   0.5480  0.3733 0.7089 -0.8694  1.2785\n",
      "purpose_A46                  -0.0383   0.3962 -0.0967 0.9230 -0.8148  0.7382\n",
      "purpose_A48                   2.0501   1.2103  1.6939 0.0903 -0.3220  4.4222\n",
      "purpose_A49                   0.7191   0.3289  2.1863 0.0288  0.0744  1.3638\n",
      "savings_A62                   0.3567   0.2863  1.2459 0.2128 -0.2044  0.9178\n",
      "savings_A63                   0.3654   0.4000  0.9136 0.3609 -0.4185  1.1494\n",
      "savings_A64                   1.3513   0.5244  2.5766 0.0100  0.3234  2.3792\n",
      "savings_A65                   0.9448   0.2623  3.6022 0.0003  0.4307  1.4588\n",
      "employment_A72                0.0413   0.4213  0.0981 0.9219 -0.7844  0.8670\n",
      "employment_A73                0.1620   0.4066  0.3984 0.6903 -0.6349  0.9589\n",
      "employment_A74                0.8173   0.4439  1.8412 0.0656 -0.0527  1.6874\n",
      "employment_A75                0.2719   0.4132  0.6579 0.5106 -0.5381  1.0818\n",
      "marital status_A92            0.2222   0.3590  0.6188 0.5360 -0.4815  0.9258\n",
      "marital status_A93            0.7754   0.3642  2.1289 0.0333  0.0615  1.4893\n",
      "marital status_A94            0.3131   0.4300  0.7282 0.4665 -0.5296  1.1559\n",
      "other debtors_A102           -0.4343   0.4101 -1.0590 0.2896 -1.2380  0.3695\n",
      "other debtors_A103            0.9780   0.4239  2.3074 0.0210  0.1473  1.8088\n",
      "property_A122                -0.2891   0.2524 -1.1452 0.2521 -0.7839  0.2057\n",
      "property_A123                -0.2033   0.2348 -0.8662 0.3864 -0.6635  0.2568\n",
      "property_A124                -0.7462   0.4223 -1.7670 0.0772 -1.5740  0.0815\n",
      "other installments_A142       0.1150   0.4114  0.2794 0.7799 -0.6914  0.9213\n",
      "other installments_A143       0.6259   0.2327  2.6892 0.0072  0.1697  1.0821\n",
      "housing_A152                  0.4303   0.2319  1.8553 0.0635 -0.0243  0.8848\n",
      "housing_A153                  0.6891   0.4771  1.4443 0.1486 -0.2460  1.6242\n",
      "job_A172                     -0.6382   0.6240 -1.0228 0.3064 -1.8613  0.5848\n",
      "job_A173                     -0.6613   0.5913 -1.1184 0.2634 -1.8202  0.4977\n",
      "job_A174                     -0.5852   0.6014 -0.9732 0.3305 -1.7638  0.5934\n",
      "phone_A192                    0.3054   0.2008  1.5212 0.1282 -0.0881  0.6990\n",
      "foreign_A202                  1.3728   0.6224  2.2056 0.0274  0.1529  2.5928\n",
      "============================================================================\n",
      "\n",
      "TVD y=1 = 0.0794294611722016\n",
      "TVD y=0 = 0.1875689059593812\n",
      "F_balance = 0.06988295448112253\n",
      "F_balance low = 0.09095134207669084\n",
      "F_balance high = 0.09686847949885814\n",
      "(male, female) ratio = [0.624 0.257]\n",
      "0.9206349206349206 0.851063829787234 0.14893617021276595 0.07936507936507936\n",
      "0.92 0.6296296296296297 0.37037037037037035 0.08\n"
     ]
    }
   ],
   "source": [
    "import TestImplementation\n",
    "import group1_banker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def total_variation(prob1, prob2):\n",
    "    \"\"\"Calculates the total variation distance by using the formula from\n",
    "    Wikipedia as referenced in the exercise text.\n",
    "\n",
    "    Args:\n",
    "        prob1: probability for a=1 for male (z=1)\n",
    "        prob2: probability for a=1 for female (z=0)\n",
    "\n",
    "    \"\"\"\n",
    "    return (1/2)*np.sum(np.abs(prob1 - prob2))\n",
    "\n",
    "\n",
    "def fairness(response, interest_rate=0.05):\n",
    "    \"\"\"Calculates proportion of a=1 conditional on gender (z) and response (y).\n",
    "\n",
    "    Args:\n",
    "        response: name of response variable in the data set\n",
    "        interest_rate: the interest rate to use\n",
    "    \"\"\"\n",
    "    data = TestImplementation.get_data()\n",
    "    y = data.pop(response)\n",
    "    X = data\n",
    "\n",
    "    g_banker = group1_banker.Group1Banker()\n",
    "    g_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    fairness_results = repeated_cv_fairness(\n",
    "        X, y, g_banker, n_repeats=10, n_folds=5)\n",
    "\n",
    "    print(f\"TVD y=1 = {np.mean(fairness_results['tv1'])}\")\n",
    "    print(f\"TVD y=0 = {np.mean(fairness_results['tv0'])}\")\n",
    "\n",
    "    print(f\"F_balance = {np.mean(fairness_results['fair_balance'])}\")\n",
    "    print(f\"F_balance low = {np.mean(fairness_results['fair_low'])}\")\n",
    "    print(f\"F_balance high = {np.mean(fairness_results['fair_high'])}\")\n",
    "    print(\n",
    "        f\"(male, female) ratio = {np.mean(fairness_results['gender_balance'], axis = 0)}\")\n",
    "\n",
    "\n",
    "def _get_gender(obs):\n",
    "    \"\"\"Gets gender from observation, 1 = male and 0 = female.\n",
    "\n",
    "    Args:\n",
    "        obs: covariates from a single observation\n",
    "\n",
    "    Returns:\n",
    "        1 if male, 0 if female.\n",
    "    \"\"\"\n",
    "    if obs['marital status_A92'] == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def calculate_balance_ratios(df):\n",
    "    \"\"\"Calculates the ratios between the actions dependent on the amounts. Will\n",
    "    check the ratio of loan  among the top 10 % of the amounts.\n",
    "    Args:\n",
    "        df: dataframe containing information about a, y, z and amount of loan\n",
    "            requested\n",
    "    Returns:\n",
    "        The gender ratios\n",
    "    \"\"\"\n",
    "    top10 = np.sort(df['am'])[-int(0.1*len(df))]\n",
    "    df = df[df['am'] >= top10]\n",
    "\n",
    "    male_ratio = len(df[(df['a'] == 1) & (df['z'] == 1)])/len(df)\n",
    "    female_ratio = len(df[(df['a'] == 1) & (df['z'] == 0)])/len(df)\n",
    "    return (male_ratio, female_ratio)\n",
    "\n",
    "\n",
    "def repeated_cv_fairness(X, y, banker, n_repeats=10, n_folds=10):\n",
    "    \"\"\"Calculates various fairness metrics with a repeated k-fold cross\n",
    "    validation.\n",
    "\n",
    "    Args:\n",
    "        X: covariates\n",
    "        y: response variable\n",
    "        n_repeats: repetitions of k-fold CV\n",
    "        n_folds: number of folds to use in CV\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of the fairness results.\n",
    "    \"\"\"\n",
    "    amount_threshold = np.median(X['amount'])\n",
    "\n",
    "    fairness_results = {}\n",
    "    total_var_dists_y1 = np.zeros(n_repeats*n_folds)\n",
    "    total_var_dists_y0 = np.zeros(n_repeats*n_folds)\n",
    "    total_fairness_bal = np.zeros(n_repeats*n_folds)\n",
    "    total_fairness_bal_low = np.zeros(n_repeats*n_folds)\n",
    "    total_fairness_bal_high = np.zeros(n_repeats*n_folds)\n",
    "    gender_balance = np.zeros(shape=(n_repeats*n_folds, 2))\n",
    "    t = 0\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "        for train_indices, test_indices in kf.split(X):\n",
    "            X_train = X.iloc[train_indices, :]\n",
    "            X_test = X.iloc[test_indices, :]\n",
    "            y_train = y[train_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            # fit model\n",
    "            banker.fit(X_train, y_train)\n",
    "\n",
    "            num_obs = len(X_test)\n",
    "            a_obs = np.zeros(num_obs)\n",
    "            am_obs = np.zeros(num_obs)\n",
    "            y_obs = np.zeros(num_obs)\n",
    "            z_obs = np.zeros(num_obs)\n",
    "\n",
    "            a_obs = banker.get_best_action(X_test)\n",
    "\n",
    "            for new_obs in range(num_obs):\n",
    "                obs = X_test.iloc[new_obs]\n",
    "\n",
    "                z_i = _get_gender(obs)\n",
    "                y_i = y_test.iloc[new_obs]\n",
    "                am_i = X.iloc[new_obs]['amount']\n",
    "\n",
    "                y_obs[new_obs] = y_i\n",
    "                z_obs[new_obs] = z_i\n",
    "                am_obs[new_obs] = am_i\n",
    "\n",
    "            fairness_df = pd.DataFrame(\n",
    "                {'z': list(z_obs), 'a': list(a_obs), 'y': list(y_obs), 'am': list(am_obs)})\n",
    "\n",
    "            men = fairness_df.loc[fairness_df['z'] == 1]\n",
    "            women = fairness_df.loc[fairness_df['z'] == 0]\n",
    "\n",
    "            z1_y1_a1 = len(men[(men['y'] == 1) & (\n",
    "                men['a'] == 1)])/len(men[men['y'] == 1])\n",
    "            z1_y0_a1 = len(men[(men['y'] == 0) & (\n",
    "                men['a'] == 1)]) / len(men[men['y'] == 0])\n",
    "            z0_y1_a1 = len(women[(women['y'] == 1) & (\n",
    "                women['a'] == 1)])/len(women[women['y'] == 1])\n",
    "            z0_y0_a1 = len(women[(women['y'] == 0) & (\n",
    "                women['a'] == 1)])/len(women[women['y'] == 0])\n",
    "\n",
    "            prob_m_y1 = np.array([z1_y1_a1, 1-z1_y1_a1])\n",
    "            prob_w_y1 = np.array([z0_y1_a1, 1-z0_y1_a1])\n",
    "\n",
    "            prob_m_y0 = np.array([z1_y0_a1, 1-z1_y0_a1])\n",
    "            prob_w_y0 = np.array([z0_y0_a1, 1-z0_y0_a1])\n",
    "\n",
    "            total_var_dists_y1[t] = total_variation(prob_m_y1, prob_w_y1)\n",
    "            total_var_dists_y0[t] = total_variation(prob_m_y0, prob_w_y0)\n",
    "\n",
    "            total_fairness_bal[t] = _calculate_balance(fairness_df)\n",
    "            total_fairness_bal_low[t] = _calculate_balance(\n",
    "                fairness_df, threshold=amount_threshold, upper=False)\n",
    "            total_fairness_bal_high[t] = _calculate_balance(\n",
    "                fairness_df, threshold=amount_threshold, upper=True)\n",
    "            gender_balance[t] = calculate_balance_ratios(fairness_df)\n",
    "            t = t + 1\n",
    "\n",
    "    fairness_results['tv0'] = total_var_dists_y0\n",
    "    fairness_results['tv1'] = total_var_dists_y1\n",
    "    fairness_results['fair_balance'] = total_fairness_bal\n",
    "    fairness_results['fair_low'] = total_fairness_bal_low\n",
    "    fairness_results['fair_high'] = total_fairness_bal_high\n",
    "    fairness_results['gender_balance'] = gender_balance\n",
    "\n",
    "    return fairness_results\n",
    "\n",
    "\n",
    "def _calculate_balance(df, threshold=None, upper=True):\n",
    "    \"\"\"Calculates the probability for the balance metric using relative\n",
    "    frequency.\n",
    "\n",
    "    Args:\n",
    "        df: dataframe containing\n",
    "            a: the action taken by the algorithm\n",
    "            y: the true response\n",
    "            z: the gender of the observation\n",
    "            am: the amount of loan\n",
    "        threshold: whether or not to threshold the amount\n",
    "        upper: use upper part of threshold\n",
    "\n",
    "    Returns:\n",
    "        Calculated balance loss.\n",
    "    \"\"\"\n",
    "    if (threshold == None):\n",
    "        N = len(df)\n",
    "        bal = 0\n",
    "        for a in range(0, 2):\n",
    "            for y in range(0, 2):\n",
    "                p_y = len(df[df['y'] == y])/N\n",
    "                p_a_and_y = len(df[(df['a'] == a) & (df['y'] == y)])/N\n",
    "                p_a_y = p_a_and_y/p_y\n",
    "                for z in range(0, 2):\n",
    "                    p_y_z = len(df[(df['y'] == y) & (df['z'] == z)])/N\n",
    "                    p_a_and_y_and_z = len(\n",
    "                        df[(df['a'] == a) & (df['y'] == y) & (df['z'] == z)])/N\n",
    "                    p_a_y_z = p_a_and_y_and_z/p_y_z\n",
    "                    bal += (p_a_y_z - p_a_y)**2\n",
    "\n",
    "        return bal\n",
    "    elif upper:\n",
    "        N = len(df['am'] > threshold)\n",
    "        bal = 0\n",
    "        for a in range(0, 2):\n",
    "            for y in range(0, 2):\n",
    "                p_y = len(df[(df['y'] == y) & (df['am'] > threshold)])/N\n",
    "                p_a_and_y = len(df[(df['a'] == a) & (\n",
    "                    df['y'] == y) & (df['am'] > threshold)])/N\n",
    "                p_a_y = p_a_and_y/p_y\n",
    "                for z in range(0, 2):\n",
    "                    p_y_z = len(df[(df['y'] == y) & (\n",
    "                        df['z'] == z) & (df['am'] > threshold)])/N\n",
    "                    p_a_and_y_and_z = len(\n",
    "                        df[(df['a'] == a) & (df['y'] == y) & (df['z'] == z) & (df['am'] > threshold)])/N\n",
    "                    p_a_y_z = p_a_and_y_and_z/p_y_z\n",
    "                    bal += (p_a_y_z - p_a_y)**2\n",
    "        return bal\n",
    "    else:\n",
    "        N = len(df['am'] <= threshold)\n",
    "        bal = 0\n",
    "        for a in range(0, 2):\n",
    "            for y in range(0, 2):\n",
    "                p_y = len(df[(df['y'] == y) & (df['am'] <= threshold)])/N\n",
    "                p_a_and_y = len(df[(df['a'] == a) & (\n",
    "                    df['y'] == y) & (df['am'] <= threshold)])/N\n",
    "                p_a_y = p_a_and_y/p_y\n",
    "                for z in range(0, 2):\n",
    "                    p_y_z = len(df[(df['y'] == y) & (df['z'] == z)\n",
    "                                   & (df['am'] <= threshold)])/N\n",
    "                    p_a_and_y_and_z = len(\n",
    "                        df[(df['a'] == a) & (df['y'] == y) & (df['z'] == z) & (df['am'] <= threshold)])/N\n",
    "                    p_a_y_z = p_a_and_y_and_z/p_y_z\n",
    "                    bal += (p_a_y_z - p_a_y)**2\n",
    "        return bal\n",
    "\n",
    "\n",
    "def countplot():\n",
    "    \"\"\" Create count plot to visualize gender fairness\n",
    "    \"\"\"\n",
    "    # Get data\n",
    "    X = TestImplementation.get_data()\n",
    "    y = X.pop(\"repaid\")\n",
    "\n",
    "    # Fit the banker\n",
    "    banker = group1_banker.Group1Banker()\n",
    "    banker.set_interest_rate(.05)\n",
    "    banker.fit(X, y)\n",
    "\n",
    "    # Get predictions\n",
    "    y_predicted = banker.get_best_action(X)\n",
    "    print(y_predicted.shape)\n",
    "\n",
    "    is_female = X[\"marital status_A92\"] == 1\n",
    "    sex = pd.Series(is_female.map({True: \"female\", False: \"male\"}))\n",
    "\n",
    "    gender_data = pd.DataFrame()\n",
    "    gender_data[\"repaid\"] = pd.concat((y, pd.Series(y_predicted))).map(\n",
    "        {0: \"no\", 1: \"yes\"})\n",
    "    gender_data[\"response\"] = np.repeat([\"true\", \"predicted\"], y.size)\n",
    "    gender_data[\"sex\"] = pd.concat((sex, sex))\n",
    "\n",
    "    sns.set_style(style=\"whitegrid\")\n",
    "    g = sns.catplot(x=\"repaid\", hue=\"sex\", col=\"response\",\n",
    "                    data=gender_data, kind=\"count\",\n",
    "                    height=4, aspect=.7)\n",
    "    plt.savefig(\"img/gender_compare.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_gender_significance():\n",
    "    \"\"\" Uses statsmodels to find statistics for the logistic model.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    X = TestImplementation.get_data()\n",
    "    y = X.pop(\"repaid\")\n",
    "\n",
    "    logit_model = sm.Logit(y, X)\n",
    "    result = logit_model.fit()\n",
    "    print(result.summary2())\n",
    "\n",
    "\n",
    "def confusion_matrix(response=\"repaid\", interest_rate=0.05):\n",
    "    \"\"\"Calculates the confusion matrix for males/females.\n",
    "    Args:\n",
    "        response: response in dataset\n",
    "        interest_rate: the interest rate to use\n",
    "    \"\"\"\n",
    "    data = TestImplementation.get_data()\n",
    "    y = data.pop(response)\n",
    "    X = data\n",
    "\n",
    "    g_banker = group1_banker.Group1Banker()\n",
    "    g_banker.set_interest_rate(interest_rate)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.25)\n",
    "\n",
    "    g_banker.fit(X_train, y_train)\n",
    "\n",
    "    num_obs = len(X_test)\n",
    "    a = g_banker.get_best_action(X_test)\n",
    "    y = np.zeros(num_obs)\n",
    "    z = np.zeros(num_obs)\n",
    "\n",
    "    for new_obs in range(num_obs):\n",
    "        obs = X_test.iloc[new_obs]\n",
    "        z_i = _get_gender(obs)\n",
    "        y_i = y_test.iloc[new_obs]\n",
    "\n",
    "        y[new_obs] = y_i\n",
    "        z[new_obs] = z_i\n",
    "\n",
    "    fairness_df = pd.DataFrame({'z': list(z), 'a': list(a), 'y': list(y)})\n",
    "    men = fairness_df.loc[fairness_df['z'] == 1]\n",
    "    women = fairness_df.loc[fairness_df['z'] == 0]\n",
    "\n",
    "    tp_male = len(men[(men['a'] == 1) & (men['y'] == 1)]) / \\\n",
    "        len(men[men['y'] == 1])\n",
    "    fp_male = len(men[(men['a'] == 1) & (men['y'] == 0)]) / \\\n",
    "        len(men[men['y'] == 0])\n",
    "    tn_male = len(men[(men['a'] == 0) & (men['y'] == 0)]) / \\\n",
    "        len(men[men['y'] == 0])\n",
    "    fn_male = len(men[(men['a'] == 0) & (men['y'] == 1)]) / \\\n",
    "        len(men[men['y'] == 1])\n",
    "\n",
    "    print(tp_male, fp_male, tn_male, fn_male)\n",
    "\n",
    "    tp_female = len(women[(women['a'] == 1) & (women['y'] == 1)]) / \\\n",
    "        len(women[women['y'] == 1])\n",
    "    fp_female = len(women[(women['a'] == 1) & (women['y'] == 0)]) / \\\n",
    "        len(women[women['y'] == 0])\n",
    "    tn_female = len(women[(women['a'] == 0) & (women['y'] == 0)]) / \\\n",
    "        len(women[women['y'] == 0])\n",
    "    fn_female = len(women[(women['a'] == 0) & (women['y'] == 1)]) / \\\n",
    "        len(women[women['y'] == 1])\n",
    "\n",
    "    print(tp_female, fp_female, tn_female, fn_female)\n",
    "\n",
    "\n",
    "def utility(a, y, pi):\n",
    "    \"\"\"Calculates the identity utility function.\n",
    "    Args:\n",
    "        a: the action taken by the policy\n",
    "        y: the true response\n",
    "        pi: the probability for action\n",
    "    \"\"\"\n",
    "    util = 0\n",
    "    for y_i in range(len(y)):\n",
    "        for a_i in range(len(a)):\n",
    "            util += pi*1 + (1-pi)*0\n",
    "    return util\n",
    "\n",
    "\n",
    "def stochastic_gradient():\n",
    "    \"\"\"Start of stochastic gradient descent for maximizing method.\n",
    "    \"\"\"\n",
    "    data = TestImplementation.get_data()\n",
    "    y = data.pop(response)\n",
    "    X = data\n",
    "\n",
    "    sgd_opt = tf.optimizers.SGD(learning_rate=0.2)\n",
    "\n",
    "    betas = tf.Variable(np.zeros(len(X.iloc[0])))\n",
    "\n",
    "    x = X.iloc[1].to_numpy()\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pi = tf.math.exp(tf.transpose(betas)*x) / \\\n",
    "            (tf.math.exp(tf.transpose(betas)*x) + 1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # countplot()\n",
    "    check_gender_significance()\n",
    "    np.random.seed(1)\n",
    "    response = 'repaid'\n",
    "    fairness(response)\n",
    "    confusion_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_banker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class RandomBanker:\n",
    "\n",
    "    # Fit the model to the data.  You can use any model you like to do\n",
    "    # the fit, however you should be able to predict all class\n",
    "    # probabilities\n",
    "    def fit(self, X, y):\n",
    "        self.data = [X, y]\n",
    "\n",
    "    # set the interest rate\n",
    "    def set_interest_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        return\n",
    "\n",
    "    # Predict the probability of failure for a specific person with data x\n",
    "    def predict_proba(self, x):\n",
    "        return 0\n",
    "\n",
    "    # THe expected utility of granting the loan or not. Here there are two actions:\n",
    "    # action = 0 do not grant the loan\n",
    "    # action = 1 grant the loan\n",
    "    #\n",
    "    # Make sure that you extract the length_of_loan from the\n",
    "    # 2nd attribute of x. Then the return if the loan is paid off to you is amount_of_loan*(1 + rate)^length_of_loan - amount_of_loan\n",
    "    # The return if the loan is not paid off is -amount_of_loan.\n",
    "    def expected_utility(self, x, action):\n",
    "        print(\"Expected utility: Not implemented\")\n",
    "    # Return the best action. This is normally the one that maximises expected utility.\n",
    "    # However, you are allowed to deviate from this if you can justify the reason.\n",
    "\n",
    "    def get_best_action(self, x):\n",
    "        return np.random.choice(2, x.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
